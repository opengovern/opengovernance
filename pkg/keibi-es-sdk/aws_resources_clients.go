// Code is generated by go generate. DO NOT EDIT.
package keibi

import (
	"context"
	aws "github.com/kaytu-io/kaytu-aws-describer/aws/model"
	"github.com/turbot/steampipe-plugin-sdk/v4/plugin"
)

// ==========================  START: AccessAnalyzerAnalyzer =============================

type AccessAnalyzerAnalyzer struct {
	Description   aws.AccessAnalyzerAnalyzerDescription `json:"description"`
	Metadata      aws.Metadata                          `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

type AccessAnalyzerAnalyzerHit struct {
	ID      string                 `json:"_id"`
	Score   float64                `json:"_score"`
	Index   string                 `json:"_index"`
	Type    string                 `json:"_type"`
	Version int64                  `json:"_version,omitempty"`
	Source  AccessAnalyzerAnalyzer `json:"_source"`
	Sort    []interface{}          `json:"sort"`
}

type AccessAnalyzerAnalyzerHits struct {
	Total SearchTotal                 `json:"total"`
	Hits  []AccessAnalyzerAnalyzerHit `json:"hits"`
}

type AccessAnalyzerAnalyzerSearchResponse struct {
	PitID string                     `json:"pit_id"`
	Hits  AccessAnalyzerAnalyzerHits `json:"hits"`
}

type AccessAnalyzerAnalyzerPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAccessAnalyzerAnalyzerPaginator(filters []BoolFilter, limit *int64) (AccessAnalyzerAnalyzerPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_accessanalyzer_analyzer", filters, limit)
	if err != nil {
		return AccessAnalyzerAnalyzerPaginator{}, err
	}

	p := AccessAnalyzerAnalyzerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AccessAnalyzerAnalyzerPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AccessAnalyzerAnalyzerPaginator) NextPage(ctx context.Context) ([]AccessAnalyzerAnalyzer, error) {
	var response AccessAnalyzerAnalyzerSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AccessAnalyzerAnalyzer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAccessAnalyzerAnalyzerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"type":             "description.Analyzer.Type",
}

func ListAccessAnalyzerAnalyzer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAccessAnalyzerAnalyzer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAccessAnalyzerAnalyzerPaginator(buildFilter(d.KeyColumnQuals, listAccessAnalyzerAnalyzerFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAccessAnalyzerAnalyzerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Analyzer.Name",
}

func GetAccessAnalyzerAnalyzer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAccessAnalyzerAnalyzer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAccessAnalyzerAnalyzerPaginator(buildFilter(d.KeyColumnQuals, getAccessAnalyzerAnalyzerFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AccessAnalyzerAnalyzer =============================

// ==========================  START: ApiGatewayStage =============================

type ApiGatewayStage struct {
	Description   aws.ApiGatewayStageDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type ApiGatewayStageHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  ApiGatewayStage `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type ApiGatewayStageHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []ApiGatewayStageHit `json:"hits"`
}

type ApiGatewayStageSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  ApiGatewayStageHits `json:"hits"`
}

type ApiGatewayStagePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewApiGatewayStagePaginator(filters []BoolFilter, limit *int64) (ApiGatewayStagePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_apigateway_stage", filters, limit)
	if err != nil {
		return ApiGatewayStagePaginator{}, err
	}

	p := ApiGatewayStagePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ApiGatewayStagePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ApiGatewayStagePaginator) NextPage(ctx context.Context) ([]ApiGatewayStage, error) {
	var response ApiGatewayStageSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ApiGatewayStage
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listApiGatewayStageFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListApiGatewayStage(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListApiGatewayStage")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewApiGatewayStagePaginator(buildFilter(d.KeyColumnQuals, listApiGatewayStageFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getApiGatewayStageFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Stage.StageName",
	"rest_api_id":      "description.RestApiId",
}

func GetApiGatewayStage(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetApiGatewayStage")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewApiGatewayStagePaginator(buildFilter(d.KeyColumnQuals, getApiGatewayStageFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ApiGatewayStage =============================

// ==========================  START: ApiGatewayV2Stage =============================

type ApiGatewayV2Stage struct {
	Description   aws.ApiGatewayV2StageDescription `json:"description"`
	Metadata      aws.Metadata                     `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

type ApiGatewayV2StageHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  ApiGatewayV2Stage `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type ApiGatewayV2StageHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []ApiGatewayV2StageHit `json:"hits"`
}

type ApiGatewayV2StageSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  ApiGatewayV2StageHits `json:"hits"`
}

type ApiGatewayV2StagePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewApiGatewayV2StagePaginator(filters []BoolFilter, limit *int64) (ApiGatewayV2StagePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_apigatewayv2_stage", filters, limit)
	if err != nil {
		return ApiGatewayV2StagePaginator{}, err
	}

	p := ApiGatewayV2StagePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ApiGatewayV2StagePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ApiGatewayV2StagePaginator) NextPage(ctx context.Context) ([]ApiGatewayV2Stage, error) {
	var response ApiGatewayV2StageSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ApiGatewayV2Stage
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listApiGatewayV2StageFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListApiGatewayV2Stage(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListApiGatewayV2Stage")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewApiGatewayV2StagePaginator(buildFilter(d.KeyColumnQuals, listApiGatewayV2StageFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getApiGatewayV2StageFilters = map[string]string{
	"api_id":           "description.ApiId",
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Stage.StageName",
}

func GetApiGatewayV2Stage(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetApiGatewayV2Stage")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewApiGatewayV2StagePaginator(buildFilter(d.KeyColumnQuals, getApiGatewayV2StageFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ApiGatewayV2Stage =============================

// ==========================  START: ApiGatewayRestAPI =============================

type ApiGatewayRestAPI struct {
	Description   aws.ApiGatewayRestAPIDescription `json:"description"`
	Metadata      aws.Metadata                     `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

type ApiGatewayRestAPIHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  ApiGatewayRestAPI `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type ApiGatewayRestAPIHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []ApiGatewayRestAPIHit `json:"hits"`
}

type ApiGatewayRestAPISearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  ApiGatewayRestAPIHits `json:"hits"`
}

type ApiGatewayRestAPIPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewApiGatewayRestAPIPaginator(filters []BoolFilter, limit *int64) (ApiGatewayRestAPIPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_apigateway_restapi", filters, limit)
	if err != nil {
		return ApiGatewayRestAPIPaginator{}, err
	}

	p := ApiGatewayRestAPIPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ApiGatewayRestAPIPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ApiGatewayRestAPIPaginator) NextPage(ctx context.Context) ([]ApiGatewayRestAPI, error) {
	var response ApiGatewayRestAPISearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ApiGatewayRestAPI
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listApiGatewayRestAPIFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListApiGatewayRestAPI(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListApiGatewayRestAPI")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewApiGatewayRestAPIPaginator(buildFilter(d.KeyColumnQuals, listApiGatewayRestAPIFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getApiGatewayRestAPIFilters = map[string]string{
	"api_id":           "description.RestAPI.Id",
	"keibi_account_id": "metadata.SourceID",
}

func GetApiGatewayRestAPI(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetApiGatewayRestAPI")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewApiGatewayRestAPIPaginator(buildFilter(d.KeyColumnQuals, getApiGatewayRestAPIFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ApiGatewayRestAPI =============================

// ==========================  START: ApiGatewayApiKey =============================

type ApiGatewayApiKey struct {
	Description   aws.ApiGatewayApiKeyDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type ApiGatewayApiKeyHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  ApiGatewayApiKey `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type ApiGatewayApiKeyHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []ApiGatewayApiKeyHit `json:"hits"`
}

type ApiGatewayApiKeySearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  ApiGatewayApiKeyHits `json:"hits"`
}

type ApiGatewayApiKeyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewApiGatewayApiKeyPaginator(filters []BoolFilter, limit *int64) (ApiGatewayApiKeyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_apigateway_apikey", filters, limit)
	if err != nil {
		return ApiGatewayApiKeyPaginator{}, err
	}

	p := ApiGatewayApiKeyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ApiGatewayApiKeyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ApiGatewayApiKeyPaginator) NextPage(ctx context.Context) ([]ApiGatewayApiKey, error) {
	var response ApiGatewayApiKeySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ApiGatewayApiKey
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listApiGatewayApiKeyFilters = map[string]string{
	"customer_id":      "description.ApiKey.CustomerId",
	"keibi_account_id": "metadata.SourceID",
}

func ListApiGatewayApiKey(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListApiGatewayApiKey")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewApiGatewayApiKeyPaginator(buildFilter(d.KeyColumnQuals, listApiGatewayApiKeyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getApiGatewayApiKeyFilters = map[string]string{
	"id":               "description.ApiKey.Id",
	"keibi_account_id": "metadata.SourceID",
}

func GetApiGatewayApiKey(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetApiGatewayApiKey")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewApiGatewayApiKeyPaginator(buildFilter(d.KeyColumnQuals, getApiGatewayApiKeyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ApiGatewayApiKey =============================

// ==========================  START: ApiGatewayUsagePlan =============================

type ApiGatewayUsagePlan struct {
	Description   aws.ApiGatewayUsagePlanDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type ApiGatewayUsagePlanHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  ApiGatewayUsagePlan `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type ApiGatewayUsagePlanHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []ApiGatewayUsagePlanHit `json:"hits"`
}

type ApiGatewayUsagePlanSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  ApiGatewayUsagePlanHits `json:"hits"`
}

type ApiGatewayUsagePlanPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewApiGatewayUsagePlanPaginator(filters []BoolFilter, limit *int64) (ApiGatewayUsagePlanPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_apigateway_usageplan", filters, limit)
	if err != nil {
		return ApiGatewayUsagePlanPaginator{}, err
	}

	p := ApiGatewayUsagePlanPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ApiGatewayUsagePlanPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ApiGatewayUsagePlanPaginator) NextPage(ctx context.Context) ([]ApiGatewayUsagePlan, error) {
	var response ApiGatewayUsagePlanSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ApiGatewayUsagePlan
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listApiGatewayUsagePlanFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListApiGatewayUsagePlan(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListApiGatewayUsagePlan")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewApiGatewayUsagePlanPaginator(buildFilter(d.KeyColumnQuals, listApiGatewayUsagePlanFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getApiGatewayUsagePlanFilters = map[string]string{
	"id":               "description.UsagePlan.Id",
	"keibi_account_id": "metadata.SourceID",
}

func GetApiGatewayUsagePlan(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetApiGatewayUsagePlan")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewApiGatewayUsagePlanPaginator(buildFilter(d.KeyColumnQuals, getApiGatewayUsagePlanFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ApiGatewayUsagePlan =============================

// ==========================  START: ApiGatewayAuthorizer =============================

type ApiGatewayAuthorizer struct {
	Description   aws.ApiGatewayAuthorizerDescription `json:"description"`
	Metadata      aws.Metadata                        `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type ApiGatewayAuthorizerHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  ApiGatewayAuthorizer `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type ApiGatewayAuthorizerHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []ApiGatewayAuthorizerHit `json:"hits"`
}

type ApiGatewayAuthorizerSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  ApiGatewayAuthorizerHits `json:"hits"`
}

type ApiGatewayAuthorizerPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewApiGatewayAuthorizerPaginator(filters []BoolFilter, limit *int64) (ApiGatewayAuthorizerPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_apigateway_authorizer", filters, limit)
	if err != nil {
		return ApiGatewayAuthorizerPaginator{}, err
	}

	p := ApiGatewayAuthorizerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ApiGatewayAuthorizerPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ApiGatewayAuthorizerPaginator) NextPage(ctx context.Context) ([]ApiGatewayAuthorizer, error) {
	var response ApiGatewayAuthorizerSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ApiGatewayAuthorizer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listApiGatewayAuthorizerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListApiGatewayAuthorizer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListApiGatewayAuthorizer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewApiGatewayAuthorizerPaginator(buildFilter(d.KeyColumnQuals, listApiGatewayAuthorizerFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getApiGatewayAuthorizerFilters = map[string]string{
	"id":               "description.Authorizer.Id",
	"keibi_account_id": "metadata.SourceID",
	"rest_api_id":      "description.RestApiId",
}

func GetApiGatewayAuthorizer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetApiGatewayAuthorizer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewApiGatewayAuthorizerPaginator(buildFilter(d.KeyColumnQuals, getApiGatewayAuthorizerFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ApiGatewayAuthorizer =============================

// ==========================  START: ApiGatewayV2API =============================

type ApiGatewayV2API struct {
	Description   aws.ApiGatewayV2APIDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type ApiGatewayV2APIHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  ApiGatewayV2API `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type ApiGatewayV2APIHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []ApiGatewayV2APIHit `json:"hits"`
}

type ApiGatewayV2APISearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  ApiGatewayV2APIHits `json:"hits"`
}

type ApiGatewayV2APIPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewApiGatewayV2APIPaginator(filters []BoolFilter, limit *int64) (ApiGatewayV2APIPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_apigatewayv2_api", filters, limit)
	if err != nil {
		return ApiGatewayV2APIPaginator{}, err
	}

	p := ApiGatewayV2APIPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ApiGatewayV2APIPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ApiGatewayV2APIPaginator) NextPage(ctx context.Context) ([]ApiGatewayV2API, error) {
	var response ApiGatewayV2APISearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ApiGatewayV2API
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listApiGatewayV2APIFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListApiGatewayV2API(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListApiGatewayV2API")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewApiGatewayV2APIPaginator(buildFilter(d.KeyColumnQuals, listApiGatewayV2APIFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getApiGatewayV2APIFilters = map[string]string{
	"api_id":           "description.API.ApiId",
	"keibi_account_id": "metadata.SourceID",
}

func GetApiGatewayV2API(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetApiGatewayV2API")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewApiGatewayV2APIPaginator(buildFilter(d.KeyColumnQuals, getApiGatewayV2APIFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ApiGatewayV2API =============================

// ==========================  START: ApiGatewayV2DomainName =============================

type ApiGatewayV2DomainName struct {
	Description   aws.ApiGatewayV2DomainNameDescription `json:"description"`
	Metadata      aws.Metadata                          `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

type ApiGatewayV2DomainNameHit struct {
	ID      string                 `json:"_id"`
	Score   float64                `json:"_score"`
	Index   string                 `json:"_index"`
	Type    string                 `json:"_type"`
	Version int64                  `json:"_version,omitempty"`
	Source  ApiGatewayV2DomainName `json:"_source"`
	Sort    []interface{}          `json:"sort"`
}

type ApiGatewayV2DomainNameHits struct {
	Total SearchTotal                 `json:"total"`
	Hits  []ApiGatewayV2DomainNameHit `json:"hits"`
}

type ApiGatewayV2DomainNameSearchResponse struct {
	PitID string                     `json:"pit_id"`
	Hits  ApiGatewayV2DomainNameHits `json:"hits"`
}

type ApiGatewayV2DomainNamePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewApiGatewayV2DomainNamePaginator(filters []BoolFilter, limit *int64) (ApiGatewayV2DomainNamePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_apigatewayv2_domainname", filters, limit)
	if err != nil {
		return ApiGatewayV2DomainNamePaginator{}, err
	}

	p := ApiGatewayV2DomainNamePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ApiGatewayV2DomainNamePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ApiGatewayV2DomainNamePaginator) NextPage(ctx context.Context) ([]ApiGatewayV2DomainName, error) {
	var response ApiGatewayV2DomainNameSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ApiGatewayV2DomainName
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listApiGatewayV2DomainNameFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListApiGatewayV2DomainName(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListApiGatewayV2DomainName")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewApiGatewayV2DomainNamePaginator(buildFilter(d.KeyColumnQuals, listApiGatewayV2DomainNameFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getApiGatewayV2DomainNameFilters = map[string]string{
	"domain_name":      "description.DomainName.DomainName",
	"keibi_account_id": "metadata.SourceID",
}

func GetApiGatewayV2DomainName(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetApiGatewayV2DomainName")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewApiGatewayV2DomainNamePaginator(buildFilter(d.KeyColumnQuals, getApiGatewayV2DomainNameFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ApiGatewayV2DomainName =============================

// ==========================  START: ApiGatewayV2Integration =============================

type ApiGatewayV2Integration struct {
	Description   aws.ApiGatewayV2IntegrationDescription `json:"description"`
	Metadata      aws.Metadata                           `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

type ApiGatewayV2IntegrationHit struct {
	ID      string                  `json:"_id"`
	Score   float64                 `json:"_score"`
	Index   string                  `json:"_index"`
	Type    string                  `json:"_type"`
	Version int64                   `json:"_version,omitempty"`
	Source  ApiGatewayV2Integration `json:"_source"`
	Sort    []interface{}           `json:"sort"`
}

type ApiGatewayV2IntegrationHits struct {
	Total SearchTotal                  `json:"total"`
	Hits  []ApiGatewayV2IntegrationHit `json:"hits"`
}

type ApiGatewayV2IntegrationSearchResponse struct {
	PitID string                      `json:"pit_id"`
	Hits  ApiGatewayV2IntegrationHits `json:"hits"`
}

type ApiGatewayV2IntegrationPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewApiGatewayV2IntegrationPaginator(filters []BoolFilter, limit *int64) (ApiGatewayV2IntegrationPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_apigatewayv2_integration", filters, limit)
	if err != nil {
		return ApiGatewayV2IntegrationPaginator{}, err
	}

	p := ApiGatewayV2IntegrationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ApiGatewayV2IntegrationPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ApiGatewayV2IntegrationPaginator) NextPage(ctx context.Context) ([]ApiGatewayV2Integration, error) {
	var response ApiGatewayV2IntegrationSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ApiGatewayV2Integration
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listApiGatewayV2IntegrationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListApiGatewayV2Integration(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListApiGatewayV2Integration")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewApiGatewayV2IntegrationPaginator(buildFilter(d.KeyColumnQuals, listApiGatewayV2IntegrationFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getApiGatewayV2IntegrationFilters = map[string]string{
	"api_id":           "description.ApiId",
	"integration_id":   "description.Integration.IntegrationId",
	"keibi_account_id": "metadata.SourceID",
}

func GetApiGatewayV2Integration(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetApiGatewayV2Integration")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewApiGatewayV2IntegrationPaginator(buildFilter(d.KeyColumnQuals, getApiGatewayV2IntegrationFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ApiGatewayV2Integration =============================

// ==========================  START: ElasticBeanstalkEnvironment =============================

type ElasticBeanstalkEnvironment struct {
	Description   aws.ElasticBeanstalkEnvironmentDescription `json:"description"`
	Metadata      aws.Metadata                               `json:"metadata"`
	ResourceJobID int                                        `json:"resource_job_id"`
	SourceJobID   int                                        `json:"source_job_id"`
	ResourceType  string                                     `json:"resource_type"`
	SourceType    string                                     `json:"source_type"`
	ID            string                                     `json:"id"`
	ARN           string                                     `json:"arn"`
	SourceID      string                                     `json:"source_id"`
}

type ElasticBeanstalkEnvironmentHit struct {
	ID      string                      `json:"_id"`
	Score   float64                     `json:"_score"`
	Index   string                      `json:"_index"`
	Type    string                      `json:"_type"`
	Version int64                       `json:"_version,omitempty"`
	Source  ElasticBeanstalkEnvironment `json:"_source"`
	Sort    []interface{}               `json:"sort"`
}

type ElasticBeanstalkEnvironmentHits struct {
	Total SearchTotal                      `json:"total"`
	Hits  []ElasticBeanstalkEnvironmentHit `json:"hits"`
}

type ElasticBeanstalkEnvironmentSearchResponse struct {
	PitID string                          `json:"pit_id"`
	Hits  ElasticBeanstalkEnvironmentHits `json:"hits"`
}

type ElasticBeanstalkEnvironmentPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewElasticBeanstalkEnvironmentPaginator(filters []BoolFilter, limit *int64) (ElasticBeanstalkEnvironmentPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticbeanstalk_environment", filters, limit)
	if err != nil {
		return ElasticBeanstalkEnvironmentPaginator{}, err
	}

	p := ElasticBeanstalkEnvironmentPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ElasticBeanstalkEnvironmentPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ElasticBeanstalkEnvironmentPaginator) NextPage(ctx context.Context) ([]ElasticBeanstalkEnvironment, error) {
	var response ElasticBeanstalkEnvironmentSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ElasticBeanstalkEnvironment
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listElasticBeanstalkEnvironmentFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListElasticBeanstalkEnvironment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListElasticBeanstalkEnvironment")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewElasticBeanstalkEnvironmentPaginator(buildFilter(d.KeyColumnQuals, listElasticBeanstalkEnvironmentFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getElasticBeanstalkEnvironmentFilters = map[string]string{
	"environment_name": "description.EnvironmentDescription.EnvironmentName",
	"keibi_account_id": "metadata.SourceID",
}

func GetElasticBeanstalkEnvironment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetElasticBeanstalkEnvironment")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewElasticBeanstalkEnvironmentPaginator(buildFilter(d.KeyColumnQuals, getElasticBeanstalkEnvironmentFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ElasticBeanstalkEnvironment =============================

// ==========================  START: ElasticBeanstalkApplication =============================

type ElasticBeanstalkApplication struct {
	Description   aws.ElasticBeanstalkApplicationDescription `json:"description"`
	Metadata      aws.Metadata                               `json:"metadata"`
	ResourceJobID int                                        `json:"resource_job_id"`
	SourceJobID   int                                        `json:"source_job_id"`
	ResourceType  string                                     `json:"resource_type"`
	SourceType    string                                     `json:"source_type"`
	ID            string                                     `json:"id"`
	ARN           string                                     `json:"arn"`
	SourceID      string                                     `json:"source_id"`
}

type ElasticBeanstalkApplicationHit struct {
	ID      string                      `json:"_id"`
	Score   float64                     `json:"_score"`
	Index   string                      `json:"_index"`
	Type    string                      `json:"_type"`
	Version int64                       `json:"_version,omitempty"`
	Source  ElasticBeanstalkApplication `json:"_source"`
	Sort    []interface{}               `json:"sort"`
}

type ElasticBeanstalkApplicationHits struct {
	Total SearchTotal                      `json:"total"`
	Hits  []ElasticBeanstalkApplicationHit `json:"hits"`
}

type ElasticBeanstalkApplicationSearchResponse struct {
	PitID string                          `json:"pit_id"`
	Hits  ElasticBeanstalkApplicationHits `json:"hits"`
}

type ElasticBeanstalkApplicationPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewElasticBeanstalkApplicationPaginator(filters []BoolFilter, limit *int64) (ElasticBeanstalkApplicationPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticbeanstalk_application", filters, limit)
	if err != nil {
		return ElasticBeanstalkApplicationPaginator{}, err
	}

	p := ElasticBeanstalkApplicationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ElasticBeanstalkApplicationPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ElasticBeanstalkApplicationPaginator) NextPage(ctx context.Context) ([]ElasticBeanstalkApplication, error) {
	var response ElasticBeanstalkApplicationSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ElasticBeanstalkApplication
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listElasticBeanstalkApplicationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListElasticBeanstalkApplication(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListElasticBeanstalkApplication")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewElasticBeanstalkApplicationPaginator(buildFilter(d.KeyColumnQuals, listElasticBeanstalkApplicationFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getElasticBeanstalkApplicationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Application.ApplicationName",
}

func GetElasticBeanstalkApplication(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetElasticBeanstalkApplication")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewElasticBeanstalkApplicationPaginator(buildFilter(d.KeyColumnQuals, getElasticBeanstalkApplicationFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ElasticBeanstalkApplication =============================

// ==========================  START: ElasticBeanstalkPlatform =============================

type ElasticBeanstalkPlatform struct {
	Description   aws.ElasticBeanstalkPlatformDescription `json:"description"`
	Metadata      aws.Metadata                            `json:"metadata"`
	ResourceJobID int                                     `json:"resource_job_id"`
	SourceJobID   int                                     `json:"source_job_id"`
	ResourceType  string                                  `json:"resource_type"`
	SourceType    string                                  `json:"source_type"`
	ID            string                                  `json:"id"`
	ARN           string                                  `json:"arn"`
	SourceID      string                                  `json:"source_id"`
}

type ElasticBeanstalkPlatformHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  ElasticBeanstalkPlatform `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type ElasticBeanstalkPlatformHits struct {
	Total SearchTotal                   `json:"total"`
	Hits  []ElasticBeanstalkPlatformHit `json:"hits"`
}

type ElasticBeanstalkPlatformSearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  ElasticBeanstalkPlatformHits `json:"hits"`
}

type ElasticBeanstalkPlatformPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewElasticBeanstalkPlatformPaginator(filters []BoolFilter, limit *int64) (ElasticBeanstalkPlatformPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticbeanstalk_platform", filters, limit)
	if err != nil {
		return ElasticBeanstalkPlatformPaginator{}, err
	}

	p := ElasticBeanstalkPlatformPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ElasticBeanstalkPlatformPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ElasticBeanstalkPlatformPaginator) NextPage(ctx context.Context) ([]ElasticBeanstalkPlatform, error) {
	var response ElasticBeanstalkPlatformSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ElasticBeanstalkPlatform
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listElasticBeanstalkPlatformFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListElasticBeanstalkPlatform(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListElasticBeanstalkPlatform")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewElasticBeanstalkPlatformPaginator(buildFilter(d.KeyColumnQuals, listElasticBeanstalkPlatformFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getElasticBeanstalkPlatformFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"platform_name":    "description.Platform.PlatformName",
}

func GetElasticBeanstalkPlatform(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetElasticBeanstalkPlatform")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewElasticBeanstalkPlatformPaginator(buildFilter(d.KeyColumnQuals, getElasticBeanstalkPlatformFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ElasticBeanstalkPlatform =============================

// ==========================  START: ElastiCacheReplicationGroup =============================

type ElastiCacheReplicationGroup struct {
	Description   aws.ElastiCacheReplicationGroupDescription `json:"description"`
	Metadata      aws.Metadata                               `json:"metadata"`
	ResourceJobID int                                        `json:"resource_job_id"`
	SourceJobID   int                                        `json:"source_job_id"`
	ResourceType  string                                     `json:"resource_type"`
	SourceType    string                                     `json:"source_type"`
	ID            string                                     `json:"id"`
	ARN           string                                     `json:"arn"`
	SourceID      string                                     `json:"source_id"`
}

type ElastiCacheReplicationGroupHit struct {
	ID      string                      `json:"_id"`
	Score   float64                     `json:"_score"`
	Index   string                      `json:"_index"`
	Type    string                      `json:"_type"`
	Version int64                       `json:"_version,omitempty"`
	Source  ElastiCacheReplicationGroup `json:"_source"`
	Sort    []interface{}               `json:"sort"`
}

type ElastiCacheReplicationGroupHits struct {
	Total SearchTotal                      `json:"total"`
	Hits  []ElastiCacheReplicationGroupHit `json:"hits"`
}

type ElastiCacheReplicationGroupSearchResponse struct {
	PitID string                          `json:"pit_id"`
	Hits  ElastiCacheReplicationGroupHits `json:"hits"`
}

type ElastiCacheReplicationGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewElastiCacheReplicationGroupPaginator(filters []BoolFilter, limit *int64) (ElastiCacheReplicationGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticache_replicationgroup", filters, limit)
	if err != nil {
		return ElastiCacheReplicationGroupPaginator{}, err
	}

	p := ElastiCacheReplicationGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ElastiCacheReplicationGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ElastiCacheReplicationGroupPaginator) NextPage(ctx context.Context) ([]ElastiCacheReplicationGroup, error) {
	var response ElastiCacheReplicationGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ElastiCacheReplicationGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listElastiCacheReplicationGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListElastiCacheReplicationGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListElastiCacheReplicationGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewElastiCacheReplicationGroupPaginator(buildFilter(d.KeyColumnQuals, listElastiCacheReplicationGroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getElastiCacheReplicationGroupFilters = map[string]string{
	"keibi_account_id":     "metadata.SourceID",
	"replication_group_id": "description.ReplicationGroup.ReplicationGroupId",
}

func GetElastiCacheReplicationGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetElastiCacheReplicationGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewElastiCacheReplicationGroupPaginator(buildFilter(d.KeyColumnQuals, getElastiCacheReplicationGroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ElastiCacheReplicationGroup =============================

// ==========================  START: ElastiCacheCluster =============================

type ElastiCacheCluster struct {
	Description   aws.ElastiCacheClusterDescription `json:"description"`
	Metadata      aws.Metadata                      `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

type ElastiCacheClusterHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  ElastiCacheCluster `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type ElastiCacheClusterHits struct {
	Total SearchTotal             `json:"total"`
	Hits  []ElastiCacheClusterHit `json:"hits"`
}

type ElastiCacheClusterSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  ElastiCacheClusterHits `json:"hits"`
}

type ElastiCacheClusterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewElastiCacheClusterPaginator(filters []BoolFilter, limit *int64) (ElastiCacheClusterPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticache_cluster", filters, limit)
	if err != nil {
		return ElastiCacheClusterPaginator{}, err
	}

	p := ElastiCacheClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ElastiCacheClusterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ElastiCacheClusterPaginator) NextPage(ctx context.Context) ([]ElastiCacheCluster, error) {
	var response ElastiCacheClusterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ElastiCacheCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listElastiCacheClusterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListElastiCacheCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListElastiCacheCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewElastiCacheClusterPaginator(buildFilter(d.KeyColumnQuals, listElastiCacheClusterFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getElastiCacheClusterFilters = map[string]string{
	"cache_cluster_id": "description.Cluster.CacheClusterId",
	"keibi_account_id": "metadata.SourceID",
}

func GetElastiCacheCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetElastiCacheCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewElastiCacheClusterPaginator(buildFilter(d.KeyColumnQuals, getElastiCacheClusterFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ElastiCacheCluster =============================

// ==========================  START: ElastiCacheParameterGroup =============================

type ElastiCacheParameterGroup struct {
	Description   aws.ElastiCacheParameterGroupDescription `json:"description"`
	Metadata      aws.Metadata                             `json:"metadata"`
	ResourceJobID int                                      `json:"resource_job_id"`
	SourceJobID   int                                      `json:"source_job_id"`
	ResourceType  string                                   `json:"resource_type"`
	SourceType    string                                   `json:"source_type"`
	ID            string                                   `json:"id"`
	ARN           string                                   `json:"arn"`
	SourceID      string                                   `json:"source_id"`
}

type ElastiCacheParameterGroupHit struct {
	ID      string                    `json:"_id"`
	Score   float64                   `json:"_score"`
	Index   string                    `json:"_index"`
	Type    string                    `json:"_type"`
	Version int64                     `json:"_version,omitempty"`
	Source  ElastiCacheParameterGroup `json:"_source"`
	Sort    []interface{}             `json:"sort"`
}

type ElastiCacheParameterGroupHits struct {
	Total SearchTotal                    `json:"total"`
	Hits  []ElastiCacheParameterGroupHit `json:"hits"`
}

type ElastiCacheParameterGroupSearchResponse struct {
	PitID string                        `json:"pit_id"`
	Hits  ElastiCacheParameterGroupHits `json:"hits"`
}

type ElastiCacheParameterGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewElastiCacheParameterGroupPaginator(filters []BoolFilter, limit *int64) (ElastiCacheParameterGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticache_parametergroup", filters, limit)
	if err != nil {
		return ElastiCacheParameterGroupPaginator{}, err
	}

	p := ElastiCacheParameterGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ElastiCacheParameterGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ElastiCacheParameterGroupPaginator) NextPage(ctx context.Context) ([]ElastiCacheParameterGroup, error) {
	var response ElastiCacheParameterGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ElastiCacheParameterGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listElastiCacheParameterGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListElastiCacheParameterGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListElastiCacheParameterGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewElastiCacheParameterGroupPaginator(buildFilter(d.KeyColumnQuals, listElastiCacheParameterGroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getElastiCacheParameterGroupFilters = map[string]string{
	"cache_parameter_group_name": "description.ParameterGroup.CacheParameterGroupName",
	"keibi_account_id":           "metadata.SourceID",
}

func GetElastiCacheParameterGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetElastiCacheParameterGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewElastiCacheParameterGroupPaginator(buildFilter(d.KeyColumnQuals, getElastiCacheParameterGroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ElastiCacheParameterGroup =============================

// ==========================  START: ElastiCacheReservedCacheNode =============================

type ElastiCacheReservedCacheNode struct {
	Description   aws.ElastiCacheReservedCacheNodeDescription `json:"description"`
	Metadata      aws.Metadata                                `json:"metadata"`
	ResourceJobID int                                         `json:"resource_job_id"`
	SourceJobID   int                                         `json:"source_job_id"`
	ResourceType  string                                      `json:"resource_type"`
	SourceType    string                                      `json:"source_type"`
	ID            string                                      `json:"id"`
	ARN           string                                      `json:"arn"`
	SourceID      string                                      `json:"source_id"`
}

type ElastiCacheReservedCacheNodeHit struct {
	ID      string                       `json:"_id"`
	Score   float64                      `json:"_score"`
	Index   string                       `json:"_index"`
	Type    string                       `json:"_type"`
	Version int64                        `json:"_version,omitempty"`
	Source  ElastiCacheReservedCacheNode `json:"_source"`
	Sort    []interface{}                `json:"sort"`
}

type ElastiCacheReservedCacheNodeHits struct {
	Total SearchTotal                       `json:"total"`
	Hits  []ElastiCacheReservedCacheNodeHit `json:"hits"`
}

type ElastiCacheReservedCacheNodeSearchResponse struct {
	PitID string                           `json:"pit_id"`
	Hits  ElastiCacheReservedCacheNodeHits `json:"hits"`
}

type ElastiCacheReservedCacheNodePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewElastiCacheReservedCacheNodePaginator(filters []BoolFilter, limit *int64) (ElastiCacheReservedCacheNodePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticache_reservedcachenode", filters, limit)
	if err != nil {
		return ElastiCacheReservedCacheNodePaginator{}, err
	}

	p := ElastiCacheReservedCacheNodePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ElastiCacheReservedCacheNodePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ElastiCacheReservedCacheNodePaginator) NextPage(ctx context.Context) ([]ElastiCacheReservedCacheNode, error) {
	var response ElastiCacheReservedCacheNodeSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ElastiCacheReservedCacheNode
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listElastiCacheReservedCacheNodeFilters = map[string]string{
	"cache_node_type":                  "description.ReservedCacheNode.CacheNodeType",
	"duration":                         "description.ReservedCacheNode.Duration",
	"keibi_account_id":                 "metadata.SourceID",
	"offering_type":                    "description.ReservedCacheNode.OfferingType",
	"reserved_cache_nodes_offering_id": "description.ReservedCacheNode.ReservedCacheNodesOfferingId",
}

func ListElastiCacheReservedCacheNode(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListElastiCacheReservedCacheNode")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewElastiCacheReservedCacheNodePaginator(buildFilter(d.KeyColumnQuals, listElastiCacheReservedCacheNodeFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getElastiCacheReservedCacheNodeFilters = map[string]string{
	"keibi_account_id":       "metadata.SourceID",
	"reserved_cache_node_id": "description.ReservedCacheNode.ReservedCacheNodeId",
}

func GetElastiCacheReservedCacheNode(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetElastiCacheReservedCacheNode")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewElastiCacheReservedCacheNodePaginator(buildFilter(d.KeyColumnQuals, getElastiCacheReservedCacheNodeFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ElastiCacheReservedCacheNode =============================

// ==========================  START: ElastiCacheSubnetGroup =============================

type ElastiCacheSubnetGroup struct {
	Description   aws.ElastiCacheSubnetGroupDescription `json:"description"`
	Metadata      aws.Metadata                          `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

type ElastiCacheSubnetGroupHit struct {
	ID      string                 `json:"_id"`
	Score   float64                `json:"_score"`
	Index   string                 `json:"_index"`
	Type    string                 `json:"_type"`
	Version int64                  `json:"_version,omitempty"`
	Source  ElastiCacheSubnetGroup `json:"_source"`
	Sort    []interface{}          `json:"sort"`
}

type ElastiCacheSubnetGroupHits struct {
	Total SearchTotal                 `json:"total"`
	Hits  []ElastiCacheSubnetGroupHit `json:"hits"`
}

type ElastiCacheSubnetGroupSearchResponse struct {
	PitID string                     `json:"pit_id"`
	Hits  ElastiCacheSubnetGroupHits `json:"hits"`
}

type ElastiCacheSubnetGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewElastiCacheSubnetGroupPaginator(filters []BoolFilter, limit *int64) (ElastiCacheSubnetGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticache_subnetgroup", filters, limit)
	if err != nil {
		return ElastiCacheSubnetGroupPaginator{}, err
	}

	p := ElastiCacheSubnetGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ElastiCacheSubnetGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ElastiCacheSubnetGroupPaginator) NextPage(ctx context.Context) ([]ElastiCacheSubnetGroup, error) {
	var response ElastiCacheSubnetGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ElastiCacheSubnetGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listElastiCacheSubnetGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListElastiCacheSubnetGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListElastiCacheSubnetGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewElastiCacheSubnetGroupPaginator(buildFilter(d.KeyColumnQuals, listElastiCacheSubnetGroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getElastiCacheSubnetGroupFilters = map[string]string{
	"cache_subnet_group_name": "description.SubnetGroup.CacheSubnetGroupName",
	"keibi_account_id":        "metadata.SourceID",
}

func GetElastiCacheSubnetGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetElastiCacheSubnetGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewElastiCacheSubnetGroupPaginator(buildFilter(d.KeyColumnQuals, getElastiCacheSubnetGroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ElastiCacheSubnetGroup =============================

// ==========================  START: ESDomain =============================

type ESDomain struct {
	Description   aws.ESDomainDescription `json:"description"`
	Metadata      aws.Metadata            `json:"metadata"`
	ResourceJobID int                     `json:"resource_job_id"`
	SourceJobID   int                     `json:"source_job_id"`
	ResourceType  string                  `json:"resource_type"`
	SourceType    string                  `json:"source_type"`
	ID            string                  `json:"id"`
	ARN           string                  `json:"arn"`
	SourceID      string                  `json:"source_id"`
}

type ESDomainHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  ESDomain      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type ESDomainHits struct {
	Total SearchTotal   `json:"total"`
	Hits  []ESDomainHit `json:"hits"`
}

type ESDomainSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  ESDomainHits `json:"hits"`
}

type ESDomainPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewESDomainPaginator(filters []BoolFilter, limit *int64) (ESDomainPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticsearch_domain", filters, limit)
	if err != nil {
		return ESDomainPaginator{}, err
	}

	p := ESDomainPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ESDomainPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ESDomainPaginator) NextPage(ctx context.Context) ([]ESDomain, error) {
	var response ESDomainSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ESDomain
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listESDomainFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListESDomain(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListESDomain")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewESDomainPaginator(buildFilter(d.KeyColumnQuals, listESDomainFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getESDomainFilters = map[string]string{
	"domain_name":      "description.Domain.DomainName",
	"keibi_account_id": "metadata.SourceID",
}

func GetESDomain(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetESDomain")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewESDomainPaginator(buildFilter(d.KeyColumnQuals, getESDomainFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ESDomain =============================

// ==========================  START: EMRCluster =============================

type EMRCluster struct {
	Description   aws.EMRClusterDescription `json:"description"`
	Metadata      aws.Metadata              `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	ARN           string                    `json:"arn"`
	SourceID      string                    `json:"source_id"`
}

type EMRClusterHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EMRCluster    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EMRClusterHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []EMRClusterHit `json:"hits"`
}

type EMRClusterSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  EMRClusterHits `json:"hits"`
}

type EMRClusterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEMRClusterPaginator(filters []BoolFilter, limit *int64) (EMRClusterPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_emr_cluster", filters, limit)
	if err != nil {
		return EMRClusterPaginator{}, err
	}

	p := EMRClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EMRClusterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EMRClusterPaginator) NextPage(ctx context.Context) ([]EMRCluster, error) {
	var response EMRClusterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EMRCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEMRClusterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEMRCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEMRCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEMRClusterPaginator(buildFilter(d.KeyColumnQuals, listEMRClusterFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEMRClusterFilters = map[string]string{
	"id":               "description.Cluster.Id",
	"keibi_account_id": "metadata.SourceID",
}

func GetEMRCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEMRCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEMRClusterPaginator(buildFilter(d.KeyColumnQuals, getEMRClusterFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EMRCluster =============================

// ==========================  START: EMRInstance =============================

type EMRInstance struct {
	Description   aws.EMRInstanceDescription `json:"description"`
	Metadata      aws.Metadata               `json:"metadata"`
	ResourceJobID int                        `json:"resource_job_id"`
	SourceJobID   int                        `json:"source_job_id"`
	ResourceType  string                     `json:"resource_type"`
	SourceType    string                     `json:"source_type"`
	ID            string                     `json:"id"`
	ARN           string                     `json:"arn"`
	SourceID      string                     `json:"source_id"`
}

type EMRInstanceHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EMRInstance   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EMRInstanceHits struct {
	Total SearchTotal      `json:"total"`
	Hits  []EMRInstanceHit `json:"hits"`
}

type EMRInstanceSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  EMRInstanceHits `json:"hits"`
}

type EMRInstancePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEMRInstancePaginator(filters []BoolFilter, limit *int64) (EMRInstancePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_emr_instance", filters, limit)
	if err != nil {
		return EMRInstancePaginator{}, err
	}

	p := EMRInstancePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EMRInstancePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EMRInstancePaginator) NextPage(ctx context.Context) ([]EMRInstance, error) {
	var response EMRInstanceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EMRInstance
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEMRInstanceFilters = map[string]string{
	"cluster_id":        "description.ClusterID",
	"instance_fleet_id": "description.Instance.InstanceFleetId",
	"instance_group_id": "description.Instance.InstanceGroupId",
	"keibi_account_id":  "metadata.SourceID",
}

func ListEMRInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEMRInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEMRInstancePaginator(buildFilter(d.KeyColumnQuals, listEMRInstanceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEMRInstanceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetEMRInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEMRInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEMRInstancePaginator(buildFilter(d.KeyColumnQuals, getEMRInstanceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EMRInstance =============================

// ==========================  START: EMRInstanceFleet =============================

type EMRInstanceFleet struct {
	Description   aws.EMRInstanceFleetDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type EMRInstanceFleetHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  EMRInstanceFleet `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type EMRInstanceFleetHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []EMRInstanceFleetHit `json:"hits"`
}

type EMRInstanceFleetSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  EMRInstanceFleetHits `json:"hits"`
}

type EMRInstanceFleetPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEMRInstanceFleetPaginator(filters []BoolFilter, limit *int64) (EMRInstanceFleetPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_emr_instancefleet", filters, limit)
	if err != nil {
		return EMRInstanceFleetPaginator{}, err
	}

	p := EMRInstanceFleetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EMRInstanceFleetPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EMRInstanceFleetPaginator) NextPage(ctx context.Context) ([]EMRInstanceFleet, error) {
	var response EMRInstanceFleetSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EMRInstanceFleet
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEMRInstanceFleetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEMRInstanceFleet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEMRInstanceFleet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEMRInstanceFleetPaginator(buildFilter(d.KeyColumnQuals, listEMRInstanceFleetFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEMRInstanceFleetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetEMRInstanceFleet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEMRInstanceFleet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEMRInstanceFleetPaginator(buildFilter(d.KeyColumnQuals, getEMRInstanceFleetFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EMRInstanceFleet =============================

// ==========================  START: EMRInstanceGroup =============================

type EMRInstanceGroup struct {
	Description   aws.EMRInstanceGroupDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type EMRInstanceGroupHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  EMRInstanceGroup `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type EMRInstanceGroupHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []EMRInstanceGroupHit `json:"hits"`
}

type EMRInstanceGroupSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  EMRInstanceGroupHits `json:"hits"`
}

type EMRInstanceGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEMRInstanceGroupPaginator(filters []BoolFilter, limit *int64) (EMRInstanceGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_emr_instancegroup", filters, limit)
	if err != nil {
		return EMRInstanceGroupPaginator{}, err
	}

	p := EMRInstanceGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EMRInstanceGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EMRInstanceGroupPaginator) NextPage(ctx context.Context) ([]EMRInstanceGroup, error) {
	var response EMRInstanceGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EMRInstanceGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEMRInstanceGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEMRInstanceGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEMRInstanceGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEMRInstanceGroupPaginator(buildFilter(d.KeyColumnQuals, listEMRInstanceGroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEMRInstanceGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetEMRInstanceGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEMRInstanceGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEMRInstanceGroupPaginator(buildFilter(d.KeyColumnQuals, getEMRInstanceGroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EMRInstanceGroup =============================

// ==========================  START: GuardDutyFinding =============================

type GuardDutyFinding struct {
	Description   aws.GuardDutyFindingDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type GuardDutyFindingHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  GuardDutyFinding `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type GuardDutyFindingHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []GuardDutyFindingHit `json:"hits"`
}

type GuardDutyFindingSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  GuardDutyFindingHits `json:"hits"`
}

type GuardDutyFindingPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewGuardDutyFindingPaginator(filters []BoolFilter, limit *int64) (GuardDutyFindingPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_guardduty_finding", filters, limit)
	if err != nil {
		return GuardDutyFindingPaginator{}, err
	}

	p := GuardDutyFindingPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p GuardDutyFindingPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p GuardDutyFindingPaginator) NextPage(ctx context.Context) ([]GuardDutyFinding, error) {
	var response GuardDutyFindingSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []GuardDutyFinding
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listGuardDutyFindingFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListGuardDutyFinding(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListGuardDutyFinding")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewGuardDutyFindingPaginator(buildFilter(d.KeyColumnQuals, listGuardDutyFindingFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getGuardDutyFindingFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetGuardDutyFinding(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetGuardDutyFinding")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewGuardDutyFindingPaginator(buildFilter(d.KeyColumnQuals, getGuardDutyFindingFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: GuardDutyFinding =============================

// ==========================  START: GuardDutyDetector =============================

type GuardDutyDetector struct {
	Description   aws.GuardDutyDetectorDescription `json:"description"`
	Metadata      aws.Metadata                     `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

type GuardDutyDetectorHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  GuardDutyDetector `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type GuardDutyDetectorHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []GuardDutyDetectorHit `json:"hits"`
}

type GuardDutyDetectorSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  GuardDutyDetectorHits `json:"hits"`
}

type GuardDutyDetectorPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewGuardDutyDetectorPaginator(filters []BoolFilter, limit *int64) (GuardDutyDetectorPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_guardduty_detector", filters, limit)
	if err != nil {
		return GuardDutyDetectorPaginator{}, err
	}

	p := GuardDutyDetectorPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p GuardDutyDetectorPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p GuardDutyDetectorPaginator) NextPage(ctx context.Context) ([]GuardDutyDetector, error) {
	var response GuardDutyDetectorSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []GuardDutyDetector
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listGuardDutyDetectorFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListGuardDutyDetector(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListGuardDutyDetector")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewGuardDutyDetectorPaginator(buildFilter(d.KeyColumnQuals, listGuardDutyDetectorFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getGuardDutyDetectorFilters = map[string]string{
	"detector_id":      "description.DetectorId",
	"keibi_account_id": "metadata.SourceID",
}

func GetGuardDutyDetector(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetGuardDutyDetector")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewGuardDutyDetectorPaginator(buildFilter(d.KeyColumnQuals, getGuardDutyDetectorFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: GuardDutyDetector =============================

// ==========================  START: GuardDutyFilter =============================

type GuardDutyFilter struct {
	Description   aws.GuardDutyFilterDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type GuardDutyFilterHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  GuardDutyFilter `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type GuardDutyFilterHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []GuardDutyFilterHit `json:"hits"`
}

type GuardDutyFilterSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  GuardDutyFilterHits `json:"hits"`
}

type GuardDutyFilterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewGuardDutyFilterPaginator(filters []BoolFilter, limit *int64) (GuardDutyFilterPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_guardduty_filter", filters, limit)
	if err != nil {
		return GuardDutyFilterPaginator{}, err
	}

	p := GuardDutyFilterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p GuardDutyFilterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p GuardDutyFilterPaginator) NextPage(ctx context.Context) ([]GuardDutyFilter, error) {
	var response GuardDutyFilterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []GuardDutyFilter
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listGuardDutyFilterFilters = map[string]string{
	"detector_id":      "description.DetectorId",
	"keibi_account_id": "metadata.SourceID",
}

func ListGuardDutyFilter(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListGuardDutyFilter")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewGuardDutyFilterPaginator(buildFilter(d.KeyColumnQuals, listGuardDutyFilterFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getGuardDutyFilterFilters = map[string]string{
	"detector_id":      "description.DetectorId",
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Filter.Name",
}

func GetGuardDutyFilter(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetGuardDutyFilter")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewGuardDutyFilterPaginator(buildFilter(d.KeyColumnQuals, getGuardDutyFilterFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: GuardDutyFilter =============================

// ==========================  START: GuardDutyIPSet =============================

type GuardDutyIPSet struct {
	Description   aws.GuardDutyIPSetDescription `json:"description"`
	Metadata      aws.Metadata                  `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

type GuardDutyIPSetHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  GuardDutyIPSet `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type GuardDutyIPSetHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []GuardDutyIPSetHit `json:"hits"`
}

type GuardDutyIPSetSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  GuardDutyIPSetHits `json:"hits"`
}

type GuardDutyIPSetPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewGuardDutyIPSetPaginator(filters []BoolFilter, limit *int64) (GuardDutyIPSetPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_guardduty_ipset", filters, limit)
	if err != nil {
		return GuardDutyIPSetPaginator{}, err
	}

	p := GuardDutyIPSetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p GuardDutyIPSetPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p GuardDutyIPSetPaginator) NextPage(ctx context.Context) ([]GuardDutyIPSet, error) {
	var response GuardDutyIPSetSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []GuardDutyIPSet
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listGuardDutyIPSetFilters = map[string]string{
	"detector_id":      "description.DetectorId",
	"keibi_account_id": "metadata.SourceID",
}

func ListGuardDutyIPSet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListGuardDutyIPSet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewGuardDutyIPSetPaginator(buildFilter(d.KeyColumnQuals, listGuardDutyIPSetFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getGuardDutyIPSetFilters = map[string]string{
	"detector_id":      "description.DetectorId",
	"ipset_id":         "description.IPSetId",
	"keibi_account_id": "metadata.SourceID",
}

func GetGuardDutyIPSet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetGuardDutyIPSet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewGuardDutyIPSetPaginator(buildFilter(d.KeyColumnQuals, getGuardDutyIPSetFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: GuardDutyIPSet =============================

// ==========================  START: GuardDutyMember =============================

type GuardDutyMember struct {
	Description   aws.GuardDutyMemberDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type GuardDutyMemberHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  GuardDutyMember `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type GuardDutyMemberHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []GuardDutyMemberHit `json:"hits"`
}

type GuardDutyMemberSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  GuardDutyMemberHits `json:"hits"`
}

type GuardDutyMemberPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewGuardDutyMemberPaginator(filters []BoolFilter, limit *int64) (GuardDutyMemberPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_guardduty_member", filters, limit)
	if err != nil {
		return GuardDutyMemberPaginator{}, err
	}

	p := GuardDutyMemberPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p GuardDutyMemberPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p GuardDutyMemberPaginator) NextPage(ctx context.Context) ([]GuardDutyMember, error) {
	var response GuardDutyMemberSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []GuardDutyMember
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listGuardDutyMemberFilters = map[string]string{
	"detector_id":      "description.Member.DetectorId",
	"keibi_account_id": "metadata.SourceID",
}

func ListGuardDutyMember(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListGuardDutyMember")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewGuardDutyMemberPaginator(buildFilter(d.KeyColumnQuals, listGuardDutyMemberFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getGuardDutyMemberFilters = map[string]string{
	"detector_id":       "description.Member.DetectorId",
	"keibi_account_id":  "metadata.SourceID",
	"member_account_id": "description.Member.AccountId",
}

func GetGuardDutyMember(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetGuardDutyMember")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewGuardDutyMemberPaginator(buildFilter(d.KeyColumnQuals, getGuardDutyMemberFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: GuardDutyMember =============================

// ==========================  START: GuardDutyPublishingDestination =============================

type GuardDutyPublishingDestination struct {
	Description   aws.GuardDutyPublishingDestinationDescription `json:"description"`
	Metadata      aws.Metadata                                  `json:"metadata"`
	ResourceJobID int                                           `json:"resource_job_id"`
	SourceJobID   int                                           `json:"source_job_id"`
	ResourceType  string                                        `json:"resource_type"`
	SourceType    string                                        `json:"source_type"`
	ID            string                                        `json:"id"`
	ARN           string                                        `json:"arn"`
	SourceID      string                                        `json:"source_id"`
}

type GuardDutyPublishingDestinationHit struct {
	ID      string                         `json:"_id"`
	Score   float64                        `json:"_score"`
	Index   string                         `json:"_index"`
	Type    string                         `json:"_type"`
	Version int64                          `json:"_version,omitempty"`
	Source  GuardDutyPublishingDestination `json:"_source"`
	Sort    []interface{}                  `json:"sort"`
}

type GuardDutyPublishingDestinationHits struct {
	Total SearchTotal                         `json:"total"`
	Hits  []GuardDutyPublishingDestinationHit `json:"hits"`
}

type GuardDutyPublishingDestinationSearchResponse struct {
	PitID string                             `json:"pit_id"`
	Hits  GuardDutyPublishingDestinationHits `json:"hits"`
}

type GuardDutyPublishingDestinationPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewGuardDutyPublishingDestinationPaginator(filters []BoolFilter, limit *int64) (GuardDutyPublishingDestinationPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_guardduty_publishingdestination", filters, limit)
	if err != nil {
		return GuardDutyPublishingDestinationPaginator{}, err
	}

	p := GuardDutyPublishingDestinationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p GuardDutyPublishingDestinationPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p GuardDutyPublishingDestinationPaginator) NextPage(ctx context.Context) ([]GuardDutyPublishingDestination, error) {
	var response GuardDutyPublishingDestinationSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []GuardDutyPublishingDestination
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listGuardDutyPublishingDestinationFilters = map[string]string{
	"detector_id":      "description.DetectorId",
	"keibi_account_id": "metadata.SourceID",
}

func ListGuardDutyPublishingDestination(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListGuardDutyPublishingDestination")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewGuardDutyPublishingDestinationPaginator(buildFilter(d.KeyColumnQuals, listGuardDutyPublishingDestinationFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getGuardDutyPublishingDestinationFilters = map[string]string{
	"destination_id":   "description.PublishingDestination.DestinationId",
	"detector_id":      "description.DetectorId",
	"keibi_account_id": "metadata.SourceID",
}

func GetGuardDutyPublishingDestination(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetGuardDutyPublishingDestination")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewGuardDutyPublishingDestinationPaginator(buildFilter(d.KeyColumnQuals, getGuardDutyPublishingDestinationFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: GuardDutyPublishingDestination =============================

// ==========================  START: GuardDutyThreatIntelSet =============================

type GuardDutyThreatIntelSet struct {
	Description   aws.GuardDutyThreatIntelSetDescription `json:"description"`
	Metadata      aws.Metadata                           `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

type GuardDutyThreatIntelSetHit struct {
	ID      string                  `json:"_id"`
	Score   float64                 `json:"_score"`
	Index   string                  `json:"_index"`
	Type    string                  `json:"_type"`
	Version int64                   `json:"_version,omitempty"`
	Source  GuardDutyThreatIntelSet `json:"_source"`
	Sort    []interface{}           `json:"sort"`
}

type GuardDutyThreatIntelSetHits struct {
	Total SearchTotal                  `json:"total"`
	Hits  []GuardDutyThreatIntelSetHit `json:"hits"`
}

type GuardDutyThreatIntelSetSearchResponse struct {
	PitID string                      `json:"pit_id"`
	Hits  GuardDutyThreatIntelSetHits `json:"hits"`
}

type GuardDutyThreatIntelSetPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewGuardDutyThreatIntelSetPaginator(filters []BoolFilter, limit *int64) (GuardDutyThreatIntelSetPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_guardduty_threatintelset", filters, limit)
	if err != nil {
		return GuardDutyThreatIntelSetPaginator{}, err
	}

	p := GuardDutyThreatIntelSetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p GuardDutyThreatIntelSetPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p GuardDutyThreatIntelSetPaginator) NextPage(ctx context.Context) ([]GuardDutyThreatIntelSet, error) {
	var response GuardDutyThreatIntelSetSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []GuardDutyThreatIntelSet
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listGuardDutyThreatIntelSetFilters = map[string]string{
	"detector_id":      "description.DetectorId",
	"keibi_account_id": "metadata.SourceID",
}

func ListGuardDutyThreatIntelSet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListGuardDutyThreatIntelSet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewGuardDutyThreatIntelSetPaginator(buildFilter(d.KeyColumnQuals, listGuardDutyThreatIntelSetFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getGuardDutyThreatIntelSetFilters = map[string]string{
	"detector_id":         "description.DetectorId",
	"keibi_account_id":    "metadata.SourceID",
	"threat_intel_set_id": "description.ThreatIntelSetID",
}

func GetGuardDutyThreatIntelSet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetGuardDutyThreatIntelSet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewGuardDutyThreatIntelSetPaginator(buildFilter(d.KeyColumnQuals, getGuardDutyThreatIntelSetFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: GuardDutyThreatIntelSet =============================

// ==========================  START: BackupPlan =============================

type BackupPlan struct {
	Description   aws.BackupPlanDescription `json:"description"`
	Metadata      aws.Metadata              `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	ARN           string                    `json:"arn"`
	SourceID      string                    `json:"source_id"`
}

type BackupPlanHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  BackupPlan    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type BackupPlanHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []BackupPlanHit `json:"hits"`
}

type BackupPlanSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  BackupPlanHits `json:"hits"`
}

type BackupPlanPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewBackupPlanPaginator(filters []BoolFilter, limit *int64) (BackupPlanPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_backup_plan", filters, limit)
	if err != nil {
		return BackupPlanPaginator{}, err
	}

	p := BackupPlanPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p BackupPlanPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p BackupPlanPaginator) NextPage(ctx context.Context) ([]BackupPlan, error) {
	var response BackupPlanSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []BackupPlan
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listBackupPlanFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListBackupPlan(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListBackupPlan")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewBackupPlanPaginator(buildFilter(d.KeyColumnQuals, listBackupPlanFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getBackupPlanFilters = map[string]string{
	"backup_plan_id":   "description.BackupPlan.BackupPlanId",
	"keibi_account_id": "metadata.SourceID",
}

func GetBackupPlan(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetBackupPlan")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewBackupPlanPaginator(buildFilter(d.KeyColumnQuals, getBackupPlanFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: BackupPlan =============================

// ==========================  START: BackupSelection =============================

type BackupSelection struct {
	Description   aws.BackupSelectionDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type BackupSelectionHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  BackupSelection `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type BackupSelectionHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []BackupSelectionHit `json:"hits"`
}

type BackupSelectionSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  BackupSelectionHits `json:"hits"`
}

type BackupSelectionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewBackupSelectionPaginator(filters []BoolFilter, limit *int64) (BackupSelectionPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_backup_selection", filters, limit)
	if err != nil {
		return BackupSelectionPaginator{}, err
	}

	p := BackupSelectionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p BackupSelectionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p BackupSelectionPaginator) NextPage(ctx context.Context) ([]BackupSelection, error) {
	var response BackupSelectionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []BackupSelection
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listBackupSelectionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListBackupSelection(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListBackupSelection")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewBackupSelectionPaginator(buildFilter(d.KeyColumnQuals, listBackupSelectionFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getBackupSelectionFilters = map[string]string{
	"backup_plan_id":   "description.BackupSelection.BackupPlanId",
	"keibi_account_id": "metadata.SourceID",
	"selection_id":     "description.BackupSelection.SelectionId",
}

func GetBackupSelection(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetBackupSelection")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewBackupSelectionPaginator(buildFilter(d.KeyColumnQuals, getBackupSelectionFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: BackupSelection =============================

// ==========================  START: BackupVault =============================

type BackupVault struct {
	Description   aws.BackupVaultDescription `json:"description"`
	Metadata      aws.Metadata               `json:"metadata"`
	ResourceJobID int                        `json:"resource_job_id"`
	SourceJobID   int                        `json:"source_job_id"`
	ResourceType  string                     `json:"resource_type"`
	SourceType    string                     `json:"source_type"`
	ID            string                     `json:"id"`
	ARN           string                     `json:"arn"`
	SourceID      string                     `json:"source_id"`
}

type BackupVaultHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  BackupVault   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type BackupVaultHits struct {
	Total SearchTotal      `json:"total"`
	Hits  []BackupVaultHit `json:"hits"`
}

type BackupVaultSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  BackupVaultHits `json:"hits"`
}

type BackupVaultPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewBackupVaultPaginator(filters []BoolFilter, limit *int64) (BackupVaultPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_backup_vault", filters, limit)
	if err != nil {
		return BackupVaultPaginator{}, err
	}

	p := BackupVaultPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p BackupVaultPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p BackupVaultPaginator) NextPage(ctx context.Context) ([]BackupVault, error) {
	var response BackupVaultSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []BackupVault
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listBackupVaultFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListBackupVault(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListBackupVault")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewBackupVaultPaginator(buildFilter(d.KeyColumnQuals, listBackupVaultFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getBackupVaultFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.BackupVault.BackupVaultName",
}

func GetBackupVault(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetBackupVault")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewBackupVaultPaginator(buildFilter(d.KeyColumnQuals, getBackupVaultFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: BackupVault =============================

// ==========================  START: BackupRecoveryPoint =============================

type BackupRecoveryPoint struct {
	Description   aws.BackupRecoveryPointDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type BackupRecoveryPointHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  BackupRecoveryPoint `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type BackupRecoveryPointHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []BackupRecoveryPointHit `json:"hits"`
}

type BackupRecoveryPointSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  BackupRecoveryPointHits `json:"hits"`
}

type BackupRecoveryPointPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewBackupRecoveryPointPaginator(filters []BoolFilter, limit *int64) (BackupRecoveryPointPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_backup_recoverypoint", filters, limit)
	if err != nil {
		return BackupRecoveryPointPaginator{}, err
	}

	p := BackupRecoveryPointPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p BackupRecoveryPointPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p BackupRecoveryPointPaginator) NextPage(ctx context.Context) ([]BackupRecoveryPoint, error) {
	var response BackupRecoveryPointSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []BackupRecoveryPoint
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listBackupRecoveryPointFilters = map[string]string{
	"completion_date":    "description.RecoveryPoint.CompletionDate",
	"keibi_account_id":   "metadata.SourceID",
	"recovery_point_arn": "description.RecoveryPoint.RecoveryPointArn",
	"resource_type":      "description.RecoveryPoint.ResourceType",
}

func ListBackupRecoveryPoint(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListBackupRecoveryPoint")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewBackupRecoveryPointPaginator(buildFilter(d.KeyColumnQuals, listBackupRecoveryPointFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getBackupRecoveryPointFilters = map[string]string{
	"backup_vault_name":  "description.RecoveryPoint.BackupVaultName",
	"keibi_account_id":   "metadata.SourceID",
	"recovery_point_arn": "description.RecoveryPoint.RecoveryPointArn",
}

func GetBackupRecoveryPoint(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetBackupRecoveryPoint")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewBackupRecoveryPointPaginator(buildFilter(d.KeyColumnQuals, getBackupRecoveryPointFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: BackupRecoveryPoint =============================

// ==========================  START: BackupProtectedResource =============================

type BackupProtectedResource struct {
	Description   aws.BackupProtectedResourceDescription `json:"description"`
	Metadata      aws.Metadata                           `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

type BackupProtectedResourceHit struct {
	ID      string                  `json:"_id"`
	Score   float64                 `json:"_score"`
	Index   string                  `json:"_index"`
	Type    string                  `json:"_type"`
	Version int64                   `json:"_version,omitempty"`
	Source  BackupProtectedResource `json:"_source"`
	Sort    []interface{}           `json:"sort"`
}

type BackupProtectedResourceHits struct {
	Total SearchTotal                  `json:"total"`
	Hits  []BackupProtectedResourceHit `json:"hits"`
}

type BackupProtectedResourceSearchResponse struct {
	PitID string                      `json:"pit_id"`
	Hits  BackupProtectedResourceHits `json:"hits"`
}

type BackupProtectedResourcePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewBackupProtectedResourcePaginator(filters []BoolFilter, limit *int64) (BackupProtectedResourcePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_backup_protectedresource", filters, limit)
	if err != nil {
		return BackupProtectedResourcePaginator{}, err
	}

	p := BackupProtectedResourcePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p BackupProtectedResourcePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p BackupProtectedResourcePaginator) NextPage(ctx context.Context) ([]BackupProtectedResource, error) {
	var response BackupProtectedResourceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []BackupProtectedResource
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listBackupProtectedResourceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListBackupProtectedResource(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListBackupProtectedResource")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewBackupProtectedResourcePaginator(buildFilter(d.KeyColumnQuals, listBackupProtectedResourceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getBackupProtectedResourceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"resource_arn":     "description.ProtectedResource.ResourceArn",
}

func GetBackupProtectedResource(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetBackupProtectedResource")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewBackupProtectedResourcePaginator(buildFilter(d.KeyColumnQuals, getBackupProtectedResourceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: BackupProtectedResource =============================

// ==========================  START: BackupFramework =============================

type BackupFramework struct {
	Description   aws.BackupFrameworkDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type BackupFrameworkHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  BackupFramework `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type BackupFrameworkHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []BackupFrameworkHit `json:"hits"`
}

type BackupFrameworkSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  BackupFrameworkHits `json:"hits"`
}

type BackupFrameworkPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewBackupFrameworkPaginator(filters []BoolFilter, limit *int64) (BackupFrameworkPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_backup_framework", filters, limit)
	if err != nil {
		return BackupFrameworkPaginator{}, err
	}

	p := BackupFrameworkPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p BackupFrameworkPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p BackupFrameworkPaginator) NextPage(ctx context.Context) ([]BackupFramework, error) {
	var response BackupFrameworkSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []BackupFramework
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listBackupFrameworkFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListBackupFramework(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListBackupFramework")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewBackupFrameworkPaginator(buildFilter(d.KeyColumnQuals, listBackupFrameworkFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getBackupFrameworkFilters = map[string]string{
	"framework_name":   "description.Framework.FrameworkName",
	"keibi_account_id": "metadata.SourceID",
}

func GetBackupFramework(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetBackupFramework")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewBackupFrameworkPaginator(buildFilter(d.KeyColumnQuals, getBackupFrameworkFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: BackupFramework =============================

// ==========================  START: BackupLegalHold =============================

type BackupLegalHold struct {
	Description   aws.BackupLegalHoldDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type BackupLegalHoldHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  BackupLegalHold `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type BackupLegalHoldHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []BackupLegalHoldHit `json:"hits"`
}

type BackupLegalHoldSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  BackupLegalHoldHits `json:"hits"`
}

type BackupLegalHoldPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewBackupLegalHoldPaginator(filters []BoolFilter, limit *int64) (BackupLegalHoldPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_backup_legalhold", filters, limit)
	if err != nil {
		return BackupLegalHoldPaginator{}, err
	}

	p := BackupLegalHoldPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p BackupLegalHoldPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p BackupLegalHoldPaginator) NextPage(ctx context.Context) ([]BackupLegalHold, error) {
	var response BackupLegalHoldSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []BackupLegalHold
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listBackupLegalHoldFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListBackupLegalHold(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListBackupLegalHold")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewBackupLegalHoldPaginator(buildFilter(d.KeyColumnQuals, listBackupLegalHoldFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getBackupLegalHoldFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"legal_hold_id":    "description.Framework.LegalHoldId",
}

func GetBackupLegalHold(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetBackupLegalHold")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewBackupLegalHoldPaginator(buildFilter(d.KeyColumnQuals, getBackupLegalHoldFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: BackupLegalHold =============================

// ==========================  START: CloudFrontDistribution =============================

type CloudFrontDistribution struct {
	Description   aws.CloudFrontDistributionDescription `json:"description"`
	Metadata      aws.Metadata                          `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

type CloudFrontDistributionHit struct {
	ID      string                 `json:"_id"`
	Score   float64                `json:"_score"`
	Index   string                 `json:"_index"`
	Type    string                 `json:"_type"`
	Version int64                  `json:"_version,omitempty"`
	Source  CloudFrontDistribution `json:"_source"`
	Sort    []interface{}          `json:"sort"`
}

type CloudFrontDistributionHits struct {
	Total SearchTotal                 `json:"total"`
	Hits  []CloudFrontDistributionHit `json:"hits"`
}

type CloudFrontDistributionSearchResponse struct {
	PitID string                     `json:"pit_id"`
	Hits  CloudFrontDistributionHits `json:"hits"`
}

type CloudFrontDistributionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudFrontDistributionPaginator(filters []BoolFilter, limit *int64) (CloudFrontDistributionPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudfront_distribution", filters, limit)
	if err != nil {
		return CloudFrontDistributionPaginator{}, err
	}

	p := CloudFrontDistributionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudFrontDistributionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudFrontDistributionPaginator) NextPage(ctx context.Context) ([]CloudFrontDistribution, error) {
	var response CloudFrontDistributionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudFrontDistribution
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudFrontDistributionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCloudFrontDistribution(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudFrontDistribution")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudFrontDistributionPaginator(buildFilter(d.KeyColumnQuals, listCloudFrontDistributionFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudFrontDistributionFilters = map[string]string{
	"id":               "description.Distribution.Id",
	"keibi_account_id": "metadata.SourceID",
}

func GetCloudFrontDistribution(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudFrontDistribution")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudFrontDistributionPaginator(buildFilter(d.KeyColumnQuals, getCloudFrontDistributionFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudFrontDistribution =============================

// ==========================  START: CloudFrontOriginAccessControl =============================

type CloudFrontOriginAccessControl struct {
	Description   aws.CloudFrontOriginAccessControlDescription `json:"description"`
	Metadata      aws.Metadata                                 `json:"metadata"`
	ResourceJobID int                                          `json:"resource_job_id"`
	SourceJobID   int                                          `json:"source_job_id"`
	ResourceType  string                                       `json:"resource_type"`
	SourceType    string                                       `json:"source_type"`
	ID            string                                       `json:"id"`
	ARN           string                                       `json:"arn"`
	SourceID      string                                       `json:"source_id"`
}

type CloudFrontOriginAccessControlHit struct {
	ID      string                        `json:"_id"`
	Score   float64                       `json:"_score"`
	Index   string                        `json:"_index"`
	Type    string                        `json:"_type"`
	Version int64                         `json:"_version,omitempty"`
	Source  CloudFrontOriginAccessControl `json:"_source"`
	Sort    []interface{}                 `json:"sort"`
}

type CloudFrontOriginAccessControlHits struct {
	Total SearchTotal                        `json:"total"`
	Hits  []CloudFrontOriginAccessControlHit `json:"hits"`
}

type CloudFrontOriginAccessControlSearchResponse struct {
	PitID string                            `json:"pit_id"`
	Hits  CloudFrontOriginAccessControlHits `json:"hits"`
}

type CloudFrontOriginAccessControlPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudFrontOriginAccessControlPaginator(filters []BoolFilter, limit *int64) (CloudFrontOriginAccessControlPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudfront_originaccesscontrol", filters, limit)
	if err != nil {
		return CloudFrontOriginAccessControlPaginator{}, err
	}

	p := CloudFrontOriginAccessControlPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudFrontOriginAccessControlPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudFrontOriginAccessControlPaginator) NextPage(ctx context.Context) ([]CloudFrontOriginAccessControl, error) {
	var response CloudFrontOriginAccessControlSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudFrontOriginAccessControl
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudFrontOriginAccessControlFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCloudFrontOriginAccessControl(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudFrontOriginAccessControl")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudFrontOriginAccessControlPaginator(buildFilter(d.KeyColumnQuals, listCloudFrontOriginAccessControlFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudFrontOriginAccessControlFilters = map[string]string{
	"id":               "description.OriginAccessControl.Id",
	"keibi_account_id": "metadata.SourceID",
}

func GetCloudFrontOriginAccessControl(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudFrontOriginAccessControl")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudFrontOriginAccessControlPaginator(buildFilter(d.KeyColumnQuals, getCloudFrontOriginAccessControlFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudFrontOriginAccessControl =============================

// ==========================  START: CloudFrontCachePolicy =============================

type CloudFrontCachePolicy struct {
	Description   aws.CloudFrontCachePolicyDescription `json:"description"`
	Metadata      aws.Metadata                         `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

type CloudFrontCachePolicyHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  CloudFrontCachePolicy `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type CloudFrontCachePolicyHits struct {
	Total SearchTotal                `json:"total"`
	Hits  []CloudFrontCachePolicyHit `json:"hits"`
}

type CloudFrontCachePolicySearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  CloudFrontCachePolicyHits `json:"hits"`
}

type CloudFrontCachePolicyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudFrontCachePolicyPaginator(filters []BoolFilter, limit *int64) (CloudFrontCachePolicyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudfront_cachepolicy", filters, limit)
	if err != nil {
		return CloudFrontCachePolicyPaginator{}, err
	}

	p := CloudFrontCachePolicyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudFrontCachePolicyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudFrontCachePolicyPaginator) NextPage(ctx context.Context) ([]CloudFrontCachePolicy, error) {
	var response CloudFrontCachePolicySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudFrontCachePolicy
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudFrontCachePolicyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCloudFrontCachePolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudFrontCachePolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudFrontCachePolicyPaginator(buildFilter(d.KeyColumnQuals, listCloudFrontCachePolicyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudFrontCachePolicyFilters = map[string]string{
	"id":               "description.CachePolicy.Id",
	"keibi_account_id": "metadata.SourceID",
}

func GetCloudFrontCachePolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudFrontCachePolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudFrontCachePolicyPaginator(buildFilter(d.KeyColumnQuals, getCloudFrontCachePolicyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudFrontCachePolicy =============================

// ==========================  START: CloudFrontFunction =============================

type CloudFrontFunction struct {
	Description   aws.CloudFrontFunctionDescription `json:"description"`
	Metadata      aws.Metadata                      `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

type CloudFrontFunctionHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  CloudFrontFunction `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type CloudFrontFunctionHits struct {
	Total SearchTotal             `json:"total"`
	Hits  []CloudFrontFunctionHit `json:"hits"`
}

type CloudFrontFunctionSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  CloudFrontFunctionHits `json:"hits"`
}

type CloudFrontFunctionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudFrontFunctionPaginator(filters []BoolFilter, limit *int64) (CloudFrontFunctionPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudfront_function", filters, limit)
	if err != nil {
		return CloudFrontFunctionPaginator{}, err
	}

	p := CloudFrontFunctionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudFrontFunctionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudFrontFunctionPaginator) NextPage(ctx context.Context) ([]CloudFrontFunction, error) {
	var response CloudFrontFunctionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudFrontFunction
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudFrontFunctionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCloudFrontFunction(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudFrontFunction")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudFrontFunctionPaginator(buildFilter(d.KeyColumnQuals, listCloudFrontFunctionFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudFrontFunctionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Function.FunctionSummary.Name",
}

func GetCloudFrontFunction(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudFrontFunction")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudFrontFunctionPaginator(buildFilter(d.KeyColumnQuals, getCloudFrontFunctionFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudFrontFunction =============================

// ==========================  START: CloudFrontOriginAccessIdentity =============================

type CloudFrontOriginAccessIdentity struct {
	Description   aws.CloudFrontOriginAccessIdentityDescription `json:"description"`
	Metadata      aws.Metadata                                  `json:"metadata"`
	ResourceJobID int                                           `json:"resource_job_id"`
	SourceJobID   int                                           `json:"source_job_id"`
	ResourceType  string                                        `json:"resource_type"`
	SourceType    string                                        `json:"source_type"`
	ID            string                                        `json:"id"`
	ARN           string                                        `json:"arn"`
	SourceID      string                                        `json:"source_id"`
}

type CloudFrontOriginAccessIdentityHit struct {
	ID      string                         `json:"_id"`
	Score   float64                        `json:"_score"`
	Index   string                         `json:"_index"`
	Type    string                         `json:"_type"`
	Version int64                          `json:"_version,omitempty"`
	Source  CloudFrontOriginAccessIdentity `json:"_source"`
	Sort    []interface{}                  `json:"sort"`
}

type CloudFrontOriginAccessIdentityHits struct {
	Total SearchTotal                         `json:"total"`
	Hits  []CloudFrontOriginAccessIdentityHit `json:"hits"`
}

type CloudFrontOriginAccessIdentitySearchResponse struct {
	PitID string                             `json:"pit_id"`
	Hits  CloudFrontOriginAccessIdentityHits `json:"hits"`
}

type CloudFrontOriginAccessIdentityPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudFrontOriginAccessIdentityPaginator(filters []BoolFilter, limit *int64) (CloudFrontOriginAccessIdentityPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudfront_originaccessidentity", filters, limit)
	if err != nil {
		return CloudFrontOriginAccessIdentityPaginator{}, err
	}

	p := CloudFrontOriginAccessIdentityPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudFrontOriginAccessIdentityPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudFrontOriginAccessIdentityPaginator) NextPage(ctx context.Context) ([]CloudFrontOriginAccessIdentity, error) {
	var response CloudFrontOriginAccessIdentitySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudFrontOriginAccessIdentity
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudFrontOriginAccessIdentityFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCloudFrontOriginAccessIdentity(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudFrontOriginAccessIdentity")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudFrontOriginAccessIdentityPaginator(buildFilter(d.KeyColumnQuals, listCloudFrontOriginAccessIdentityFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudFrontOriginAccessIdentityFilters = map[string]string{
	"id":               "description.OriginAccessIdentity.CloudFrontOriginAccessIdentity.Id",
	"keibi_account_id": "metadata.SourceID",
}

func GetCloudFrontOriginAccessIdentity(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudFrontOriginAccessIdentity")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudFrontOriginAccessIdentityPaginator(buildFilter(d.KeyColumnQuals, getCloudFrontOriginAccessIdentityFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudFrontOriginAccessIdentity =============================

// ==========================  START: CloudFrontOriginRequestPolicy =============================

type CloudFrontOriginRequestPolicy struct {
	Description   aws.CloudFrontOriginRequestPolicyDescription `json:"description"`
	Metadata      aws.Metadata                                 `json:"metadata"`
	ResourceJobID int                                          `json:"resource_job_id"`
	SourceJobID   int                                          `json:"source_job_id"`
	ResourceType  string                                       `json:"resource_type"`
	SourceType    string                                       `json:"source_type"`
	ID            string                                       `json:"id"`
	ARN           string                                       `json:"arn"`
	SourceID      string                                       `json:"source_id"`
}

type CloudFrontOriginRequestPolicyHit struct {
	ID      string                        `json:"_id"`
	Score   float64                       `json:"_score"`
	Index   string                        `json:"_index"`
	Type    string                        `json:"_type"`
	Version int64                         `json:"_version,omitempty"`
	Source  CloudFrontOriginRequestPolicy `json:"_source"`
	Sort    []interface{}                 `json:"sort"`
}

type CloudFrontOriginRequestPolicyHits struct {
	Total SearchTotal                        `json:"total"`
	Hits  []CloudFrontOriginRequestPolicyHit `json:"hits"`
}

type CloudFrontOriginRequestPolicySearchResponse struct {
	PitID string                            `json:"pit_id"`
	Hits  CloudFrontOriginRequestPolicyHits `json:"hits"`
}

type CloudFrontOriginRequestPolicyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudFrontOriginRequestPolicyPaginator(filters []BoolFilter, limit *int64) (CloudFrontOriginRequestPolicyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudfront_originrequestpolicy", filters, limit)
	if err != nil {
		return CloudFrontOriginRequestPolicyPaginator{}, err
	}

	p := CloudFrontOriginRequestPolicyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudFrontOriginRequestPolicyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudFrontOriginRequestPolicyPaginator) NextPage(ctx context.Context) ([]CloudFrontOriginRequestPolicy, error) {
	var response CloudFrontOriginRequestPolicySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudFrontOriginRequestPolicy
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudFrontOriginRequestPolicyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCloudFrontOriginRequestPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudFrontOriginRequestPolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudFrontOriginRequestPolicyPaginator(buildFilter(d.KeyColumnQuals, listCloudFrontOriginRequestPolicyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudFrontOriginRequestPolicyFilters = map[string]string{
	"id":               "description.OriginRequestPolicy.OriginRequestPolicy.Id",
	"keibi_account_id": "metadata.SourceID",
}

func GetCloudFrontOriginRequestPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudFrontOriginRequestPolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudFrontOriginRequestPolicyPaginator(buildFilter(d.KeyColumnQuals, getCloudFrontOriginRequestPolicyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudFrontOriginRequestPolicy =============================

// ==========================  START: CloudFrontResponseHeadersPolicy =============================

type CloudFrontResponseHeadersPolicy struct {
	Description   aws.CloudFrontResponseHeadersPolicyDescription `json:"description"`
	Metadata      aws.Metadata                                   `json:"metadata"`
	ResourceJobID int                                            `json:"resource_job_id"`
	SourceJobID   int                                            `json:"source_job_id"`
	ResourceType  string                                         `json:"resource_type"`
	SourceType    string                                         `json:"source_type"`
	ID            string                                         `json:"id"`
	ARN           string                                         `json:"arn"`
	SourceID      string                                         `json:"source_id"`
}

type CloudFrontResponseHeadersPolicyHit struct {
	ID      string                          `json:"_id"`
	Score   float64                         `json:"_score"`
	Index   string                          `json:"_index"`
	Type    string                          `json:"_type"`
	Version int64                           `json:"_version,omitempty"`
	Source  CloudFrontResponseHeadersPolicy `json:"_source"`
	Sort    []interface{}                   `json:"sort"`
}

type CloudFrontResponseHeadersPolicyHits struct {
	Total SearchTotal                          `json:"total"`
	Hits  []CloudFrontResponseHeadersPolicyHit `json:"hits"`
}

type CloudFrontResponseHeadersPolicySearchResponse struct {
	PitID string                              `json:"pit_id"`
	Hits  CloudFrontResponseHeadersPolicyHits `json:"hits"`
}

type CloudFrontResponseHeadersPolicyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudFrontResponseHeadersPolicyPaginator(filters []BoolFilter, limit *int64) (CloudFrontResponseHeadersPolicyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudfront_responseheaderspolicy", filters, limit)
	if err != nil {
		return CloudFrontResponseHeadersPolicyPaginator{}, err
	}

	p := CloudFrontResponseHeadersPolicyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudFrontResponseHeadersPolicyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudFrontResponseHeadersPolicyPaginator) NextPage(ctx context.Context) ([]CloudFrontResponseHeadersPolicy, error) {
	var response CloudFrontResponseHeadersPolicySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudFrontResponseHeadersPolicy
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudFrontResponseHeadersPolicyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCloudFrontResponseHeadersPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudFrontResponseHeadersPolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudFrontResponseHeadersPolicyPaginator(buildFilter(d.KeyColumnQuals, listCloudFrontResponseHeadersPolicyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudFrontResponseHeadersPolicyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetCloudFrontResponseHeadersPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudFrontResponseHeadersPolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudFrontResponseHeadersPolicyPaginator(buildFilter(d.KeyColumnQuals, getCloudFrontResponseHeadersPolicyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudFrontResponseHeadersPolicy =============================

// ==========================  START: CloudWatchAlarm =============================

type CloudWatchAlarm struct {
	Description   aws.CloudWatchAlarmDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type CloudWatchAlarmHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  CloudWatchAlarm `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type CloudWatchAlarmHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []CloudWatchAlarmHit `json:"hits"`
}

type CloudWatchAlarmSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  CloudWatchAlarmHits `json:"hits"`
}

type CloudWatchAlarmPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudWatchAlarmPaginator(filters []BoolFilter, limit *int64) (CloudWatchAlarmPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudwatch_alarm", filters, limit)
	if err != nil {
		return CloudWatchAlarmPaginator{}, err
	}

	p := CloudWatchAlarmPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudWatchAlarmPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudWatchAlarmPaginator) NextPage(ctx context.Context) ([]CloudWatchAlarm, error) {
	var response CloudWatchAlarmSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudWatchAlarm
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudWatchAlarmFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.MetricAlarm.AlarmName",
	"state_value":      "description.MetricAlarm.StateValue",
}

func ListCloudWatchAlarm(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudWatchAlarm")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudWatchAlarmPaginator(buildFilter(d.KeyColumnQuals, listCloudWatchAlarmFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudWatchAlarmFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.MetricAlarm.AlarmName",
}

func GetCloudWatchAlarm(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudWatchAlarm")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudWatchAlarmPaginator(buildFilter(d.KeyColumnQuals, getCloudWatchAlarmFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudWatchAlarm =============================

// ==========================  START: CloudWatchLogEvent =============================

type CloudWatchLogEvent struct {
	Description   aws.CloudWatchLogEventDescription `json:"description"`
	Metadata      aws.Metadata                      `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

type CloudWatchLogEventHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  CloudWatchLogEvent `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type CloudWatchLogEventHits struct {
	Total SearchTotal             `json:"total"`
	Hits  []CloudWatchLogEventHit `json:"hits"`
}

type CloudWatchLogEventSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  CloudWatchLogEventHits `json:"hits"`
}

type CloudWatchLogEventPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudWatchLogEventPaginator(filters []BoolFilter, limit *int64) (CloudWatchLogEventPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudwatch_logevent", filters, limit)
	if err != nil {
		return CloudWatchLogEventPaginator{}, err
	}

	p := CloudWatchLogEventPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudWatchLogEventPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudWatchLogEventPaginator) NextPage(ctx context.Context) ([]CloudWatchLogEvent, error) {
	var response CloudWatchLogEventSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudWatchLogEvent
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudWatchLogEventFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"log_stream_name":  "description.LogEvent.LogStreamName",
	"timestamp":        "description.LogEvent.Timestamp",
}

func ListCloudWatchLogEvent(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudWatchLogEvent")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudWatchLogEventPaginator(buildFilter(d.KeyColumnQuals, listCloudWatchLogEventFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudWatchLogEventFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetCloudWatchLogEvent(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudWatchLogEvent")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudWatchLogEventPaginator(buildFilter(d.KeyColumnQuals, getCloudWatchLogEventFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudWatchLogEvent =============================

// ==========================  START: CloudWatchLogResourcePolicy =============================

type CloudWatchLogResourcePolicy struct {
	Description   aws.CloudWatchLogResourcePolicyDescription `json:"description"`
	Metadata      aws.Metadata                               `json:"metadata"`
	ResourceJobID int                                        `json:"resource_job_id"`
	SourceJobID   int                                        `json:"source_job_id"`
	ResourceType  string                                     `json:"resource_type"`
	SourceType    string                                     `json:"source_type"`
	ID            string                                     `json:"id"`
	ARN           string                                     `json:"arn"`
	SourceID      string                                     `json:"source_id"`
}

type CloudWatchLogResourcePolicyHit struct {
	ID      string                      `json:"_id"`
	Score   float64                     `json:"_score"`
	Index   string                      `json:"_index"`
	Type    string                      `json:"_type"`
	Version int64                       `json:"_version,omitempty"`
	Source  CloudWatchLogResourcePolicy `json:"_source"`
	Sort    []interface{}               `json:"sort"`
}

type CloudWatchLogResourcePolicyHits struct {
	Total SearchTotal                      `json:"total"`
	Hits  []CloudWatchLogResourcePolicyHit `json:"hits"`
}

type CloudWatchLogResourcePolicySearchResponse struct {
	PitID string                          `json:"pit_id"`
	Hits  CloudWatchLogResourcePolicyHits `json:"hits"`
}

type CloudWatchLogResourcePolicyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudWatchLogResourcePolicyPaginator(filters []BoolFilter, limit *int64) (CloudWatchLogResourcePolicyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudwatch_logresourcepolicy", filters, limit)
	if err != nil {
		return CloudWatchLogResourcePolicyPaginator{}, err
	}

	p := CloudWatchLogResourcePolicyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudWatchLogResourcePolicyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudWatchLogResourcePolicyPaginator) NextPage(ctx context.Context) ([]CloudWatchLogResourcePolicy, error) {
	var response CloudWatchLogResourcePolicySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudWatchLogResourcePolicy
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudWatchLogResourcePolicyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCloudWatchLogResourcePolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudWatchLogResourcePolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudWatchLogResourcePolicyPaginator(buildFilter(d.KeyColumnQuals, listCloudWatchLogResourcePolicyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudWatchLogResourcePolicyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetCloudWatchLogResourcePolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudWatchLogResourcePolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudWatchLogResourcePolicyPaginator(buildFilter(d.KeyColumnQuals, getCloudWatchLogResourcePolicyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudWatchLogResourcePolicy =============================

// ==========================  START: CloudWatchLogStream =============================

type CloudWatchLogStream struct {
	Description   aws.CloudWatchLogStreamDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type CloudWatchLogStreamHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  CloudWatchLogStream `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type CloudWatchLogStreamHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []CloudWatchLogStreamHit `json:"hits"`
}

type CloudWatchLogStreamSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  CloudWatchLogStreamHits `json:"hits"`
}

type CloudWatchLogStreamPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudWatchLogStreamPaginator(filters []BoolFilter, limit *int64) (CloudWatchLogStreamPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudwatch_logstream", filters, limit)
	if err != nil {
		return CloudWatchLogStreamPaginator{}, err
	}

	p := CloudWatchLogStreamPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudWatchLogStreamPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudWatchLogStreamPaginator) NextPage(ctx context.Context) ([]CloudWatchLogStream, error) {
	var response CloudWatchLogStreamSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudWatchLogStream
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudWatchLogStreamFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.LogStream.LogStreamName",
}

func ListCloudWatchLogStream(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudWatchLogStream")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudWatchLogStreamPaginator(buildFilter(d.KeyColumnQuals, listCloudWatchLogStreamFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudWatchLogStreamFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.LogStream.LogStreamName",
}

func GetCloudWatchLogStream(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudWatchLogStream")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudWatchLogStreamPaginator(buildFilter(d.KeyColumnQuals, getCloudWatchLogStreamFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudWatchLogStream =============================

// ==========================  START: CloudWatchLogSubscriptionFilter =============================

type CloudWatchLogSubscriptionFilter struct {
	Description   aws.CloudWatchLogSubscriptionFilterDescription `json:"description"`
	Metadata      aws.Metadata                                   `json:"metadata"`
	ResourceJobID int                                            `json:"resource_job_id"`
	SourceJobID   int                                            `json:"source_job_id"`
	ResourceType  string                                         `json:"resource_type"`
	SourceType    string                                         `json:"source_type"`
	ID            string                                         `json:"id"`
	ARN           string                                         `json:"arn"`
	SourceID      string                                         `json:"source_id"`
}

type CloudWatchLogSubscriptionFilterHit struct {
	ID      string                          `json:"_id"`
	Score   float64                         `json:"_score"`
	Index   string                          `json:"_index"`
	Type    string                          `json:"_type"`
	Version int64                           `json:"_version,omitempty"`
	Source  CloudWatchLogSubscriptionFilter `json:"_source"`
	Sort    []interface{}                   `json:"sort"`
}

type CloudWatchLogSubscriptionFilterHits struct {
	Total SearchTotal                          `json:"total"`
	Hits  []CloudWatchLogSubscriptionFilterHit `json:"hits"`
}

type CloudWatchLogSubscriptionFilterSearchResponse struct {
	PitID string                              `json:"pit_id"`
	Hits  CloudWatchLogSubscriptionFilterHits `json:"hits"`
}

type CloudWatchLogSubscriptionFilterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudWatchLogSubscriptionFilterPaginator(filters []BoolFilter, limit *int64) (CloudWatchLogSubscriptionFilterPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudwatch_logsubscriptionfilter", filters, limit)
	if err != nil {
		return CloudWatchLogSubscriptionFilterPaginator{}, err
	}

	p := CloudWatchLogSubscriptionFilterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudWatchLogSubscriptionFilterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudWatchLogSubscriptionFilterPaginator) NextPage(ctx context.Context) ([]CloudWatchLogSubscriptionFilter, error) {
	var response CloudWatchLogSubscriptionFilterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudWatchLogSubscriptionFilter
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudWatchLogSubscriptionFilterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"log_group_name":   "description.SubscriptionFilter.LogGroupName",
	"name":             "description.SubscriptionFilter.FilterName",
}

func ListCloudWatchLogSubscriptionFilter(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudWatchLogSubscriptionFilter")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudWatchLogSubscriptionFilterPaginator(buildFilter(d.KeyColumnQuals, listCloudWatchLogSubscriptionFilterFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudWatchLogSubscriptionFilterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"log_group_name":   "description.SubscriptionFilter.LogGroupName",
	"name":             "description.SubscriptionFilter.FilterName",
}

func GetCloudWatchLogSubscriptionFilter(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudWatchLogSubscriptionFilter")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudWatchLogSubscriptionFilterPaginator(buildFilter(d.KeyColumnQuals, getCloudWatchLogSubscriptionFilterFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudWatchLogSubscriptionFilter =============================

// ==========================  START: CloudWatchMetric =============================

type CloudWatchMetric struct {
	Description   aws.CloudWatchMetricDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type CloudWatchMetricHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  CloudWatchMetric `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type CloudWatchMetricHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []CloudWatchMetricHit `json:"hits"`
}

type CloudWatchMetricSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  CloudWatchMetricHits `json:"hits"`
}

type CloudWatchMetricPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudWatchMetricPaginator(filters []BoolFilter, limit *int64) (CloudWatchMetricPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudwatch_metric", filters, limit)
	if err != nil {
		return CloudWatchMetricPaginator{}, err
	}

	p := CloudWatchMetricPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudWatchMetricPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudWatchMetricPaginator) NextPage(ctx context.Context) ([]CloudWatchMetric, error) {
	var response CloudWatchMetricSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudWatchMetric
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudWatchMetricFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"metric_name":      "description.Metric.MetricName",
	"namespace":        "description.Metric.Namespace",
}

func ListCloudWatchMetric(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudWatchMetric")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudWatchMetricPaginator(buildFilter(d.KeyColumnQuals, listCloudWatchMetricFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudWatchMetricFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetCloudWatchMetric(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudWatchMetric")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudWatchMetricPaginator(buildFilter(d.KeyColumnQuals, getCloudWatchMetricFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudWatchMetric =============================

// ==========================  START: CloudWatchLogsLogGroup =============================

type CloudWatchLogsLogGroup struct {
	Description   aws.CloudWatchLogsLogGroupDescription `json:"description"`
	Metadata      aws.Metadata                          `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

type CloudWatchLogsLogGroupHit struct {
	ID      string                 `json:"_id"`
	Score   float64                `json:"_score"`
	Index   string                 `json:"_index"`
	Type    string                 `json:"_type"`
	Version int64                  `json:"_version,omitempty"`
	Source  CloudWatchLogsLogGroup `json:"_source"`
	Sort    []interface{}          `json:"sort"`
}

type CloudWatchLogsLogGroupHits struct {
	Total SearchTotal                 `json:"total"`
	Hits  []CloudWatchLogsLogGroupHit `json:"hits"`
}

type CloudWatchLogsLogGroupSearchResponse struct {
	PitID string                     `json:"pit_id"`
	Hits  CloudWatchLogsLogGroupHits `json:"hits"`
}

type CloudWatchLogsLogGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudWatchLogsLogGroupPaginator(filters []BoolFilter, limit *int64) (CloudWatchLogsLogGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_logs_loggroup", filters, limit)
	if err != nil {
		return CloudWatchLogsLogGroupPaginator{}, err
	}

	p := CloudWatchLogsLogGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudWatchLogsLogGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudWatchLogsLogGroupPaginator) NextPage(ctx context.Context) ([]CloudWatchLogsLogGroup, error) {
	var response CloudWatchLogsLogGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudWatchLogsLogGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudWatchLogsLogGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.LogGroup.LogGroupName",
}

func ListCloudWatchLogsLogGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudWatchLogsLogGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudWatchLogsLogGroupPaginator(buildFilter(d.KeyColumnQuals, listCloudWatchLogsLogGroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudWatchLogsLogGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.LogGroup.LogGroupName",
}

func GetCloudWatchLogsLogGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudWatchLogsLogGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudWatchLogsLogGroupPaginator(buildFilter(d.KeyColumnQuals, getCloudWatchLogsLogGroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudWatchLogsLogGroup =============================

// ==========================  START: CloudWatchLogsMetricFilter =============================

type CloudWatchLogsMetricFilter struct {
	Description   aws.CloudWatchLogsMetricFilterDescription `json:"description"`
	Metadata      aws.Metadata                              `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

type CloudWatchLogsMetricFilterHit struct {
	ID      string                     `json:"_id"`
	Score   float64                    `json:"_score"`
	Index   string                     `json:"_index"`
	Type    string                     `json:"_type"`
	Version int64                      `json:"_version,omitempty"`
	Source  CloudWatchLogsMetricFilter `json:"_source"`
	Sort    []interface{}              `json:"sort"`
}

type CloudWatchLogsMetricFilterHits struct {
	Total SearchTotal                     `json:"total"`
	Hits  []CloudWatchLogsMetricFilterHit `json:"hits"`
}

type CloudWatchLogsMetricFilterSearchResponse struct {
	PitID string                         `json:"pit_id"`
	Hits  CloudWatchLogsMetricFilterHits `json:"hits"`
}

type CloudWatchLogsMetricFilterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudWatchLogsMetricFilterPaginator(filters []BoolFilter, limit *int64) (CloudWatchLogsMetricFilterPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_logs_metricfilter", filters, limit)
	if err != nil {
		return CloudWatchLogsMetricFilterPaginator{}, err
	}

	p := CloudWatchLogsMetricFilterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudWatchLogsMetricFilterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudWatchLogsMetricFilterPaginator) NextPage(ctx context.Context) ([]CloudWatchLogsMetricFilter, error) {
	var response CloudWatchLogsMetricFilterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudWatchLogsMetricFilter
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudWatchLogsMetricFilterFilters = map[string]string{
	"keibi_account_id":                "metadata.SourceID",
	"log_group_name":                  "decsription.MetricFilter.LogGroupName",
	"metric_transformation_name":      "decsription.MetricFilter.MetricTransformations.MetricName",
	"metric_transformation_namespace": "decsription.MetricFilter.MetricTransformations.MetricNamespace",
	"name":                            "decsription.MetricFilter.FilterName",
}

func ListCloudWatchLogsMetricFilter(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudWatchLogsMetricFilter")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudWatchLogsMetricFilterPaginator(buildFilter(d.KeyColumnQuals, listCloudWatchLogsMetricFilterFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudWatchLogsMetricFilterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "decsription.MetricFilter.FilterName",
}

func GetCloudWatchLogsMetricFilter(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudWatchLogsMetricFilter")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudWatchLogsMetricFilterPaginator(buildFilter(d.KeyColumnQuals, getCloudWatchLogsMetricFilterFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudWatchLogsMetricFilter =============================

// ==========================  START: CodeBuildProject =============================

type CodeBuildProject struct {
	Description   aws.CodeBuildProjectDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type CodeBuildProjectHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  CodeBuildProject `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type CodeBuildProjectHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []CodeBuildProjectHit `json:"hits"`
}

type CodeBuildProjectSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  CodeBuildProjectHits `json:"hits"`
}

type CodeBuildProjectPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCodeBuildProjectPaginator(filters []BoolFilter, limit *int64) (CodeBuildProjectPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_codebuild_project", filters, limit)
	if err != nil {
		return CodeBuildProjectPaginator{}, err
	}

	p := CodeBuildProjectPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CodeBuildProjectPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CodeBuildProjectPaginator) NextPage(ctx context.Context) ([]CodeBuildProject, error) {
	var response CodeBuildProjectSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CodeBuildProject
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCodeBuildProjectFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCodeBuildProject(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCodeBuildProject")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCodeBuildProjectPaginator(buildFilter(d.KeyColumnQuals, listCodeBuildProjectFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCodeBuildProjectFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Project.Name",
}

func GetCodeBuildProject(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCodeBuildProject")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCodeBuildProjectPaginator(buildFilter(d.KeyColumnQuals, getCodeBuildProjectFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CodeBuildProject =============================

// ==========================  START: CodeBuildSourceCredential =============================

type CodeBuildSourceCredential struct {
	Description   aws.CodeBuildSourceCredentialDescription `json:"description"`
	Metadata      aws.Metadata                             `json:"metadata"`
	ResourceJobID int                                      `json:"resource_job_id"`
	SourceJobID   int                                      `json:"source_job_id"`
	ResourceType  string                                   `json:"resource_type"`
	SourceType    string                                   `json:"source_type"`
	ID            string                                   `json:"id"`
	ARN           string                                   `json:"arn"`
	SourceID      string                                   `json:"source_id"`
}

type CodeBuildSourceCredentialHit struct {
	ID      string                    `json:"_id"`
	Score   float64                   `json:"_score"`
	Index   string                    `json:"_index"`
	Type    string                    `json:"_type"`
	Version int64                     `json:"_version,omitempty"`
	Source  CodeBuildSourceCredential `json:"_source"`
	Sort    []interface{}             `json:"sort"`
}

type CodeBuildSourceCredentialHits struct {
	Total SearchTotal                    `json:"total"`
	Hits  []CodeBuildSourceCredentialHit `json:"hits"`
}

type CodeBuildSourceCredentialSearchResponse struct {
	PitID string                        `json:"pit_id"`
	Hits  CodeBuildSourceCredentialHits `json:"hits"`
}

type CodeBuildSourceCredentialPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCodeBuildSourceCredentialPaginator(filters []BoolFilter, limit *int64) (CodeBuildSourceCredentialPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_codebuild_sourcecredential", filters, limit)
	if err != nil {
		return CodeBuildSourceCredentialPaginator{}, err
	}

	p := CodeBuildSourceCredentialPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CodeBuildSourceCredentialPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CodeBuildSourceCredentialPaginator) NextPage(ctx context.Context) ([]CodeBuildSourceCredential, error) {
	var response CodeBuildSourceCredentialSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CodeBuildSourceCredential
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCodeBuildSourceCredentialFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCodeBuildSourceCredential(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCodeBuildSourceCredential")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCodeBuildSourceCredentialPaginator(buildFilter(d.KeyColumnQuals, listCodeBuildSourceCredentialFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCodeBuildSourceCredentialFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetCodeBuildSourceCredential(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCodeBuildSourceCredential")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCodeBuildSourceCredentialPaginator(buildFilter(d.KeyColumnQuals, getCodeBuildSourceCredentialFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CodeBuildSourceCredential =============================

// ==========================  START: ConfigConfigurationRecorder =============================

type ConfigConfigurationRecorder struct {
	Description   aws.ConfigConfigurationRecorderDescription `json:"description"`
	Metadata      aws.Metadata                               `json:"metadata"`
	ResourceJobID int                                        `json:"resource_job_id"`
	SourceJobID   int                                        `json:"source_job_id"`
	ResourceType  string                                     `json:"resource_type"`
	SourceType    string                                     `json:"source_type"`
	ID            string                                     `json:"id"`
	ARN           string                                     `json:"arn"`
	SourceID      string                                     `json:"source_id"`
}

type ConfigConfigurationRecorderHit struct {
	ID      string                      `json:"_id"`
	Score   float64                     `json:"_score"`
	Index   string                      `json:"_index"`
	Type    string                      `json:"_type"`
	Version int64                       `json:"_version,omitempty"`
	Source  ConfigConfigurationRecorder `json:"_source"`
	Sort    []interface{}               `json:"sort"`
}

type ConfigConfigurationRecorderHits struct {
	Total SearchTotal                      `json:"total"`
	Hits  []ConfigConfigurationRecorderHit `json:"hits"`
}

type ConfigConfigurationRecorderSearchResponse struct {
	PitID string                          `json:"pit_id"`
	Hits  ConfigConfigurationRecorderHits `json:"hits"`
}

type ConfigConfigurationRecorderPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewConfigConfigurationRecorderPaginator(filters []BoolFilter, limit *int64) (ConfigConfigurationRecorderPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_config_configurationrecorder", filters, limit)
	if err != nil {
		return ConfigConfigurationRecorderPaginator{}, err
	}

	p := ConfigConfigurationRecorderPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ConfigConfigurationRecorderPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ConfigConfigurationRecorderPaginator) NextPage(ctx context.Context) ([]ConfigConfigurationRecorder, error) {
	var response ConfigConfigurationRecorderSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ConfigConfigurationRecorder
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listConfigConfigurationRecorderFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.ConfigurationRecorder.Name",
}

func ListConfigConfigurationRecorder(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListConfigConfigurationRecorder")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewConfigConfigurationRecorderPaginator(buildFilter(d.KeyColumnQuals, listConfigConfigurationRecorderFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getConfigConfigurationRecorderFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.ConfigurationRecorder.Name",
}

func GetConfigConfigurationRecorder(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetConfigConfigurationRecorder")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewConfigConfigurationRecorderPaginator(buildFilter(d.KeyColumnQuals, getConfigConfigurationRecorderFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ConfigConfigurationRecorder =============================

// ==========================  START: ConfigAggregationAuthorization =============================

type ConfigAggregationAuthorization struct {
	Description   aws.ConfigAggregationAuthorizationDescription `json:"description"`
	Metadata      aws.Metadata                                  `json:"metadata"`
	ResourceJobID int                                           `json:"resource_job_id"`
	SourceJobID   int                                           `json:"source_job_id"`
	ResourceType  string                                        `json:"resource_type"`
	SourceType    string                                        `json:"source_type"`
	ID            string                                        `json:"id"`
	ARN           string                                        `json:"arn"`
	SourceID      string                                        `json:"source_id"`
}

type ConfigAggregationAuthorizationHit struct {
	ID      string                         `json:"_id"`
	Score   float64                        `json:"_score"`
	Index   string                         `json:"_index"`
	Type    string                         `json:"_type"`
	Version int64                          `json:"_version,omitempty"`
	Source  ConfigAggregationAuthorization `json:"_source"`
	Sort    []interface{}                  `json:"sort"`
}

type ConfigAggregationAuthorizationHits struct {
	Total SearchTotal                         `json:"total"`
	Hits  []ConfigAggregationAuthorizationHit `json:"hits"`
}

type ConfigAggregationAuthorizationSearchResponse struct {
	PitID string                             `json:"pit_id"`
	Hits  ConfigAggregationAuthorizationHits `json:"hits"`
}

type ConfigAggregationAuthorizationPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewConfigAggregationAuthorizationPaginator(filters []BoolFilter, limit *int64) (ConfigAggregationAuthorizationPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_config_aggregationauthorization", filters, limit)
	if err != nil {
		return ConfigAggregationAuthorizationPaginator{}, err
	}

	p := ConfigAggregationAuthorizationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ConfigAggregationAuthorizationPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ConfigAggregationAuthorizationPaginator) NextPage(ctx context.Context) ([]ConfigAggregationAuthorization, error) {
	var response ConfigAggregationAuthorizationSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ConfigAggregationAuthorization
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listConfigAggregationAuthorizationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListConfigAggregationAuthorization(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListConfigAggregationAuthorization")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewConfigAggregationAuthorizationPaginator(buildFilter(d.KeyColumnQuals, listConfigAggregationAuthorizationFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getConfigAggregationAuthorizationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetConfigAggregationAuthorization(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetConfigAggregationAuthorization")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewConfigAggregationAuthorizationPaginator(buildFilter(d.KeyColumnQuals, getConfigAggregationAuthorizationFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ConfigAggregationAuthorization =============================

// ==========================  START: ConfigConformancePack =============================

type ConfigConformancePack struct {
	Description   aws.ConfigConformancePackDescription `json:"description"`
	Metadata      aws.Metadata                         `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

type ConfigConformancePackHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  ConfigConformancePack `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type ConfigConformancePackHits struct {
	Total SearchTotal                `json:"total"`
	Hits  []ConfigConformancePackHit `json:"hits"`
}

type ConfigConformancePackSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  ConfigConformancePackHits `json:"hits"`
}

type ConfigConformancePackPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewConfigConformancePackPaginator(filters []BoolFilter, limit *int64) (ConfigConformancePackPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_config_conformancepack", filters, limit)
	if err != nil {
		return ConfigConformancePackPaginator{}, err
	}

	p := ConfigConformancePackPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ConfigConformancePackPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ConfigConformancePackPaginator) NextPage(ctx context.Context) ([]ConfigConformancePack, error) {
	var response ConfigConformancePackSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ConfigConformancePack
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listConfigConformancePackFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListConfigConformancePack(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListConfigConformancePack")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewConfigConformancePackPaginator(buildFilter(d.KeyColumnQuals, listConfigConformancePackFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getConfigConformancePackFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.ConformancePack.ConformancePackName",
}

func GetConfigConformancePack(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetConfigConformancePack")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewConfigConformancePackPaginator(buildFilter(d.KeyColumnQuals, getConfigConformancePackFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ConfigConformancePack =============================

// ==========================  START: ConfigRule =============================

type ConfigRule struct {
	Description   aws.ConfigRuleDescription `json:"description"`
	Metadata      aws.Metadata              `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	ARN           string                    `json:"arn"`
	SourceID      string                    `json:"source_id"`
}

type ConfigRuleHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  ConfigRule    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type ConfigRuleHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []ConfigRuleHit `json:"hits"`
}

type ConfigRuleSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  ConfigRuleHits `json:"hits"`
}

type ConfigRulePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewConfigRulePaginator(filters []BoolFilter, limit *int64) (ConfigRulePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_config_rule", filters, limit)
	if err != nil {
		return ConfigRulePaginator{}, err
	}

	p := ConfigRulePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ConfigRulePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ConfigRulePaginator) NextPage(ctx context.Context) ([]ConfigRule, error) {
	var response ConfigRuleSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ConfigRule
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listConfigRuleFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListConfigRule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListConfigRule")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewConfigRulePaginator(buildFilter(d.KeyColumnQuals, listConfigRuleFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getConfigRuleFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Rule.ConfigRuleName",
}

func GetConfigRule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetConfigRule")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewConfigRulePaginator(buildFilter(d.KeyColumnQuals, getConfigRuleFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ConfigRule =============================

// ==========================  START: DAXCluster =============================

type DAXCluster struct {
	Description   aws.DAXClusterDescription `json:"description"`
	Metadata      aws.Metadata              `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	ARN           string                    `json:"arn"`
	SourceID      string                    `json:"source_id"`
}

type DAXClusterHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  DAXCluster    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type DAXClusterHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []DAXClusterHit `json:"hits"`
}

type DAXClusterSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  DAXClusterHits `json:"hits"`
}

type DAXClusterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDAXClusterPaginator(filters []BoolFilter, limit *int64) (DAXClusterPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_dax_cluster", filters, limit)
	if err != nil {
		return DAXClusterPaginator{}, err
	}

	p := DAXClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DAXClusterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DAXClusterPaginator) NextPage(ctx context.Context) ([]DAXCluster, error) {
	var response DAXClusterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DAXCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDAXClusterFilters = map[string]string{
	"cluster_name":     "description.Cluster.ClusterName",
	"keibi_account_id": "metadata.SourceID",
}

func ListDAXCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDAXCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDAXClusterPaginator(buildFilter(d.KeyColumnQuals, listDAXClusterFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDAXClusterFilters = map[string]string{
	"cluster_name":     "description.Cluster.ClusterName",
	"keibi_account_id": "metadata.SourceID",
}

func GetDAXCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDAXCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDAXClusterPaginator(buildFilter(d.KeyColumnQuals, getDAXClusterFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DAXCluster =============================

// ==========================  START: DAXParameterGroup =============================

type DAXParameterGroup struct {
	Description   aws.DAXParameterGroupDescription `json:"description"`
	Metadata      aws.Metadata                     `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

type DAXParameterGroupHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  DAXParameterGroup `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type DAXParameterGroupHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []DAXParameterGroupHit `json:"hits"`
}

type DAXParameterGroupSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  DAXParameterGroupHits `json:"hits"`
}

type DAXParameterGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDAXParameterGroupPaginator(filters []BoolFilter, limit *int64) (DAXParameterGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_dax_parametergroup", filters, limit)
	if err != nil {
		return DAXParameterGroupPaginator{}, err
	}

	p := DAXParameterGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DAXParameterGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DAXParameterGroupPaginator) NextPage(ctx context.Context) ([]DAXParameterGroup, error) {
	var response DAXParameterGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DAXParameterGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDAXParameterGroupFilters = map[string]string{
	"keibi_account_id":     "metadata.SourceID",
	"parameter_group_name": "description.ParameterGroup.ParameterGroupName",
}

func ListDAXParameterGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDAXParameterGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDAXParameterGroupPaginator(buildFilter(d.KeyColumnQuals, listDAXParameterGroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDAXParameterGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetDAXParameterGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDAXParameterGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDAXParameterGroupPaginator(buildFilter(d.KeyColumnQuals, getDAXParameterGroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DAXParameterGroup =============================

// ==========================  START: DAXParameter =============================

type DAXParameter struct {
	Description   aws.DAXParameterDescription `json:"description"`
	Metadata      aws.Metadata                `json:"metadata"`
	ResourceJobID int                         `json:"resource_job_id"`
	SourceJobID   int                         `json:"source_job_id"`
	ResourceType  string                      `json:"resource_type"`
	SourceType    string                      `json:"source_type"`
	ID            string                      `json:"id"`
	ARN           string                      `json:"arn"`
	SourceID      string                      `json:"source_id"`
}

type DAXParameterHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  DAXParameter  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type DAXParameterHits struct {
	Total SearchTotal       `json:"total"`
	Hits  []DAXParameterHit `json:"hits"`
}

type DAXParameterSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  DAXParameterHits `json:"hits"`
}

type DAXParameterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDAXParameterPaginator(filters []BoolFilter, limit *int64) (DAXParameterPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_dax_parameter", filters, limit)
	if err != nil {
		return DAXParameterPaginator{}, err
	}

	p := DAXParameterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DAXParameterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DAXParameterPaginator) NextPage(ctx context.Context) ([]DAXParameter, error) {
	var response DAXParameterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DAXParameter
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDAXParameterFilters = map[string]string{
	"keibi_account_id":     "metadata.SourceID",
	"parameter_group_name": "description.ParameterGroupName",
}

func ListDAXParameter(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDAXParameter")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDAXParameterPaginator(buildFilter(d.KeyColumnQuals, listDAXParameterFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDAXParameterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetDAXParameter(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDAXParameter")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDAXParameterPaginator(buildFilter(d.KeyColumnQuals, getDAXParameterFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DAXParameter =============================

// ==========================  START: DAXSubnetGroup =============================

type DAXSubnetGroup struct {
	Description   aws.DAXSubnetGroupDescription `json:"description"`
	Metadata      aws.Metadata                  `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

type DAXSubnetGroupHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  DAXSubnetGroup `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type DAXSubnetGroupHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []DAXSubnetGroupHit `json:"hits"`
}

type DAXSubnetGroupSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  DAXSubnetGroupHits `json:"hits"`
}

type DAXSubnetGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDAXSubnetGroupPaginator(filters []BoolFilter, limit *int64) (DAXSubnetGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_dax_subnetgroup", filters, limit)
	if err != nil {
		return DAXSubnetGroupPaginator{}, err
	}

	p := DAXSubnetGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DAXSubnetGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DAXSubnetGroupPaginator) NextPage(ctx context.Context) ([]DAXSubnetGroup, error) {
	var response DAXSubnetGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DAXSubnetGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDAXSubnetGroupFilters = map[string]string{
	"keibi_account_id":  "metadata.SourceID",
	"subnet_group_name": "description.SubnetGroup.SubnetGroupName",
}

func ListDAXSubnetGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDAXSubnetGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDAXSubnetGroupPaginator(buildFilter(d.KeyColumnQuals, listDAXSubnetGroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDAXSubnetGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetDAXSubnetGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDAXSubnetGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDAXSubnetGroupPaginator(buildFilter(d.KeyColumnQuals, getDAXSubnetGroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DAXSubnetGroup =============================

// ==========================  START: DMSReplicationInstance =============================

type DMSReplicationInstance struct {
	Description   aws.DMSReplicationInstanceDescription `json:"description"`
	Metadata      aws.Metadata                          `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

type DMSReplicationInstanceHit struct {
	ID      string                 `json:"_id"`
	Score   float64                `json:"_score"`
	Index   string                 `json:"_index"`
	Type    string                 `json:"_type"`
	Version int64                  `json:"_version,omitempty"`
	Source  DMSReplicationInstance `json:"_source"`
	Sort    []interface{}          `json:"sort"`
}

type DMSReplicationInstanceHits struct {
	Total SearchTotal                 `json:"total"`
	Hits  []DMSReplicationInstanceHit `json:"hits"`
}

type DMSReplicationInstanceSearchResponse struct {
	PitID string                     `json:"pit_id"`
	Hits  DMSReplicationInstanceHits `json:"hits"`
}

type DMSReplicationInstancePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDMSReplicationInstancePaginator(filters []BoolFilter, limit *int64) (DMSReplicationInstancePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_dms_replicationinstance", filters, limit)
	if err != nil {
		return DMSReplicationInstancePaginator{}, err
	}

	p := DMSReplicationInstancePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DMSReplicationInstancePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DMSReplicationInstancePaginator) NextPage(ctx context.Context) ([]DMSReplicationInstance, error) {
	var response DMSReplicationInstanceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DMSReplicationInstance
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDMSReplicationInstanceFilters = map[string]string{
	"arn":                             "description.ReplicationInstance.ReplicationInstanceArn",
	"engine_version":                  "description.ReplicationInstance.EngineVersion",
	"keibi_account_id":                "metadata.SourceID",
	"replication_instance_class":      "description.ReplicationInstance.ReplicationInstanceClass",
	"replication_instance_identifier": "description.ReplicationInstance.ReplicationInstanceIdentifier",
}

func ListDMSReplicationInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDMSReplicationInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDMSReplicationInstancePaginator(buildFilter(d.KeyColumnQuals, listDMSReplicationInstanceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDMSReplicationInstanceFilters = map[string]string{
	"arn":              "description.ReplicationInstance.ReplicationInstanceArn",
	"keibi_account_id": "metadata.SourceID",
}

func GetDMSReplicationInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDMSReplicationInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDMSReplicationInstancePaginator(buildFilter(d.KeyColumnQuals, getDMSReplicationInstanceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DMSReplicationInstance =============================

// ==========================  START: DynamoDbTable =============================

type DynamoDbTable struct {
	Description   aws.DynamoDbTableDescription `json:"description"`
	Metadata      aws.Metadata                 `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

type DynamoDbTableHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  DynamoDbTable `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type DynamoDbTableHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []DynamoDbTableHit `json:"hits"`
}

type DynamoDbTableSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  DynamoDbTableHits `json:"hits"`
}

type DynamoDbTablePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDynamoDbTablePaginator(filters []BoolFilter, limit *int64) (DynamoDbTablePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_dynamodb_table", filters, limit)
	if err != nil {
		return DynamoDbTablePaginator{}, err
	}

	p := DynamoDbTablePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DynamoDbTablePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DynamoDbTablePaginator) NextPage(ctx context.Context) ([]DynamoDbTable, error) {
	var response DynamoDbTableSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DynamoDbTable
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDynamoDbTableFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Table.TableName",
}

func ListDynamoDbTable(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDynamoDbTable")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDynamoDbTablePaginator(buildFilter(d.KeyColumnQuals, listDynamoDbTableFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDynamoDbTableFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Table.TableName",
}

func GetDynamoDbTable(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDynamoDbTable")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDynamoDbTablePaginator(buildFilter(d.KeyColumnQuals, getDynamoDbTableFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DynamoDbTable =============================

// ==========================  START: DynamoDbGlobalSecondaryIndex =============================

type DynamoDbGlobalSecondaryIndex struct {
	Description   aws.DynamoDbGlobalSecondaryIndexDescription `json:"description"`
	Metadata      aws.Metadata                                `json:"metadata"`
	ResourceJobID int                                         `json:"resource_job_id"`
	SourceJobID   int                                         `json:"source_job_id"`
	ResourceType  string                                      `json:"resource_type"`
	SourceType    string                                      `json:"source_type"`
	ID            string                                      `json:"id"`
	ARN           string                                      `json:"arn"`
	SourceID      string                                      `json:"source_id"`
}

type DynamoDbGlobalSecondaryIndexHit struct {
	ID      string                       `json:"_id"`
	Score   float64                      `json:"_score"`
	Index   string                       `json:"_index"`
	Type    string                       `json:"_type"`
	Version int64                        `json:"_version,omitempty"`
	Source  DynamoDbGlobalSecondaryIndex `json:"_source"`
	Sort    []interface{}                `json:"sort"`
}

type DynamoDbGlobalSecondaryIndexHits struct {
	Total SearchTotal                       `json:"total"`
	Hits  []DynamoDbGlobalSecondaryIndexHit `json:"hits"`
}

type DynamoDbGlobalSecondaryIndexSearchResponse struct {
	PitID string                           `json:"pit_id"`
	Hits  DynamoDbGlobalSecondaryIndexHits `json:"hits"`
}

type DynamoDbGlobalSecondaryIndexPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDynamoDbGlobalSecondaryIndexPaginator(filters []BoolFilter, limit *int64) (DynamoDbGlobalSecondaryIndexPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_dynamodb_globalsecondaryindex", filters, limit)
	if err != nil {
		return DynamoDbGlobalSecondaryIndexPaginator{}, err
	}

	p := DynamoDbGlobalSecondaryIndexPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DynamoDbGlobalSecondaryIndexPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DynamoDbGlobalSecondaryIndexPaginator) NextPage(ctx context.Context) ([]DynamoDbGlobalSecondaryIndex, error) {
	var response DynamoDbGlobalSecondaryIndexSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DynamoDbGlobalSecondaryIndex
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDynamoDbGlobalSecondaryIndexFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListDynamoDbGlobalSecondaryIndex(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDynamoDbGlobalSecondaryIndex")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDynamoDbGlobalSecondaryIndexPaginator(buildFilter(d.KeyColumnQuals, listDynamoDbGlobalSecondaryIndexFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDynamoDbGlobalSecondaryIndexFilters = map[string]string{
	"index_arn":        "description.GlobalSecondaryIndex.IndexArn",
	"keibi_account_id": "metadata.SourceID",
}

func GetDynamoDbGlobalSecondaryIndex(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDynamoDbGlobalSecondaryIndex")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDynamoDbGlobalSecondaryIndexPaginator(buildFilter(d.KeyColumnQuals, getDynamoDbGlobalSecondaryIndexFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DynamoDbGlobalSecondaryIndex =============================

// ==========================  START: DynamoDbLocalSecondaryIndex =============================

type DynamoDbLocalSecondaryIndex struct {
	Description   aws.DynamoDbLocalSecondaryIndexDescription `json:"description"`
	Metadata      aws.Metadata                               `json:"metadata"`
	ResourceJobID int                                        `json:"resource_job_id"`
	SourceJobID   int                                        `json:"source_job_id"`
	ResourceType  string                                     `json:"resource_type"`
	SourceType    string                                     `json:"source_type"`
	ID            string                                     `json:"id"`
	ARN           string                                     `json:"arn"`
	SourceID      string                                     `json:"source_id"`
}

type DynamoDbLocalSecondaryIndexHit struct {
	ID      string                      `json:"_id"`
	Score   float64                     `json:"_score"`
	Index   string                      `json:"_index"`
	Type    string                      `json:"_type"`
	Version int64                       `json:"_version,omitempty"`
	Source  DynamoDbLocalSecondaryIndex `json:"_source"`
	Sort    []interface{}               `json:"sort"`
}

type DynamoDbLocalSecondaryIndexHits struct {
	Total SearchTotal                      `json:"total"`
	Hits  []DynamoDbLocalSecondaryIndexHit `json:"hits"`
}

type DynamoDbLocalSecondaryIndexSearchResponse struct {
	PitID string                          `json:"pit_id"`
	Hits  DynamoDbLocalSecondaryIndexHits `json:"hits"`
}

type DynamoDbLocalSecondaryIndexPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDynamoDbLocalSecondaryIndexPaginator(filters []BoolFilter, limit *int64) (DynamoDbLocalSecondaryIndexPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_dynamodb_localsecondaryindex", filters, limit)
	if err != nil {
		return DynamoDbLocalSecondaryIndexPaginator{}, err
	}

	p := DynamoDbLocalSecondaryIndexPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DynamoDbLocalSecondaryIndexPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DynamoDbLocalSecondaryIndexPaginator) NextPage(ctx context.Context) ([]DynamoDbLocalSecondaryIndex, error) {
	var response DynamoDbLocalSecondaryIndexSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DynamoDbLocalSecondaryIndex
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDynamoDbLocalSecondaryIndexFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListDynamoDbLocalSecondaryIndex(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDynamoDbLocalSecondaryIndex")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDynamoDbLocalSecondaryIndexPaginator(buildFilter(d.KeyColumnQuals, listDynamoDbLocalSecondaryIndexFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDynamoDbLocalSecondaryIndexFilters = map[string]string{
	"index_arn":        "description.LocalSecondaryIndex.IndexArn",
	"keibi_account_id": "metadata.SourceID",
}

func GetDynamoDbLocalSecondaryIndex(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDynamoDbLocalSecondaryIndex")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDynamoDbLocalSecondaryIndexPaginator(buildFilter(d.KeyColumnQuals, getDynamoDbLocalSecondaryIndexFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DynamoDbLocalSecondaryIndex =============================

// ==========================  START: DynamoDbStream =============================

type DynamoDbStream struct {
	Description   aws.DynamoDbStreamDescription `json:"description"`
	Metadata      aws.Metadata                  `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

type DynamoDbStreamHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  DynamoDbStream `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type DynamoDbStreamHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []DynamoDbStreamHit `json:"hits"`
}

type DynamoDbStreamSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  DynamoDbStreamHits `json:"hits"`
}

type DynamoDbStreamPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDynamoDbStreamPaginator(filters []BoolFilter, limit *int64) (DynamoDbStreamPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_dynamodbstreams_stream", filters, limit)
	if err != nil {
		return DynamoDbStreamPaginator{}, err
	}

	p := DynamoDbStreamPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DynamoDbStreamPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DynamoDbStreamPaginator) NextPage(ctx context.Context) ([]DynamoDbStream, error) {
	var response DynamoDbStreamSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DynamoDbStream
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDynamoDbStreamFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListDynamoDbStream(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDynamoDbStream")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDynamoDbStreamPaginator(buildFilter(d.KeyColumnQuals, listDynamoDbStreamFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDynamoDbStreamFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"stream_arn":       "description.Stream.StreamArn",
}

func GetDynamoDbStream(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDynamoDbStream")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDynamoDbStreamPaginator(buildFilter(d.KeyColumnQuals, getDynamoDbStreamFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DynamoDbStream =============================

// ==========================  START: DynamoDbBackup =============================

type DynamoDbBackup struct {
	Description   aws.DynamoDbBackupDescription `json:"description"`
	Metadata      aws.Metadata                  `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

type DynamoDbBackupHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  DynamoDbBackup `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type DynamoDbBackupHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []DynamoDbBackupHit `json:"hits"`
}

type DynamoDbBackupSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  DynamoDbBackupHits `json:"hits"`
}

type DynamoDbBackupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDynamoDbBackupPaginator(filters []BoolFilter, limit *int64) (DynamoDbBackupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_dynamodb_backup", filters, limit)
	if err != nil {
		return DynamoDbBackupPaginator{}, err
	}

	p := DynamoDbBackupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DynamoDbBackupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DynamoDbBackupPaginator) NextPage(ctx context.Context) ([]DynamoDbBackup, error) {
	var response DynamoDbBackupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DynamoDbBackup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDynamoDbBackupFilters = map[string]string{
	"arn":              "description.Backup.BackupArn",
	"backup_type":      "description.Backup.BackupType",
	"keibi_account_id": "metadata.SourceID",
	"table_name":       "description.Backup.TableName",
}

func ListDynamoDbBackup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDynamoDbBackup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDynamoDbBackupPaginator(buildFilter(d.KeyColumnQuals, listDynamoDbBackupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDynamoDbBackupFilters = map[string]string{
	"arn":              "description.Backup.BackupArn",
	"keibi_account_id": "metadata.SourceID",
}

func GetDynamoDbBackup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDynamoDbBackup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDynamoDbBackupPaginator(buildFilter(d.KeyColumnQuals, getDynamoDbBackupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DynamoDbBackup =============================

// ==========================  START: DynamoDbGlobalTable =============================

type DynamoDbGlobalTable struct {
	Description   aws.DynamoDbGlobalTableDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type DynamoDbGlobalTableHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  DynamoDbGlobalTable `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type DynamoDbGlobalTableHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []DynamoDbGlobalTableHit `json:"hits"`
}

type DynamoDbGlobalTableSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  DynamoDbGlobalTableHits `json:"hits"`
}

type DynamoDbGlobalTablePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDynamoDbGlobalTablePaginator(filters []BoolFilter, limit *int64) (DynamoDbGlobalTablePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_dynamodb_globaltable", filters, limit)
	if err != nil {
		return DynamoDbGlobalTablePaginator{}, err
	}

	p := DynamoDbGlobalTablePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DynamoDbGlobalTablePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DynamoDbGlobalTablePaginator) NextPage(ctx context.Context) ([]DynamoDbGlobalTable, error) {
	var response DynamoDbGlobalTableSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DynamoDbGlobalTable
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDynamoDbGlobalTableFilters = map[string]string{
	"global_table_name": "description.GlobalTable.GlobalTableName",
	"keibi_account_id":  "metadata.SourceID",
}

func ListDynamoDbGlobalTable(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDynamoDbGlobalTable")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDynamoDbGlobalTablePaginator(buildFilter(d.KeyColumnQuals, listDynamoDbGlobalTableFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDynamoDbGlobalTableFilters = map[string]string{
	"global_table_name": "description.GlobalTable.GlobalTableName",
	"keibi_account_id":  "metadata.SourceID",
}

func GetDynamoDbGlobalTable(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDynamoDbGlobalTable")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDynamoDbGlobalTablePaginator(buildFilter(d.KeyColumnQuals, getDynamoDbGlobalTableFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DynamoDbGlobalTable =============================

// ==========================  START: DynamoDbTableExport =============================

type DynamoDbTableExport struct {
	Description   aws.DynamoDbTableExportDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type DynamoDbTableExportHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  DynamoDbTableExport `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type DynamoDbTableExportHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []DynamoDbTableExportHit `json:"hits"`
}

type DynamoDbTableExportSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  DynamoDbTableExportHits `json:"hits"`
}

type DynamoDbTableExportPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDynamoDbTableExportPaginator(filters []BoolFilter, limit *int64) (DynamoDbTableExportPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_dynamodb_tableexport", filters, limit)
	if err != nil {
		return DynamoDbTableExportPaginator{}, err
	}

	p := DynamoDbTableExportPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DynamoDbTableExportPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DynamoDbTableExportPaginator) NextPage(ctx context.Context) ([]DynamoDbTableExport, error) {
	var response DynamoDbTableExportSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DynamoDbTableExport
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDynamoDbTableExportFilters = map[string]string{
	"arn":              "description.Export.ExportArn",
	"keibi_account_id": "metadata.SourceID",
}

func ListDynamoDbTableExport(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDynamoDbTableExport")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDynamoDbTableExportPaginator(buildFilter(d.KeyColumnQuals, listDynamoDbTableExportFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDynamoDbTableExportFilters = map[string]string{
	"arn":              "description.Export.ExportArn",
	"keibi_account_id": "metadata.SourceID",
}

func GetDynamoDbTableExport(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDynamoDbTableExport")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDynamoDbTableExportPaginator(buildFilter(d.KeyColumnQuals, getDynamoDbTableExportFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DynamoDbTableExport =============================

// ==========================  START: DynamoDBMetricAccountProvisionedReadCapacityUtilization =============================

type DynamoDBMetricAccountProvisionedReadCapacityUtilization struct {
	Description   aws.DynamoDBMetricAccountProvisionedReadCapacityUtilizationDescription `json:"description"`
	Metadata      aws.Metadata                                                           `json:"metadata"`
	ResourceJobID int                                                                    `json:"resource_job_id"`
	SourceJobID   int                                                                    `json:"source_job_id"`
	ResourceType  string                                                                 `json:"resource_type"`
	SourceType    string                                                                 `json:"source_type"`
	ID            string                                                                 `json:"id"`
	ARN           string                                                                 `json:"arn"`
	SourceID      string                                                                 `json:"source_id"`
}

type DynamoDBMetricAccountProvisionedReadCapacityUtilizationHit struct {
	ID      string                                                  `json:"_id"`
	Score   float64                                                 `json:"_score"`
	Index   string                                                  `json:"_index"`
	Type    string                                                  `json:"_type"`
	Version int64                                                   `json:"_version,omitempty"`
	Source  DynamoDBMetricAccountProvisionedReadCapacityUtilization `json:"_source"`
	Sort    []interface{}                                           `json:"sort"`
}

type DynamoDBMetricAccountProvisionedReadCapacityUtilizationHits struct {
	Total SearchTotal                                                  `json:"total"`
	Hits  []DynamoDBMetricAccountProvisionedReadCapacityUtilizationHit `json:"hits"`
}

type DynamoDBMetricAccountProvisionedReadCapacityUtilizationSearchResponse struct {
	PitID string                                                      `json:"pit_id"`
	Hits  DynamoDBMetricAccountProvisionedReadCapacityUtilizationHits `json:"hits"`
}

type DynamoDBMetricAccountProvisionedReadCapacityUtilizationPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDynamoDBMetricAccountProvisionedReadCapacityUtilizationPaginator(filters []BoolFilter, limit *int64) (DynamoDBMetricAccountProvisionedReadCapacityUtilizationPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_dynamodb_metricaccountprovisionedreadcapacityutilization", filters, limit)
	if err != nil {
		return DynamoDBMetricAccountProvisionedReadCapacityUtilizationPaginator{}, err
	}

	p := DynamoDBMetricAccountProvisionedReadCapacityUtilizationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DynamoDBMetricAccountProvisionedReadCapacityUtilizationPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DynamoDBMetricAccountProvisionedReadCapacityUtilizationPaginator) NextPage(ctx context.Context) ([]DynamoDBMetricAccountProvisionedReadCapacityUtilization, error) {
	var response DynamoDBMetricAccountProvisionedReadCapacityUtilizationSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DynamoDBMetricAccountProvisionedReadCapacityUtilization
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDynamoDBMetricAccountProvisionedReadCapacityUtilizationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListDynamoDBMetricAccountProvisionedReadCapacityUtilization(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDynamoDBMetricAccountProvisionedReadCapacityUtilization")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDynamoDBMetricAccountProvisionedReadCapacityUtilizationPaginator(buildFilter(d.KeyColumnQuals, listDynamoDBMetricAccountProvisionedReadCapacityUtilizationFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDynamoDBMetricAccountProvisionedReadCapacityUtilizationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetDynamoDBMetricAccountProvisionedReadCapacityUtilization(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDynamoDBMetricAccountProvisionedReadCapacityUtilization")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDynamoDBMetricAccountProvisionedReadCapacityUtilizationPaginator(buildFilter(d.KeyColumnQuals, getDynamoDBMetricAccountProvisionedReadCapacityUtilizationFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DynamoDBMetricAccountProvisionedReadCapacityUtilization =============================

// ==========================  START: DynamoDBMetricAccountProvisionedWriteCapacityUtilization =============================

type DynamoDBMetricAccountProvisionedWriteCapacityUtilization struct {
	Description   aws.DynamoDBMetricAccountProvisionedWriteCapacityUtilizationDescription `json:"description"`
	Metadata      aws.Metadata                                                            `json:"metadata"`
	ResourceJobID int                                                                     `json:"resource_job_id"`
	SourceJobID   int                                                                     `json:"source_job_id"`
	ResourceType  string                                                                  `json:"resource_type"`
	SourceType    string                                                                  `json:"source_type"`
	ID            string                                                                  `json:"id"`
	ARN           string                                                                  `json:"arn"`
	SourceID      string                                                                  `json:"source_id"`
}

type DynamoDBMetricAccountProvisionedWriteCapacityUtilizationHit struct {
	ID      string                                                   `json:"_id"`
	Score   float64                                                  `json:"_score"`
	Index   string                                                   `json:"_index"`
	Type    string                                                   `json:"_type"`
	Version int64                                                    `json:"_version,omitempty"`
	Source  DynamoDBMetricAccountProvisionedWriteCapacityUtilization `json:"_source"`
	Sort    []interface{}                                            `json:"sort"`
}

type DynamoDBMetricAccountProvisionedWriteCapacityUtilizationHits struct {
	Total SearchTotal                                                   `json:"total"`
	Hits  []DynamoDBMetricAccountProvisionedWriteCapacityUtilizationHit `json:"hits"`
}

type DynamoDBMetricAccountProvisionedWriteCapacityUtilizationSearchResponse struct {
	PitID string                                                       `json:"pit_id"`
	Hits  DynamoDBMetricAccountProvisionedWriteCapacityUtilizationHits `json:"hits"`
}

type DynamoDBMetricAccountProvisionedWriteCapacityUtilizationPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDynamoDBMetricAccountProvisionedWriteCapacityUtilizationPaginator(filters []BoolFilter, limit *int64) (DynamoDBMetricAccountProvisionedWriteCapacityUtilizationPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_dynamodb_metricaccountprovisionedwritecapacityutilization", filters, limit)
	if err != nil {
		return DynamoDBMetricAccountProvisionedWriteCapacityUtilizationPaginator{}, err
	}

	p := DynamoDBMetricAccountProvisionedWriteCapacityUtilizationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DynamoDBMetricAccountProvisionedWriteCapacityUtilizationPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DynamoDBMetricAccountProvisionedWriteCapacityUtilizationPaginator) NextPage(ctx context.Context) ([]DynamoDBMetricAccountProvisionedWriteCapacityUtilization, error) {
	var response DynamoDBMetricAccountProvisionedWriteCapacityUtilizationSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DynamoDBMetricAccountProvisionedWriteCapacityUtilization
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDynamoDBMetricAccountProvisionedWriteCapacityUtilizationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListDynamoDBMetricAccountProvisionedWriteCapacityUtilization(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDynamoDBMetricAccountProvisionedWriteCapacityUtilization")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDynamoDBMetricAccountProvisionedWriteCapacityUtilizationPaginator(buildFilter(d.KeyColumnQuals, listDynamoDBMetricAccountProvisionedWriteCapacityUtilizationFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDynamoDBMetricAccountProvisionedWriteCapacityUtilizationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetDynamoDBMetricAccountProvisionedWriteCapacityUtilization(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDynamoDBMetricAccountProvisionedWriteCapacityUtilization")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDynamoDBMetricAccountProvisionedWriteCapacityUtilizationPaginator(buildFilter(d.KeyColumnQuals, getDynamoDBMetricAccountProvisionedWriteCapacityUtilizationFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DynamoDBMetricAccountProvisionedWriteCapacityUtilization =============================

// ==========================  START: EC2VolumeSnapshot =============================

type EC2VolumeSnapshot struct {
	Description   aws.EC2VolumeSnapshotDescription `json:"description"`
	Metadata      aws.Metadata                     `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

type EC2VolumeSnapshotHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  EC2VolumeSnapshot `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type EC2VolumeSnapshotHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []EC2VolumeSnapshotHit `json:"hits"`
}

type EC2VolumeSnapshotSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  EC2VolumeSnapshotHits `json:"hits"`
}

type EC2VolumeSnapshotPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2VolumeSnapshotPaginator(filters []BoolFilter, limit *int64) (EC2VolumeSnapshotPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_volumesnapshot", filters, limit)
	if err != nil {
		return EC2VolumeSnapshotPaginator{}, err
	}

	p := EC2VolumeSnapshotPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2VolumeSnapshotPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2VolumeSnapshotPaginator) NextPage(ctx context.Context) ([]EC2VolumeSnapshot, error) {
	var response EC2VolumeSnapshotSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2VolumeSnapshot
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2VolumeSnapshotFilters = map[string]string{
	"description":      "description.Snapshot.Description",
	"encrypted":        "description.Snapshot.Encrypted",
	"keibi_account_id": "metadata.SourceID",
	"owner_alias":      "description.Snapshot.OwnerAlias",
	"owner_id":         "description.Snapshot.OwnerId",
	"progress":         "description.Snapshot.Progress",
	"snapshot_id":      "description.Snapshot.SnapshotId",
	"state":            "description.Snapshot.State",
	"volume_id":        "description.Snapshot.VolumeId",
	"volume_size":      "description.Snapshot.VolumeSize",
}

func ListEC2VolumeSnapshot(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2VolumeSnapshot")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2VolumeSnapshotPaginator(buildFilter(d.KeyColumnQuals, listEC2VolumeSnapshotFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2VolumeSnapshotFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"snapshot_id":      "description.Snapshot.SnapshotId",
}

func GetEC2VolumeSnapshot(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2VolumeSnapshot")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2VolumeSnapshotPaginator(buildFilter(d.KeyColumnQuals, getEC2VolumeSnapshotFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2VolumeSnapshot =============================

// ==========================  START: EC2Volume =============================

type EC2Volume struct {
	Description   aws.EC2VolumeDescription `json:"description"`
	Metadata      aws.Metadata             `json:"metadata"`
	ResourceJobID int                      `json:"resource_job_id"`
	SourceJobID   int                      `json:"source_job_id"`
	ResourceType  string                   `json:"resource_type"`
	SourceType    string                   `json:"source_type"`
	ID            string                   `json:"id"`
	ARN           string                   `json:"arn"`
	SourceID      string                   `json:"source_id"`
}

type EC2VolumeHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2Volume     `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2VolumeHits struct {
	Total SearchTotal    `json:"total"`
	Hits  []EC2VolumeHit `json:"hits"`
}

type EC2VolumeSearchResponse struct {
	PitID string        `json:"pit_id"`
	Hits  EC2VolumeHits `json:"hits"`
}

type EC2VolumePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2VolumePaginator(filters []BoolFilter, limit *int64) (EC2VolumePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_volume", filters, limit)
	if err != nil {
		return EC2VolumePaginator{}, err
	}

	p := EC2VolumePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2VolumePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2VolumePaginator) NextPage(ctx context.Context) ([]EC2Volume, error) {
	var response EC2VolumeSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2Volume
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2VolumeFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2Volume(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2Volume")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2VolumePaginator(buildFilter(d.KeyColumnQuals, listEC2VolumeFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2VolumeFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"volume_id":        "description.Volume.VolumeId",
}

func GetEC2Volume(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2Volume")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2VolumePaginator(buildFilter(d.KeyColumnQuals, getEC2VolumeFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2Volume =============================

// ==========================  START: EC2Instance =============================

type EC2Instance struct {
	Description   aws.EC2InstanceDescription `json:"description"`
	Metadata      aws.Metadata               `json:"metadata"`
	ResourceJobID int                        `json:"resource_job_id"`
	SourceJobID   int                        `json:"source_job_id"`
	ResourceType  string                     `json:"resource_type"`
	SourceType    string                     `json:"source_type"`
	ID            string                     `json:"id"`
	ARN           string                     `json:"arn"`
	SourceID      string                     `json:"source_id"`
}

type EC2InstanceHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2Instance   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2InstanceHits struct {
	Total SearchTotal      `json:"total"`
	Hits  []EC2InstanceHit `json:"hits"`
}

type EC2InstanceSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  EC2InstanceHits `json:"hits"`
}

type EC2InstancePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2InstancePaginator(filters []BoolFilter, limit *int64) (EC2InstancePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_instance", filters, limit)
	if err != nil {
		return EC2InstancePaginator{}, err
	}

	p := EC2InstancePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2InstancePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2InstancePaginator) NextPage(ctx context.Context) ([]EC2Instance, error) {
	var response EC2InstanceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2Instance
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2InstanceFilters = map[string]string{
	"hypervisor":                  "description.Instance.Hypervisor",
	"iam_instance_profile_arn":    "description.Instance.IamInstanceProfile.Arn",
	"image_id":                    "description.Instance.ImageId",
	"instance_lifecycle":          "description.Instance.InstanceLifecycle",
	"instance_state":              "description.Instance.State.Name",
	"instance_type":               "description.Instance.InstanceType",
	"keibi_account_id":            "metadata.SourceID",
	"monitoring_state":            "description.Instance.Monitoring.State",
	"outpost_arn":                 "description.Instance.OutpostArn",
	"placement_availability_zone": "description.Instance.Placement.AvailabilityZone",
	"placement_group_name":        "description.Instance.Placement.GroupName",
	"placement_tenancy":           "description.Instance.Placement.Tenancy",
	"public_dns_name":             "description.Instance.PublicDnsName",
	"ram_disk_id":                 "description.Instance.RamdiskId",
	"root_device_name":            "description.Instance.RootDeviceName",
	"root_device_type":            "description.Instance.RootDeviceType",
	"subnet_id":                   "description.Instance.SubnetId",
	"virtualization_type":         "description.Instance.VirtualizationType",
	"vpc_id":                      "description.Instance.VpcId",
}

func ListEC2Instance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2Instance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2InstancePaginator(buildFilter(d.KeyColumnQuals, listEC2InstanceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2InstanceFilters = map[string]string{
	"instance_id":      "description.Instance.InstanceId",
	"keibi_account_id": "metadata.SourceID",
}

func GetEC2Instance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2Instance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2InstancePaginator(buildFilter(d.KeyColumnQuals, getEC2InstanceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2Instance =============================

// ==========================  START: EC2Vpc =============================

type EC2Vpc struct {
	Description   aws.EC2VpcDescription `json:"description"`
	Metadata      aws.Metadata          `json:"metadata"`
	ResourceJobID int                   `json:"resource_job_id"`
	SourceJobID   int                   `json:"source_job_id"`
	ResourceType  string                `json:"resource_type"`
	SourceType    string                `json:"source_type"`
	ID            string                `json:"id"`
	ARN           string                `json:"arn"`
	SourceID      string                `json:"source_id"`
}

type EC2VpcHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2Vpc        `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2VpcHits struct {
	Total SearchTotal `json:"total"`
	Hits  []EC2VpcHit `json:"hits"`
}

type EC2VpcSearchResponse struct {
	PitID string     `json:"pit_id"`
	Hits  EC2VpcHits `json:"hits"`
}

type EC2VpcPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2VpcPaginator(filters []BoolFilter, limit *int64) (EC2VpcPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_vpc", filters, limit)
	if err != nil {
		return EC2VpcPaginator{}, err
	}

	p := EC2VpcPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2VpcPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2VpcPaginator) NextPage(ctx context.Context) ([]EC2Vpc, error) {
	var response EC2VpcSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2Vpc
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2VpcFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2Vpc(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2Vpc")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2VpcPaginator(buildFilter(d.KeyColumnQuals, listEC2VpcFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2VpcFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"vpc_id":           "description.Vpc.VpcId",
}

func GetEC2Vpc(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2Vpc")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2VpcPaginator(buildFilter(d.KeyColumnQuals, getEC2VpcFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2Vpc =============================

// ==========================  START: EC2NetworkInterface =============================

type EC2NetworkInterface struct {
	Description   aws.EC2NetworkInterfaceDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type EC2NetworkInterfaceHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  EC2NetworkInterface `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type EC2NetworkInterfaceHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []EC2NetworkInterfaceHit `json:"hits"`
}

type EC2NetworkInterfaceSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  EC2NetworkInterfaceHits `json:"hits"`
}

type EC2NetworkInterfacePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2NetworkInterfacePaginator(filters []BoolFilter, limit *int64) (EC2NetworkInterfacePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_networkinterface", filters, limit)
	if err != nil {
		return EC2NetworkInterfacePaginator{}, err
	}

	p := EC2NetworkInterfacePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2NetworkInterfacePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2NetworkInterfacePaginator) NextPage(ctx context.Context) ([]EC2NetworkInterface, error) {
	var response EC2NetworkInterfaceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2NetworkInterface
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2NetworkInterfaceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2NetworkInterface(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2NetworkInterface")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2NetworkInterfacePaginator(buildFilter(d.KeyColumnQuals, listEC2NetworkInterfaceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2NetworkInterfaceFilters = map[string]string{
	"keibi_account_id":     "metadata.SourceID",
	"network_interface_id": "description.NetworkInterface.NetworkInterfaceId",
}

func GetEC2NetworkInterface(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2NetworkInterface")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2NetworkInterfacePaginator(buildFilter(d.KeyColumnQuals, getEC2NetworkInterfaceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2NetworkInterface =============================

// ==========================  START: EC2RegionalSettings =============================

type EC2RegionalSettings struct {
	Description   aws.EC2RegionalSettingsDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type EC2RegionalSettingsHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  EC2RegionalSettings `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type EC2RegionalSettingsHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []EC2RegionalSettingsHit `json:"hits"`
}

type EC2RegionalSettingsSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  EC2RegionalSettingsHits `json:"hits"`
}

type EC2RegionalSettingsPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2RegionalSettingsPaginator(filters []BoolFilter, limit *int64) (EC2RegionalSettingsPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_regionalsettings", filters, limit)
	if err != nil {
		return EC2RegionalSettingsPaginator{}, err
	}

	p := EC2RegionalSettingsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2RegionalSettingsPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2RegionalSettingsPaginator) NextPage(ctx context.Context) ([]EC2RegionalSettings, error) {
	var response EC2RegionalSettingsSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2RegionalSettings
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2RegionalSettingsFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2RegionalSettings(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2RegionalSettings")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2RegionalSettingsPaginator(buildFilter(d.KeyColumnQuals, listEC2RegionalSettingsFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2RegionalSettingsFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetEC2RegionalSettings(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2RegionalSettings")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2RegionalSettingsPaginator(buildFilter(d.KeyColumnQuals, getEC2RegionalSettingsFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2RegionalSettings =============================

// ==========================  START: EbsVolumeMetricReadOps =============================

type EbsVolumeMetricReadOps struct {
	Description   aws.EbsVolumeMetricReadOpsDescription `json:"description"`
	Metadata      aws.Metadata                          `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

type EbsVolumeMetricReadOpsHit struct {
	ID      string                 `json:"_id"`
	Score   float64                `json:"_score"`
	Index   string                 `json:"_index"`
	Type    string                 `json:"_type"`
	Version int64                  `json:"_version,omitempty"`
	Source  EbsVolumeMetricReadOps `json:"_source"`
	Sort    []interface{}          `json:"sort"`
}

type EbsVolumeMetricReadOpsHits struct {
	Total SearchTotal                 `json:"total"`
	Hits  []EbsVolumeMetricReadOpsHit `json:"hits"`
}

type EbsVolumeMetricReadOpsSearchResponse struct {
	PitID string                     `json:"pit_id"`
	Hits  EbsVolumeMetricReadOpsHits `json:"hits"`
}

type EbsVolumeMetricReadOpsPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEbsVolumeMetricReadOpsPaginator(filters []BoolFilter, limit *int64) (EbsVolumeMetricReadOpsPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_ebsvolumemetricreadops", filters, limit)
	if err != nil {
		return EbsVolumeMetricReadOpsPaginator{}, err
	}

	p := EbsVolumeMetricReadOpsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EbsVolumeMetricReadOpsPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EbsVolumeMetricReadOpsPaginator) NextPage(ctx context.Context) ([]EbsVolumeMetricReadOps, error) {
	var response EbsVolumeMetricReadOpsSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EbsVolumeMetricReadOps
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEbsVolumeMetricReadOpsFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEbsVolumeMetricReadOps(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEbsVolumeMetricReadOps")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEbsVolumeMetricReadOpsPaginator(buildFilter(d.KeyColumnQuals, listEbsVolumeMetricReadOpsFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEbsVolumeMetricReadOpsFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetEbsVolumeMetricReadOps(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEbsVolumeMetricReadOps")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEbsVolumeMetricReadOpsPaginator(buildFilter(d.KeyColumnQuals, getEbsVolumeMetricReadOpsFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EbsVolumeMetricReadOps =============================

// ==========================  START: EbsVolumeMetricReadOpsDaily =============================

type EbsVolumeMetricReadOpsDaily struct {
	Description   aws.EbsVolumeMetricReadOpsDailyDescription `json:"description"`
	Metadata      aws.Metadata                               `json:"metadata"`
	ResourceJobID int                                        `json:"resource_job_id"`
	SourceJobID   int                                        `json:"source_job_id"`
	ResourceType  string                                     `json:"resource_type"`
	SourceType    string                                     `json:"source_type"`
	ID            string                                     `json:"id"`
	ARN           string                                     `json:"arn"`
	SourceID      string                                     `json:"source_id"`
}

type EbsVolumeMetricReadOpsDailyHit struct {
	ID      string                      `json:"_id"`
	Score   float64                     `json:"_score"`
	Index   string                      `json:"_index"`
	Type    string                      `json:"_type"`
	Version int64                       `json:"_version,omitempty"`
	Source  EbsVolumeMetricReadOpsDaily `json:"_source"`
	Sort    []interface{}               `json:"sort"`
}

type EbsVolumeMetricReadOpsDailyHits struct {
	Total SearchTotal                      `json:"total"`
	Hits  []EbsVolumeMetricReadOpsDailyHit `json:"hits"`
}

type EbsVolumeMetricReadOpsDailySearchResponse struct {
	PitID string                          `json:"pit_id"`
	Hits  EbsVolumeMetricReadOpsDailyHits `json:"hits"`
}

type EbsVolumeMetricReadOpsDailyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEbsVolumeMetricReadOpsDailyPaginator(filters []BoolFilter, limit *int64) (EbsVolumeMetricReadOpsDailyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_ebsvolumemetricreadopsdaily", filters, limit)
	if err != nil {
		return EbsVolumeMetricReadOpsDailyPaginator{}, err
	}

	p := EbsVolumeMetricReadOpsDailyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EbsVolumeMetricReadOpsDailyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EbsVolumeMetricReadOpsDailyPaginator) NextPage(ctx context.Context) ([]EbsVolumeMetricReadOpsDaily, error) {
	var response EbsVolumeMetricReadOpsDailySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EbsVolumeMetricReadOpsDaily
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEbsVolumeMetricReadOpsDailyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEbsVolumeMetricReadOpsDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEbsVolumeMetricReadOpsDaily")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEbsVolumeMetricReadOpsDailyPaginator(buildFilter(d.KeyColumnQuals, listEbsVolumeMetricReadOpsDailyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEbsVolumeMetricReadOpsDailyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetEbsVolumeMetricReadOpsDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEbsVolumeMetricReadOpsDaily")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEbsVolumeMetricReadOpsDailyPaginator(buildFilter(d.KeyColumnQuals, getEbsVolumeMetricReadOpsDailyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EbsVolumeMetricReadOpsDaily =============================

// ==========================  START: EbsVolumeMetricReadOpsHourly =============================

type EbsVolumeMetricReadOpsHourly struct {
	Description   aws.EbsVolumeMetricReadOpsHourlyDescription `json:"description"`
	Metadata      aws.Metadata                                `json:"metadata"`
	ResourceJobID int                                         `json:"resource_job_id"`
	SourceJobID   int                                         `json:"source_job_id"`
	ResourceType  string                                      `json:"resource_type"`
	SourceType    string                                      `json:"source_type"`
	ID            string                                      `json:"id"`
	ARN           string                                      `json:"arn"`
	SourceID      string                                      `json:"source_id"`
}

type EbsVolumeMetricReadOpsHourlyHit struct {
	ID      string                       `json:"_id"`
	Score   float64                      `json:"_score"`
	Index   string                       `json:"_index"`
	Type    string                       `json:"_type"`
	Version int64                        `json:"_version,omitempty"`
	Source  EbsVolumeMetricReadOpsHourly `json:"_source"`
	Sort    []interface{}                `json:"sort"`
}

type EbsVolumeMetricReadOpsHourlyHits struct {
	Total SearchTotal                       `json:"total"`
	Hits  []EbsVolumeMetricReadOpsHourlyHit `json:"hits"`
}

type EbsVolumeMetricReadOpsHourlySearchResponse struct {
	PitID string                           `json:"pit_id"`
	Hits  EbsVolumeMetricReadOpsHourlyHits `json:"hits"`
}

type EbsVolumeMetricReadOpsHourlyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEbsVolumeMetricReadOpsHourlyPaginator(filters []BoolFilter, limit *int64) (EbsVolumeMetricReadOpsHourlyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_ebsvolumemetricreadopshourly", filters, limit)
	if err != nil {
		return EbsVolumeMetricReadOpsHourlyPaginator{}, err
	}

	p := EbsVolumeMetricReadOpsHourlyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EbsVolumeMetricReadOpsHourlyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EbsVolumeMetricReadOpsHourlyPaginator) NextPage(ctx context.Context) ([]EbsVolumeMetricReadOpsHourly, error) {
	var response EbsVolumeMetricReadOpsHourlySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EbsVolumeMetricReadOpsHourly
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEbsVolumeMetricReadOpsHourlyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEbsVolumeMetricReadOpsHourly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEbsVolumeMetricReadOpsHourly")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEbsVolumeMetricReadOpsHourlyPaginator(buildFilter(d.KeyColumnQuals, listEbsVolumeMetricReadOpsHourlyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEbsVolumeMetricReadOpsHourlyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetEbsVolumeMetricReadOpsHourly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEbsVolumeMetricReadOpsHourly")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEbsVolumeMetricReadOpsHourlyPaginator(buildFilter(d.KeyColumnQuals, getEbsVolumeMetricReadOpsHourlyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EbsVolumeMetricReadOpsHourly =============================

// ==========================  START: EbsVolumeMetricWriteOps =============================

type EbsVolumeMetricWriteOps struct {
	Description   aws.EbsVolumeMetricWriteOpsDescription `json:"description"`
	Metadata      aws.Metadata                           `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

type EbsVolumeMetricWriteOpsHit struct {
	ID      string                  `json:"_id"`
	Score   float64                 `json:"_score"`
	Index   string                  `json:"_index"`
	Type    string                  `json:"_type"`
	Version int64                   `json:"_version,omitempty"`
	Source  EbsVolumeMetricWriteOps `json:"_source"`
	Sort    []interface{}           `json:"sort"`
}

type EbsVolumeMetricWriteOpsHits struct {
	Total SearchTotal                  `json:"total"`
	Hits  []EbsVolumeMetricWriteOpsHit `json:"hits"`
}

type EbsVolumeMetricWriteOpsSearchResponse struct {
	PitID string                      `json:"pit_id"`
	Hits  EbsVolumeMetricWriteOpsHits `json:"hits"`
}

type EbsVolumeMetricWriteOpsPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEbsVolumeMetricWriteOpsPaginator(filters []BoolFilter, limit *int64) (EbsVolumeMetricWriteOpsPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_ebsvolumemetricwriteops", filters, limit)
	if err != nil {
		return EbsVolumeMetricWriteOpsPaginator{}, err
	}

	p := EbsVolumeMetricWriteOpsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EbsVolumeMetricWriteOpsPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EbsVolumeMetricWriteOpsPaginator) NextPage(ctx context.Context) ([]EbsVolumeMetricWriteOps, error) {
	var response EbsVolumeMetricWriteOpsSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EbsVolumeMetricWriteOps
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEbsVolumeMetricWriteOpsFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEbsVolumeMetricWriteOps(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEbsVolumeMetricWriteOps")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEbsVolumeMetricWriteOpsPaginator(buildFilter(d.KeyColumnQuals, listEbsVolumeMetricWriteOpsFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEbsVolumeMetricWriteOpsFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetEbsVolumeMetricWriteOps(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEbsVolumeMetricWriteOps")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEbsVolumeMetricWriteOpsPaginator(buildFilter(d.KeyColumnQuals, getEbsVolumeMetricWriteOpsFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EbsVolumeMetricWriteOps =============================

// ==========================  START: EbsVolumeMetricWriteOpsDaily =============================

type EbsVolumeMetricWriteOpsDaily struct {
	Description   aws.EbsVolumeMetricWriteOpsDailyDescription `json:"description"`
	Metadata      aws.Metadata                                `json:"metadata"`
	ResourceJobID int                                         `json:"resource_job_id"`
	SourceJobID   int                                         `json:"source_job_id"`
	ResourceType  string                                      `json:"resource_type"`
	SourceType    string                                      `json:"source_type"`
	ID            string                                      `json:"id"`
	ARN           string                                      `json:"arn"`
	SourceID      string                                      `json:"source_id"`
}

type EbsVolumeMetricWriteOpsDailyHit struct {
	ID      string                       `json:"_id"`
	Score   float64                      `json:"_score"`
	Index   string                       `json:"_index"`
	Type    string                       `json:"_type"`
	Version int64                        `json:"_version,omitempty"`
	Source  EbsVolumeMetricWriteOpsDaily `json:"_source"`
	Sort    []interface{}                `json:"sort"`
}

type EbsVolumeMetricWriteOpsDailyHits struct {
	Total SearchTotal                       `json:"total"`
	Hits  []EbsVolumeMetricWriteOpsDailyHit `json:"hits"`
}

type EbsVolumeMetricWriteOpsDailySearchResponse struct {
	PitID string                           `json:"pit_id"`
	Hits  EbsVolumeMetricWriteOpsDailyHits `json:"hits"`
}

type EbsVolumeMetricWriteOpsDailyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEbsVolumeMetricWriteOpsDailyPaginator(filters []BoolFilter, limit *int64) (EbsVolumeMetricWriteOpsDailyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_ebsvolumemetricwriteopsdaily", filters, limit)
	if err != nil {
		return EbsVolumeMetricWriteOpsDailyPaginator{}, err
	}

	p := EbsVolumeMetricWriteOpsDailyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EbsVolumeMetricWriteOpsDailyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EbsVolumeMetricWriteOpsDailyPaginator) NextPage(ctx context.Context) ([]EbsVolumeMetricWriteOpsDaily, error) {
	var response EbsVolumeMetricWriteOpsDailySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EbsVolumeMetricWriteOpsDaily
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEbsVolumeMetricWriteOpsDailyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEbsVolumeMetricWriteOpsDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEbsVolumeMetricWriteOpsDaily")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEbsVolumeMetricWriteOpsDailyPaginator(buildFilter(d.KeyColumnQuals, listEbsVolumeMetricWriteOpsDailyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEbsVolumeMetricWriteOpsDailyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetEbsVolumeMetricWriteOpsDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEbsVolumeMetricWriteOpsDaily")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEbsVolumeMetricWriteOpsDailyPaginator(buildFilter(d.KeyColumnQuals, getEbsVolumeMetricWriteOpsDailyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EbsVolumeMetricWriteOpsDaily =============================

// ==========================  START: EbsVolumeMetricWriteOpsHourly =============================

type EbsVolumeMetricWriteOpsHourly struct {
	Description   aws.EbsVolumeMetricWriteOpsHourlyDescription `json:"description"`
	Metadata      aws.Metadata                                 `json:"metadata"`
	ResourceJobID int                                          `json:"resource_job_id"`
	SourceJobID   int                                          `json:"source_job_id"`
	ResourceType  string                                       `json:"resource_type"`
	SourceType    string                                       `json:"source_type"`
	ID            string                                       `json:"id"`
	ARN           string                                       `json:"arn"`
	SourceID      string                                       `json:"source_id"`
}

type EbsVolumeMetricWriteOpsHourlyHit struct {
	ID      string                        `json:"_id"`
	Score   float64                       `json:"_score"`
	Index   string                        `json:"_index"`
	Type    string                        `json:"_type"`
	Version int64                         `json:"_version,omitempty"`
	Source  EbsVolumeMetricWriteOpsHourly `json:"_source"`
	Sort    []interface{}                 `json:"sort"`
}

type EbsVolumeMetricWriteOpsHourlyHits struct {
	Total SearchTotal                        `json:"total"`
	Hits  []EbsVolumeMetricWriteOpsHourlyHit `json:"hits"`
}

type EbsVolumeMetricWriteOpsHourlySearchResponse struct {
	PitID string                            `json:"pit_id"`
	Hits  EbsVolumeMetricWriteOpsHourlyHits `json:"hits"`
}

type EbsVolumeMetricWriteOpsHourlyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEbsVolumeMetricWriteOpsHourlyPaginator(filters []BoolFilter, limit *int64) (EbsVolumeMetricWriteOpsHourlyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_ebsvolumemetricwriteopshourly", filters, limit)
	if err != nil {
		return EbsVolumeMetricWriteOpsHourlyPaginator{}, err
	}

	p := EbsVolumeMetricWriteOpsHourlyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EbsVolumeMetricWriteOpsHourlyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EbsVolumeMetricWriteOpsHourlyPaginator) NextPage(ctx context.Context) ([]EbsVolumeMetricWriteOpsHourly, error) {
	var response EbsVolumeMetricWriteOpsHourlySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EbsVolumeMetricWriteOpsHourly
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEbsVolumeMetricWriteOpsHourlyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEbsVolumeMetricWriteOpsHourly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEbsVolumeMetricWriteOpsHourly")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEbsVolumeMetricWriteOpsHourlyPaginator(buildFilter(d.KeyColumnQuals, listEbsVolumeMetricWriteOpsHourlyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEbsVolumeMetricWriteOpsHourlyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetEbsVolumeMetricWriteOpsHourly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEbsVolumeMetricWriteOpsHourly")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEbsVolumeMetricWriteOpsHourlyPaginator(buildFilter(d.KeyColumnQuals, getEbsVolumeMetricWriteOpsHourlyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EbsVolumeMetricWriteOpsHourly =============================

// ==========================  START: EC2Subnet =============================

type EC2Subnet struct {
	Description   aws.EC2SubnetDescription `json:"description"`
	Metadata      aws.Metadata             `json:"metadata"`
	ResourceJobID int                      `json:"resource_job_id"`
	SourceJobID   int                      `json:"source_job_id"`
	ResourceType  string                   `json:"resource_type"`
	SourceType    string                   `json:"source_type"`
	ID            string                   `json:"id"`
	ARN           string                   `json:"arn"`
	SourceID      string                   `json:"source_id"`
}

type EC2SubnetHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2Subnet     `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2SubnetHits struct {
	Total SearchTotal    `json:"total"`
	Hits  []EC2SubnetHit `json:"hits"`
}

type EC2SubnetSearchResponse struct {
	PitID string        `json:"pit_id"`
	Hits  EC2SubnetHits `json:"hits"`
}

type EC2SubnetPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2SubnetPaginator(filters []BoolFilter, limit *int64) (EC2SubnetPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_subnet", filters, limit)
	if err != nil {
		return EC2SubnetPaginator{}, err
	}

	p := EC2SubnetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2SubnetPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2SubnetPaginator) NextPage(ctx context.Context) ([]EC2Subnet, error) {
	var response EC2SubnetSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2Subnet
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2SubnetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2Subnet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2Subnet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2SubnetPaginator(buildFilter(d.KeyColumnQuals, listEC2SubnetFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2SubnetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"subnet_id":        "description.Subnet.SubnetId",
}

func GetEC2Subnet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2Subnet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2SubnetPaginator(buildFilter(d.KeyColumnQuals, getEC2SubnetFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2Subnet =============================

// ==========================  START: EC2VPCEndpoint =============================

type EC2VPCEndpoint struct {
	Description   aws.EC2VPCEndpointDescription `json:"description"`
	Metadata      aws.Metadata                  `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

type EC2VPCEndpointHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  EC2VPCEndpoint `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type EC2VPCEndpointHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []EC2VPCEndpointHit `json:"hits"`
}

type EC2VPCEndpointSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  EC2VPCEndpointHits `json:"hits"`
}

type EC2VPCEndpointPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2VPCEndpointPaginator(filters []BoolFilter, limit *int64) (EC2VPCEndpointPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_vpcendpoint", filters, limit)
	if err != nil {
		return EC2VPCEndpointPaginator{}, err
	}

	p := EC2VPCEndpointPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2VPCEndpointPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2VPCEndpointPaginator) NextPage(ctx context.Context) ([]EC2VPCEndpoint, error) {
	var response EC2VPCEndpointSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2VPCEndpoint
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2VPCEndpointFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2VPCEndpoint(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2VPCEndpoint")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2VPCEndpointPaginator(buildFilter(d.KeyColumnQuals, listEC2VPCEndpointFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2VPCEndpointFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"vpc_endpoint_id":  "description.VpcEndpoint.VpcEndpointId",
}

func GetEC2VPCEndpoint(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2VPCEndpoint")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2VPCEndpointPaginator(buildFilter(d.KeyColumnQuals, getEC2VPCEndpointFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2VPCEndpoint =============================

// ==========================  START: EC2SecurityGroup =============================

type EC2SecurityGroup struct {
	Description   aws.EC2SecurityGroupDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type EC2SecurityGroupHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  EC2SecurityGroup `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type EC2SecurityGroupHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []EC2SecurityGroupHit `json:"hits"`
}

type EC2SecurityGroupSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  EC2SecurityGroupHits `json:"hits"`
}

type EC2SecurityGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2SecurityGroupPaginator(filters []BoolFilter, limit *int64) (EC2SecurityGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_securitygroup", filters, limit)
	if err != nil {
		return EC2SecurityGroupPaginator{}, err
	}

	p := EC2SecurityGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2SecurityGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2SecurityGroupPaginator) NextPage(ctx context.Context) ([]EC2SecurityGroup, error) {
	var response EC2SecurityGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2SecurityGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2SecurityGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2SecurityGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2SecurityGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2SecurityGroupPaginator(buildFilter(d.KeyColumnQuals, listEC2SecurityGroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2SecurityGroupFilters = map[string]string{
	"group_id":         "description.SecurityGroup.GroupId",
	"keibi_account_id": "metadata.SourceID",
}

func GetEC2SecurityGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2SecurityGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2SecurityGroupPaginator(buildFilter(d.KeyColumnQuals, getEC2SecurityGroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2SecurityGroup =============================

// ==========================  START: EC2EIP =============================

type EC2EIP struct {
	Description   aws.EC2EIPDescription `json:"description"`
	Metadata      aws.Metadata          `json:"metadata"`
	ResourceJobID int                   `json:"resource_job_id"`
	SourceJobID   int                   `json:"source_job_id"`
	ResourceType  string                `json:"resource_type"`
	SourceType    string                `json:"source_type"`
	ID            string                `json:"id"`
	ARN           string                `json:"arn"`
	SourceID      string                `json:"source_id"`
}

type EC2EIPHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2EIP        `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2EIPHits struct {
	Total SearchTotal `json:"total"`
	Hits  []EC2EIPHit `json:"hits"`
}

type EC2EIPSearchResponse struct {
	PitID string     `json:"pit_id"`
	Hits  EC2EIPHits `json:"hits"`
}

type EC2EIPPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2EIPPaginator(filters []BoolFilter, limit *int64) (EC2EIPPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_eip", filters, limit)
	if err != nil {
		return EC2EIPPaginator{}, err
	}

	p := EC2EIPPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2EIPPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2EIPPaginator) NextPage(ctx context.Context) ([]EC2EIP, error) {
	var response EC2EIPSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2EIP
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2EIPFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2EIP(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2EIP")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2EIPPaginator(buildFilter(d.KeyColumnQuals, listEC2EIPFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2EIPFilters = map[string]string{
	"allocation_id":    "description.SecurityGroup.AllocationId",
	"keibi_account_id": "metadata.SourceID",
}

func GetEC2EIP(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2EIP")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2EIPPaginator(buildFilter(d.KeyColumnQuals, getEC2EIPFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2EIP =============================

// ==========================  START: EC2InternetGateway =============================

type EC2InternetGateway struct {
	Description   aws.EC2InternetGatewayDescription `json:"description"`
	Metadata      aws.Metadata                      `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

type EC2InternetGatewayHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  EC2InternetGateway `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type EC2InternetGatewayHits struct {
	Total SearchTotal             `json:"total"`
	Hits  []EC2InternetGatewayHit `json:"hits"`
}

type EC2InternetGatewaySearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  EC2InternetGatewayHits `json:"hits"`
}

type EC2InternetGatewayPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2InternetGatewayPaginator(filters []BoolFilter, limit *int64) (EC2InternetGatewayPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_internetgateway", filters, limit)
	if err != nil {
		return EC2InternetGatewayPaginator{}, err
	}

	p := EC2InternetGatewayPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2InternetGatewayPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2InternetGatewayPaginator) NextPage(ctx context.Context) ([]EC2InternetGateway, error) {
	var response EC2InternetGatewaySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2InternetGateway
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2InternetGatewayFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2InternetGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2InternetGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2InternetGatewayPaginator(buildFilter(d.KeyColumnQuals, listEC2InternetGatewayFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2InternetGatewayFilters = map[string]string{
	"internet_gateway_id": "description.InternetGateway.InternetGatewayId",
	"keibi_account_id":    "metadata.SourceID",
}

func GetEC2InternetGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2InternetGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2InternetGatewayPaginator(buildFilter(d.KeyColumnQuals, getEC2InternetGatewayFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2InternetGateway =============================

// ==========================  START: EC2NetworkAcl =============================

type EC2NetworkAcl struct {
	Description   aws.EC2NetworkAclDescription `json:"description"`
	Metadata      aws.Metadata                 `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

type EC2NetworkAclHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2NetworkAcl `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2NetworkAclHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []EC2NetworkAclHit `json:"hits"`
}

type EC2NetworkAclSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  EC2NetworkAclHits `json:"hits"`
}

type EC2NetworkAclPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2NetworkAclPaginator(filters []BoolFilter, limit *int64) (EC2NetworkAclPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_networkacl", filters, limit)
	if err != nil {
		return EC2NetworkAclPaginator{}, err
	}

	p := EC2NetworkAclPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2NetworkAclPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2NetworkAclPaginator) NextPage(ctx context.Context) ([]EC2NetworkAcl, error) {
	var response EC2NetworkAclSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2NetworkAcl
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2NetworkAclFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2NetworkAcl(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2NetworkAcl")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2NetworkAclPaginator(buildFilter(d.KeyColumnQuals, listEC2NetworkAclFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2NetworkAclFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"network_acl_id":   "description.NetworkAcl.NetworkAclId",
}

func GetEC2NetworkAcl(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2NetworkAcl")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2NetworkAclPaginator(buildFilter(d.KeyColumnQuals, getEC2NetworkAclFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2NetworkAcl =============================

// ==========================  START: EC2VPNConnection =============================

type EC2VPNConnection struct {
	Description   aws.EC2VPNConnectionDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type EC2VPNConnectionHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  EC2VPNConnection `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type EC2VPNConnectionHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []EC2VPNConnectionHit `json:"hits"`
}

type EC2VPNConnectionSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  EC2VPNConnectionHits `json:"hits"`
}

type EC2VPNConnectionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2VPNConnectionPaginator(filters []BoolFilter, limit *int64) (EC2VPNConnectionPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_vpnconnection", filters, limit)
	if err != nil {
		return EC2VPNConnectionPaginator{}, err
	}

	p := EC2VPNConnectionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2VPNConnectionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2VPNConnectionPaginator) NextPage(ctx context.Context) ([]EC2VPNConnection, error) {
	var response EC2VPNConnectionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2VPNConnection
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2VPNConnectionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2VPNConnection(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2VPNConnection")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2VPNConnectionPaginator(buildFilter(d.KeyColumnQuals, listEC2VPNConnectionFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2VPNConnectionFilters = map[string]string{
	"keibi_account_id":  "metadata.SourceID",
	"vpn_connection_id": "description.VpnConnection.VpnConnectionId",
}

func GetEC2VPNConnection(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2VPNConnection")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2VPNConnectionPaginator(buildFilter(d.KeyColumnQuals, getEC2VPNConnectionFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2VPNConnection =============================

// ==========================  START: EC2RouteTable =============================

type EC2RouteTable struct {
	Description   aws.EC2RouteTableDescription `json:"description"`
	Metadata      aws.Metadata                 `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

type EC2RouteTableHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2RouteTable `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2RouteTableHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []EC2RouteTableHit `json:"hits"`
}

type EC2RouteTableSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  EC2RouteTableHits `json:"hits"`
}

type EC2RouteTablePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2RouteTablePaginator(filters []BoolFilter, limit *int64) (EC2RouteTablePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_routetable", filters, limit)
	if err != nil {
		return EC2RouteTablePaginator{}, err
	}

	p := EC2RouteTablePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2RouteTablePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2RouteTablePaginator) NextPage(ctx context.Context) ([]EC2RouteTable, error) {
	var response EC2RouteTableSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2RouteTable
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2RouteTableFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2RouteTable(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2RouteTable")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2RouteTablePaginator(buildFilter(d.KeyColumnQuals, listEC2RouteTableFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2RouteTableFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"route_table_id":   "description.RouteTable.RouteTableId",
}

func GetEC2RouteTable(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2RouteTable")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2RouteTablePaginator(buildFilter(d.KeyColumnQuals, getEC2RouteTableFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2RouteTable =============================

// ==========================  START: EC2NatGateway =============================

type EC2NatGateway struct {
	Description   aws.EC2NatGatewayDescription `json:"description"`
	Metadata      aws.Metadata                 `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

type EC2NatGatewayHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2NatGateway `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2NatGatewayHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []EC2NatGatewayHit `json:"hits"`
}

type EC2NatGatewaySearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  EC2NatGatewayHits `json:"hits"`
}

type EC2NatGatewayPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2NatGatewayPaginator(filters []BoolFilter, limit *int64) (EC2NatGatewayPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_natgateway", filters, limit)
	if err != nil {
		return EC2NatGatewayPaginator{}, err
	}

	p := EC2NatGatewayPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2NatGatewayPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2NatGatewayPaginator) NextPage(ctx context.Context) ([]EC2NatGateway, error) {
	var response EC2NatGatewaySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2NatGateway
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2NatGatewayFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2NatGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2NatGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2NatGatewayPaginator(buildFilter(d.KeyColumnQuals, listEC2NatGatewayFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2NatGatewayFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"nat_gateway_id":   "description.NatGateway.NatGatewayId",
}

func GetEC2NatGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2NatGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2NatGatewayPaginator(buildFilter(d.KeyColumnQuals, getEC2NatGatewayFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2NatGateway =============================

// ==========================  START: EC2Region =============================

type EC2Region struct {
	Description   aws.EC2RegionDescription `json:"description"`
	Metadata      aws.Metadata             `json:"metadata"`
	ResourceJobID int                      `json:"resource_job_id"`
	SourceJobID   int                      `json:"source_job_id"`
	ResourceType  string                   `json:"resource_type"`
	SourceType    string                   `json:"source_type"`
	ID            string                   `json:"id"`
	ARN           string                   `json:"arn"`
	SourceID      string                   `json:"source_id"`
}

type EC2RegionHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2Region     `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2RegionHits struct {
	Total SearchTotal    `json:"total"`
	Hits  []EC2RegionHit `json:"hits"`
}

type EC2RegionSearchResponse struct {
	PitID string        `json:"pit_id"`
	Hits  EC2RegionHits `json:"hits"`
}

type EC2RegionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2RegionPaginator(filters []BoolFilter, limit *int64) (EC2RegionPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_region", filters, limit)
	if err != nil {
		return EC2RegionPaginator{}, err
	}

	p := EC2RegionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2RegionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2RegionPaginator) NextPage(ctx context.Context) ([]EC2Region, error) {
	var response EC2RegionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2Region
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2RegionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2Region(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2Region")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2RegionPaginator(buildFilter(d.KeyColumnQuals, listEC2RegionFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2RegionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Region.RegionName",
}

func GetEC2Region(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2Region")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2RegionPaginator(buildFilter(d.KeyColumnQuals, getEC2RegionFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2Region =============================

// ==========================  START: EC2AvailabilityZone =============================

type EC2AvailabilityZone struct {
	Description   aws.EC2AvailabilityZoneDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type EC2AvailabilityZoneHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  EC2AvailabilityZone `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type EC2AvailabilityZoneHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []EC2AvailabilityZoneHit `json:"hits"`
}

type EC2AvailabilityZoneSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  EC2AvailabilityZoneHits `json:"hits"`
}

type EC2AvailabilityZonePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2AvailabilityZonePaginator(filters []BoolFilter, limit *int64) (EC2AvailabilityZonePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_availabilityzone", filters, limit)
	if err != nil {
		return EC2AvailabilityZonePaginator{}, err
	}

	p := EC2AvailabilityZonePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2AvailabilityZonePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2AvailabilityZonePaginator) NextPage(ctx context.Context) ([]EC2AvailabilityZone, error) {
	var response EC2AvailabilityZoneSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2AvailabilityZone
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2AvailabilityZoneFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.AvailabilityZone.ZoneName",
	"zone_id":          "description.AvailabilityZone.ZoneId",
}

func ListEC2AvailabilityZone(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2AvailabilityZone")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2AvailabilityZonePaginator(buildFilter(d.KeyColumnQuals, listEC2AvailabilityZoneFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2AvailabilityZoneFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.AvailabilityZone.ZoneName",
	"region_name":      "description.AvailabilityZone.RegionName",
}

func GetEC2AvailabilityZone(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2AvailabilityZone")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2AvailabilityZonePaginator(buildFilter(d.KeyColumnQuals, getEC2AvailabilityZoneFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2AvailabilityZone =============================

// ==========================  START: EC2FlowLog =============================

type EC2FlowLog struct {
	Description   aws.EC2FlowLogDescription `json:"description"`
	Metadata      aws.Metadata              `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	ARN           string                    `json:"arn"`
	SourceID      string                    `json:"source_id"`
}

type EC2FlowLogHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2FlowLog    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2FlowLogHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []EC2FlowLogHit `json:"hits"`
}

type EC2FlowLogSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  EC2FlowLogHits `json:"hits"`
}

type EC2FlowLogPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2FlowLogPaginator(filters []BoolFilter, limit *int64) (EC2FlowLogPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_flowlog", filters, limit)
	if err != nil {
		return EC2FlowLogPaginator{}, err
	}

	p := EC2FlowLogPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2FlowLogPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2FlowLogPaginator) NextPage(ctx context.Context) ([]EC2FlowLog, error) {
	var response EC2FlowLogSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2FlowLog
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2FlowLogFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2FlowLog(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2FlowLog")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2FlowLogPaginator(buildFilter(d.KeyColumnQuals, listEC2FlowLogFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2FlowLogFilters = map[string]string{
	"flow_log_id":      "description.FlowLog.FlowLogId",
	"keibi_account_id": "metadata.SourceID",
}

func GetEC2FlowLog(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2FlowLog")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2FlowLogPaginator(buildFilter(d.KeyColumnQuals, getEC2FlowLogFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2FlowLog =============================

// ==========================  START: EC2CapacityReservation =============================

type EC2CapacityReservation struct {
	Description   aws.EC2CapacityReservationDescription `json:"description"`
	Metadata      aws.Metadata                          `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

type EC2CapacityReservationHit struct {
	ID      string                 `json:"_id"`
	Score   float64                `json:"_score"`
	Index   string                 `json:"_index"`
	Type    string                 `json:"_type"`
	Version int64                  `json:"_version,omitempty"`
	Source  EC2CapacityReservation `json:"_source"`
	Sort    []interface{}          `json:"sort"`
}

type EC2CapacityReservationHits struct {
	Total SearchTotal                 `json:"total"`
	Hits  []EC2CapacityReservationHit `json:"hits"`
}

type EC2CapacityReservationSearchResponse struct {
	PitID string                     `json:"pit_id"`
	Hits  EC2CapacityReservationHits `json:"hits"`
}

type EC2CapacityReservationPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2CapacityReservationPaginator(filters []BoolFilter, limit *int64) (EC2CapacityReservationPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_capacityreservation", filters, limit)
	if err != nil {
		return EC2CapacityReservationPaginator{}, err
	}

	p := EC2CapacityReservationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2CapacityReservationPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2CapacityReservationPaginator) NextPage(ctx context.Context) ([]EC2CapacityReservation, error) {
	var response EC2CapacityReservationSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2CapacityReservation
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2CapacityReservationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2CapacityReservation(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2CapacityReservation")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2CapacityReservationPaginator(buildFilter(d.KeyColumnQuals, listEC2CapacityReservationFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2CapacityReservationFilters = map[string]string{
	"capacity_reservation_id": "description.CapacityReservation.CapacityReservationId",
	"keibi_account_id":        "metadata.SourceID",
}

func GetEC2CapacityReservation(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2CapacityReservation")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2CapacityReservationPaginator(buildFilter(d.KeyColumnQuals, getEC2CapacityReservationFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2CapacityReservation =============================

// ==========================  START: EC2KeyPair =============================

type EC2KeyPair struct {
	Description   aws.EC2KeyPairDescription `json:"description"`
	Metadata      aws.Metadata              `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	ARN           string                    `json:"arn"`
	SourceID      string                    `json:"source_id"`
}

type EC2KeyPairHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2KeyPair    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2KeyPairHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []EC2KeyPairHit `json:"hits"`
}

type EC2KeyPairSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  EC2KeyPairHits `json:"hits"`
}

type EC2KeyPairPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2KeyPairPaginator(filters []BoolFilter, limit *int64) (EC2KeyPairPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_keypair", filters, limit)
	if err != nil {
		return EC2KeyPairPaginator{}, err
	}

	p := EC2KeyPairPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2KeyPairPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2KeyPairPaginator) NextPage(ctx context.Context) ([]EC2KeyPair, error) {
	var response EC2KeyPairSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2KeyPair
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2KeyPairFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2KeyPair(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2KeyPair")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2KeyPairPaginator(buildFilter(d.KeyColumnQuals, listEC2KeyPairFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2KeyPairFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"key_name":         "description.KeyPair.KeyName",
}

func GetEC2KeyPair(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2KeyPair")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2KeyPairPaginator(buildFilter(d.KeyColumnQuals, getEC2KeyPairFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2KeyPair =============================

// ==========================  START: EC2AMI =============================

type EC2AMI struct {
	Description   aws.EC2AMIDescription `json:"description"`
	Metadata      aws.Metadata          `json:"metadata"`
	ResourceJobID int                   `json:"resource_job_id"`
	SourceJobID   int                   `json:"source_job_id"`
	ResourceType  string                `json:"resource_type"`
	SourceType    string                `json:"source_type"`
	ID            string                `json:"id"`
	ARN           string                `json:"arn"`
	SourceID      string                `json:"source_id"`
}

type EC2AMIHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2AMI        `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2AMIHits struct {
	Total SearchTotal `json:"total"`
	Hits  []EC2AMIHit `json:"hits"`
}

type EC2AMISearchResponse struct {
	PitID string     `json:"pit_id"`
	Hits  EC2AMIHits `json:"hits"`
}

type EC2AMIPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2AMIPaginator(filters []BoolFilter, limit *int64) (EC2AMIPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_ami", filters, limit)
	if err != nil {
		return EC2AMIPaginator{}, err
	}

	p := EC2AMIPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2AMIPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2AMIPaginator) NextPage(ctx context.Context) ([]EC2AMI, error) {
	var response EC2AMISearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2AMI
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2AMIFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2AMI(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2AMI")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2AMIPaginator(buildFilter(d.KeyColumnQuals, listEC2AMIFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2AMIFilters = map[string]string{
	"image_id":         "description.AMI.ImageId",
	"keibi_account_id": "metadata.SourceID",
}

func GetEC2AMI(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2AMI")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2AMIPaginator(buildFilter(d.KeyColumnQuals, getEC2AMIFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2AMI =============================

// ==========================  START: EC2ReservedInstances =============================

type EC2ReservedInstances struct {
	Description   aws.EC2ReservedInstancesDescription `json:"description"`
	Metadata      aws.Metadata                        `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type EC2ReservedInstancesHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  EC2ReservedInstances `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type EC2ReservedInstancesHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []EC2ReservedInstancesHit `json:"hits"`
}

type EC2ReservedInstancesSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  EC2ReservedInstancesHits `json:"hits"`
}

type EC2ReservedInstancesPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2ReservedInstancesPaginator(filters []BoolFilter, limit *int64) (EC2ReservedInstancesPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_reservedinstance", filters, limit)
	if err != nil {
		return EC2ReservedInstancesPaginator{}, err
	}

	p := EC2ReservedInstancesPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2ReservedInstancesPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2ReservedInstancesPaginator) NextPage(ctx context.Context) ([]EC2ReservedInstances, error) {
	var response EC2ReservedInstancesSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2ReservedInstances
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2ReservedInstancesFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2ReservedInstances(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2ReservedInstances")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2ReservedInstancesPaginator(buildFilter(d.KeyColumnQuals, listEC2ReservedInstancesFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2ReservedInstancesFilters = map[string]string{
	"keibi_account_id":     "metadata.SourceID",
	"reserved_instance_id": "description.ReservedInstance.ReservedInstancesId",
}

func GetEC2ReservedInstances(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2ReservedInstances")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2ReservedInstancesPaginator(buildFilter(d.KeyColumnQuals, getEC2ReservedInstancesFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2ReservedInstances =============================

// ==========================  START: EC2CapacityReservationFleet =============================

type EC2CapacityReservationFleet struct {
	Description   aws.EC2CapacityReservationFleetDescription `json:"description"`
	Metadata      aws.Metadata                               `json:"metadata"`
	ResourceJobID int                                        `json:"resource_job_id"`
	SourceJobID   int                                        `json:"source_job_id"`
	ResourceType  string                                     `json:"resource_type"`
	SourceType    string                                     `json:"source_type"`
	ID            string                                     `json:"id"`
	ARN           string                                     `json:"arn"`
	SourceID      string                                     `json:"source_id"`
}

type EC2CapacityReservationFleetHit struct {
	ID      string                      `json:"_id"`
	Score   float64                     `json:"_score"`
	Index   string                      `json:"_index"`
	Type    string                      `json:"_type"`
	Version int64                       `json:"_version,omitempty"`
	Source  EC2CapacityReservationFleet `json:"_source"`
	Sort    []interface{}               `json:"sort"`
}

type EC2CapacityReservationFleetHits struct {
	Total SearchTotal                      `json:"total"`
	Hits  []EC2CapacityReservationFleetHit `json:"hits"`
}

type EC2CapacityReservationFleetSearchResponse struct {
	PitID string                          `json:"pit_id"`
	Hits  EC2CapacityReservationFleetHits `json:"hits"`
}

type EC2CapacityReservationFleetPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2CapacityReservationFleetPaginator(filters []BoolFilter, limit *int64) (EC2CapacityReservationFleetPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_capacityreservationfleet", filters, limit)
	if err != nil {
		return EC2CapacityReservationFleetPaginator{}, err
	}

	p := EC2CapacityReservationFleetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2CapacityReservationFleetPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2CapacityReservationFleetPaginator) NextPage(ctx context.Context) ([]EC2CapacityReservationFleet, error) {
	var response EC2CapacityReservationFleetSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2CapacityReservationFleet
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2CapacityReservationFleetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2CapacityReservationFleet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2CapacityReservationFleet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2CapacityReservationFleetPaginator(buildFilter(d.KeyColumnQuals, listEC2CapacityReservationFleetFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2CapacityReservationFleetFilters = map[string]string{
	"capacity_reservation_fleet_id": "description.CapacityReservationFleet.CapacityReservationFleetId",
	"keibi_account_id":              "metadata.SourceID",
}

func GetEC2CapacityReservationFleet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2CapacityReservationFleet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2CapacityReservationFleetPaginator(buildFilter(d.KeyColumnQuals, getEC2CapacityReservationFleetFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2CapacityReservationFleet =============================

// ==========================  START: EC2Fleet =============================

type EC2Fleet struct {
	Description   aws.EC2FleetDescription `json:"description"`
	Metadata      aws.Metadata            `json:"metadata"`
	ResourceJobID int                     `json:"resource_job_id"`
	SourceJobID   int                     `json:"source_job_id"`
	ResourceType  string                  `json:"resource_type"`
	SourceType    string                  `json:"source_type"`
	ID            string                  `json:"id"`
	ARN           string                  `json:"arn"`
	SourceID      string                  `json:"source_id"`
}

type EC2FleetHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2Fleet      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2FleetHits struct {
	Total SearchTotal   `json:"total"`
	Hits  []EC2FleetHit `json:"hits"`
}

type EC2FleetSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  EC2FleetHits `json:"hits"`
}

type EC2FleetPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2FleetPaginator(filters []BoolFilter, limit *int64) (EC2FleetPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_fleet", filters, limit)
	if err != nil {
		return EC2FleetPaginator{}, err
	}

	p := EC2FleetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2FleetPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2FleetPaginator) NextPage(ctx context.Context) ([]EC2Fleet, error) {
	var response EC2FleetSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2Fleet
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2FleetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2Fleet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2Fleet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2FleetPaginator(buildFilter(d.KeyColumnQuals, listEC2FleetFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2FleetFilters = map[string]string{
	"fleet_id":         "description.Fleet.FleetId",
	"keibi_account_id": "metadata.SourceID",
}

func GetEC2Fleet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2Fleet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2FleetPaginator(buildFilter(d.KeyColumnQuals, getEC2FleetFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2Fleet =============================

// ==========================  START: EC2Host =============================

type EC2Host struct {
	Description   aws.EC2HostDescription `json:"description"`
	Metadata      aws.Metadata           `json:"metadata"`
	ResourceJobID int                    `json:"resource_job_id"`
	SourceJobID   int                    `json:"source_job_id"`
	ResourceType  string                 `json:"resource_type"`
	SourceType    string                 `json:"source_type"`
	ID            string                 `json:"id"`
	ARN           string                 `json:"arn"`
	SourceID      string                 `json:"source_id"`
}

type EC2HostHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2Host       `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2HostHits struct {
	Total SearchTotal  `json:"total"`
	Hits  []EC2HostHit `json:"hits"`
}

type EC2HostSearchResponse struct {
	PitID string      `json:"pit_id"`
	Hits  EC2HostHits `json:"hits"`
}

type EC2HostPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2HostPaginator(filters []BoolFilter, limit *int64) (EC2HostPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_host", filters, limit)
	if err != nil {
		return EC2HostPaginator{}, err
	}

	p := EC2HostPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2HostPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2HostPaginator) NextPage(ctx context.Context) ([]EC2Host, error) {
	var response EC2HostSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2Host
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2HostFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2Host(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2Host")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2HostPaginator(buildFilter(d.KeyColumnQuals, listEC2HostFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2HostFilters = map[string]string{
	"host_id":          "description.Host.HostId",
	"keibi_account_id": "metadata.SourceID",
}

func GetEC2Host(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2Host")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2HostPaginator(buildFilter(d.KeyColumnQuals, getEC2HostFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2Host =============================

// ==========================  START: EC2PlacementGroup =============================

type EC2PlacementGroup struct {
	Description   aws.EC2PlacementGroupDescription `json:"description"`
	Metadata      aws.Metadata                     `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

type EC2PlacementGroupHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  EC2PlacementGroup `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type EC2PlacementGroupHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []EC2PlacementGroupHit `json:"hits"`
}

type EC2PlacementGroupSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  EC2PlacementGroupHits `json:"hits"`
}

type EC2PlacementGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2PlacementGroupPaginator(filters []BoolFilter, limit *int64) (EC2PlacementGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_placementgroup", filters, limit)
	if err != nil {
		return EC2PlacementGroupPaginator{}, err
	}

	p := EC2PlacementGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2PlacementGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2PlacementGroupPaginator) NextPage(ctx context.Context) ([]EC2PlacementGroup, error) {
	var response EC2PlacementGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2PlacementGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2PlacementGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2PlacementGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2PlacementGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2PlacementGroupPaginator(buildFilter(d.KeyColumnQuals, listEC2PlacementGroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2PlacementGroupFilters = map[string]string{
	"group_name":       "description.PlacementGroup.GroupName",
	"keibi_account_id": "metadata.SourceID",
}

func GetEC2PlacementGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2PlacementGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2PlacementGroupPaginator(buildFilter(d.KeyColumnQuals, getEC2PlacementGroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2PlacementGroup =============================

// ==========================  START: EC2TransitGateway =============================

type EC2TransitGateway struct {
	Description   aws.EC2TransitGatewayDescription `json:"description"`
	Metadata      aws.Metadata                     `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

type EC2TransitGatewayHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  EC2TransitGateway `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type EC2TransitGatewayHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []EC2TransitGatewayHit `json:"hits"`
}

type EC2TransitGatewaySearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  EC2TransitGatewayHits `json:"hits"`
}

type EC2TransitGatewayPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2TransitGatewayPaginator(filters []BoolFilter, limit *int64) (EC2TransitGatewayPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_transitgateway", filters, limit)
	if err != nil {
		return EC2TransitGatewayPaginator{}, err
	}

	p := EC2TransitGatewayPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2TransitGatewayPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2TransitGatewayPaginator) NextPage(ctx context.Context) ([]EC2TransitGateway, error) {
	var response EC2TransitGatewaySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2TransitGateway
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2TransitGatewayFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2TransitGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2TransitGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2TransitGatewayPaginator(buildFilter(d.KeyColumnQuals, listEC2TransitGatewayFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2TransitGatewayFilters = map[string]string{
	"keibi_account_id":   "metadata.SourceID",
	"transit_gateway_id": "description.TransitGateway.TransitGatewayId",
}

func GetEC2TransitGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2TransitGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2TransitGatewayPaginator(buildFilter(d.KeyColumnQuals, getEC2TransitGatewayFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2TransitGateway =============================

// ==========================  START: EC2TransitGatewayRouteTable =============================

type EC2TransitGatewayRouteTable struct {
	Description   aws.EC2TransitGatewayRouteTableDescription `json:"description"`
	Metadata      aws.Metadata                               `json:"metadata"`
	ResourceJobID int                                        `json:"resource_job_id"`
	SourceJobID   int                                        `json:"source_job_id"`
	ResourceType  string                                     `json:"resource_type"`
	SourceType    string                                     `json:"source_type"`
	ID            string                                     `json:"id"`
	ARN           string                                     `json:"arn"`
	SourceID      string                                     `json:"source_id"`
}

type EC2TransitGatewayRouteTableHit struct {
	ID      string                      `json:"_id"`
	Score   float64                     `json:"_score"`
	Index   string                      `json:"_index"`
	Type    string                      `json:"_type"`
	Version int64                       `json:"_version,omitempty"`
	Source  EC2TransitGatewayRouteTable `json:"_source"`
	Sort    []interface{}               `json:"sort"`
}

type EC2TransitGatewayRouteTableHits struct {
	Total SearchTotal                      `json:"total"`
	Hits  []EC2TransitGatewayRouteTableHit `json:"hits"`
}

type EC2TransitGatewayRouteTableSearchResponse struct {
	PitID string                          `json:"pit_id"`
	Hits  EC2TransitGatewayRouteTableHits `json:"hits"`
}

type EC2TransitGatewayRouteTablePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2TransitGatewayRouteTablePaginator(filters []BoolFilter, limit *int64) (EC2TransitGatewayRouteTablePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_transitgatewayroutetable", filters, limit)
	if err != nil {
		return EC2TransitGatewayRouteTablePaginator{}, err
	}

	p := EC2TransitGatewayRouteTablePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2TransitGatewayRouteTablePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2TransitGatewayRouteTablePaginator) NextPage(ctx context.Context) ([]EC2TransitGatewayRouteTable, error) {
	var response EC2TransitGatewayRouteTableSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2TransitGatewayRouteTable
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2TransitGatewayRouteTableFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2TransitGatewayRouteTable(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2TransitGatewayRouteTable")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2TransitGatewayRouteTablePaginator(buildFilter(d.KeyColumnQuals, listEC2TransitGatewayRouteTableFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2TransitGatewayRouteTableFilters = map[string]string{
	"keibi_account_id":               "metadata.SourceID",
	"transit_gateway_route_table_id": "description.TransitGatewayRouteTable.TransitGatewayRouteTableId",
}

func GetEC2TransitGatewayRouteTable(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2TransitGatewayRouteTable")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2TransitGatewayRouteTablePaginator(buildFilter(d.KeyColumnQuals, getEC2TransitGatewayRouteTableFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2TransitGatewayRouteTable =============================

// ==========================  START: EC2DhcpOptions =============================

type EC2DhcpOptions struct {
	Description   aws.EC2DhcpOptionsDescription `json:"description"`
	Metadata      aws.Metadata                  `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

type EC2DhcpOptionsHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  EC2DhcpOptions `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type EC2DhcpOptionsHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []EC2DhcpOptionsHit `json:"hits"`
}

type EC2DhcpOptionsSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  EC2DhcpOptionsHits `json:"hits"`
}

type EC2DhcpOptionsPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2DhcpOptionsPaginator(filters []BoolFilter, limit *int64) (EC2DhcpOptionsPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_dhcpoptions", filters, limit)
	if err != nil {
		return EC2DhcpOptionsPaginator{}, err
	}

	p := EC2DhcpOptionsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2DhcpOptionsPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2DhcpOptionsPaginator) NextPage(ctx context.Context) ([]EC2DhcpOptions, error) {
	var response EC2DhcpOptionsSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2DhcpOptions
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2DhcpOptionsFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2DhcpOptions(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2DhcpOptions")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2DhcpOptionsPaginator(buildFilter(d.KeyColumnQuals, listEC2DhcpOptionsFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2DhcpOptionsFilters = map[string]string{
	"dhcp_options_id":  "description.DhcpOptions.DhcpOptionsId",
	"keibi_account_id": "metadata.SourceID",
}

func GetEC2DhcpOptions(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2DhcpOptions")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2DhcpOptionsPaginator(buildFilter(d.KeyColumnQuals, getEC2DhcpOptionsFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2DhcpOptions =============================

// ==========================  START: EC2EgressOnlyInternetGateway =============================

type EC2EgressOnlyInternetGateway struct {
	Description   aws.EC2EgressOnlyInternetGatewayDescription `json:"description"`
	Metadata      aws.Metadata                                `json:"metadata"`
	ResourceJobID int                                         `json:"resource_job_id"`
	SourceJobID   int                                         `json:"source_job_id"`
	ResourceType  string                                      `json:"resource_type"`
	SourceType    string                                      `json:"source_type"`
	ID            string                                      `json:"id"`
	ARN           string                                      `json:"arn"`
	SourceID      string                                      `json:"source_id"`
}

type EC2EgressOnlyInternetGatewayHit struct {
	ID      string                       `json:"_id"`
	Score   float64                      `json:"_score"`
	Index   string                       `json:"_index"`
	Type    string                       `json:"_type"`
	Version int64                        `json:"_version,omitempty"`
	Source  EC2EgressOnlyInternetGateway `json:"_source"`
	Sort    []interface{}                `json:"sort"`
}

type EC2EgressOnlyInternetGatewayHits struct {
	Total SearchTotal                       `json:"total"`
	Hits  []EC2EgressOnlyInternetGatewayHit `json:"hits"`
}

type EC2EgressOnlyInternetGatewaySearchResponse struct {
	PitID string                           `json:"pit_id"`
	Hits  EC2EgressOnlyInternetGatewayHits `json:"hits"`
}

type EC2EgressOnlyInternetGatewayPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2EgressOnlyInternetGatewayPaginator(filters []BoolFilter, limit *int64) (EC2EgressOnlyInternetGatewayPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_egressonlyinternetgateway", filters, limit)
	if err != nil {
		return EC2EgressOnlyInternetGatewayPaginator{}, err
	}

	p := EC2EgressOnlyInternetGatewayPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2EgressOnlyInternetGatewayPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2EgressOnlyInternetGatewayPaginator) NextPage(ctx context.Context) ([]EC2EgressOnlyInternetGateway, error) {
	var response EC2EgressOnlyInternetGatewaySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2EgressOnlyInternetGateway
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2EgressOnlyInternetGatewayFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2EgressOnlyInternetGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2EgressOnlyInternetGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2EgressOnlyInternetGatewayPaginator(buildFilter(d.KeyColumnQuals, listEC2EgressOnlyInternetGatewayFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2EgressOnlyInternetGatewayFilters = map[string]string{
	"id":               "description.EgressOnlyInternetGateway.EgressOnlyInternetGatewayId",
	"keibi_account_id": "metadata.SourceID",
}

func GetEC2EgressOnlyInternetGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2EgressOnlyInternetGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2EgressOnlyInternetGatewayPaginator(buildFilter(d.KeyColumnQuals, getEC2EgressOnlyInternetGatewayFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2EgressOnlyInternetGateway =============================

// ==========================  START: EC2VpcPeeringConnection =============================

type EC2VpcPeeringConnection struct {
	Description   aws.EC2VpcPeeringConnectionDescription `json:"description"`
	Metadata      aws.Metadata                           `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

type EC2VpcPeeringConnectionHit struct {
	ID      string                  `json:"_id"`
	Score   float64                 `json:"_score"`
	Index   string                  `json:"_index"`
	Type    string                  `json:"_type"`
	Version int64                   `json:"_version,omitempty"`
	Source  EC2VpcPeeringConnection `json:"_source"`
	Sort    []interface{}           `json:"sort"`
}

type EC2VpcPeeringConnectionHits struct {
	Total SearchTotal                  `json:"total"`
	Hits  []EC2VpcPeeringConnectionHit `json:"hits"`
}

type EC2VpcPeeringConnectionSearchResponse struct {
	PitID string                      `json:"pit_id"`
	Hits  EC2VpcPeeringConnectionHits `json:"hits"`
}

type EC2VpcPeeringConnectionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2VpcPeeringConnectionPaginator(filters []BoolFilter, limit *int64) (EC2VpcPeeringConnectionPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_vpcpeeringconnection", filters, limit)
	if err != nil {
		return EC2VpcPeeringConnectionPaginator{}, err
	}

	p := EC2VpcPeeringConnectionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2VpcPeeringConnectionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2VpcPeeringConnectionPaginator) NextPage(ctx context.Context) ([]EC2VpcPeeringConnection, error) {
	var response EC2VpcPeeringConnectionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2VpcPeeringConnection
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2VpcPeeringConnectionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2VpcPeeringConnection(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2VpcPeeringConnection")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2VpcPeeringConnectionPaginator(buildFilter(d.KeyColumnQuals, listEC2VpcPeeringConnectionFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2VpcPeeringConnectionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetEC2VpcPeeringConnection(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2VpcPeeringConnection")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2VpcPeeringConnectionPaginator(buildFilter(d.KeyColumnQuals, getEC2VpcPeeringConnectionFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2VpcPeeringConnection =============================

// ==========================  START: EC2SecurityGroupRule =============================

type EC2SecurityGroupRule struct {
	Description   aws.EC2SecurityGroupRuleDescription `json:"description"`
	Metadata      aws.Metadata                        `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type EC2SecurityGroupRuleHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  EC2SecurityGroupRule `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type EC2SecurityGroupRuleHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []EC2SecurityGroupRuleHit `json:"hits"`
}

type EC2SecurityGroupRuleSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  EC2SecurityGroupRuleHits `json:"hits"`
}

type EC2SecurityGroupRulePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2SecurityGroupRulePaginator(filters []BoolFilter, limit *int64) (EC2SecurityGroupRulePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_securitygrouprule", filters, limit)
	if err != nil {
		return EC2SecurityGroupRulePaginator{}, err
	}

	p := EC2SecurityGroupRulePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2SecurityGroupRulePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2SecurityGroupRulePaginator) NextPage(ctx context.Context) ([]EC2SecurityGroupRule, error) {
	var response EC2SecurityGroupRuleSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2SecurityGroupRule
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2SecurityGroupRuleFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2SecurityGroupRule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2SecurityGroupRule")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2SecurityGroupRulePaginator(buildFilter(d.KeyColumnQuals, listEC2SecurityGroupRuleFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2SecurityGroupRuleFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetEC2SecurityGroupRule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2SecurityGroupRule")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2SecurityGroupRulePaginator(buildFilter(d.KeyColumnQuals, getEC2SecurityGroupRuleFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2SecurityGroupRule =============================

// ==========================  START: EC2IpamPool =============================

type EC2IpamPool struct {
	Description   aws.EC2IpamPoolDescription `json:"description"`
	Metadata      aws.Metadata               `json:"metadata"`
	ResourceJobID int                        `json:"resource_job_id"`
	SourceJobID   int                        `json:"source_job_id"`
	ResourceType  string                     `json:"resource_type"`
	SourceType    string                     `json:"source_type"`
	ID            string                     `json:"id"`
	ARN           string                     `json:"arn"`
	SourceID      string                     `json:"source_id"`
}

type EC2IpamPoolHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2IpamPool   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2IpamPoolHits struct {
	Total SearchTotal      `json:"total"`
	Hits  []EC2IpamPoolHit `json:"hits"`
}

type EC2IpamPoolSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  EC2IpamPoolHits `json:"hits"`
}

type EC2IpamPoolPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2IpamPoolPaginator(filters []BoolFilter, limit *int64) (EC2IpamPoolPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_ipampool", filters, limit)
	if err != nil {
		return EC2IpamPoolPaginator{}, err
	}

	p := EC2IpamPoolPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2IpamPoolPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2IpamPoolPaginator) NextPage(ctx context.Context) ([]EC2IpamPool, error) {
	var response EC2IpamPoolSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2IpamPool
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2IpamPoolFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2IpamPool(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2IpamPool")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2IpamPoolPaginator(buildFilter(d.KeyColumnQuals, listEC2IpamPoolFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2IpamPoolFilters = map[string]string{
	"ipam_pool_id":     "description.IpamPool.IpamPoolId",
	"keibi_account_id": "metadata.SourceID",
}

func GetEC2IpamPool(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2IpamPool")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2IpamPoolPaginator(buildFilter(d.KeyColumnQuals, getEC2IpamPoolFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2IpamPool =============================

// ==========================  START: EC2Ipam =============================

type EC2Ipam struct {
	Description   aws.EC2IpamDescription `json:"description"`
	Metadata      aws.Metadata           `json:"metadata"`
	ResourceJobID int                    `json:"resource_job_id"`
	SourceJobID   int                    `json:"source_job_id"`
	ResourceType  string                 `json:"resource_type"`
	SourceType    string                 `json:"source_type"`
	ID            string                 `json:"id"`
	ARN           string                 `json:"arn"`
	SourceID      string                 `json:"source_id"`
}

type EC2IpamHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2Ipam       `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2IpamHits struct {
	Total SearchTotal  `json:"total"`
	Hits  []EC2IpamHit `json:"hits"`
}

type EC2IpamSearchResponse struct {
	PitID string      `json:"pit_id"`
	Hits  EC2IpamHits `json:"hits"`
}

type EC2IpamPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2IpamPaginator(filters []BoolFilter, limit *int64) (EC2IpamPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_ipam", filters, limit)
	if err != nil {
		return EC2IpamPaginator{}, err
	}

	p := EC2IpamPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2IpamPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2IpamPaginator) NextPage(ctx context.Context) ([]EC2Ipam, error) {
	var response EC2IpamSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2Ipam
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2IpamFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2Ipam(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2Ipam")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2IpamPaginator(buildFilter(d.KeyColumnQuals, listEC2IpamFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2IpamFilters = map[string]string{
	"ipam_id":          "description.Ipam.IpamId",
	"keibi_account_id": "metadata.SourceID",
}

func GetEC2Ipam(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2Ipam")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2IpamPaginator(buildFilter(d.KeyColumnQuals, getEC2IpamFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2Ipam =============================

// ==========================  START: EC2VPCEndpointService =============================

type EC2VPCEndpointService struct {
	Description   aws.EC2VPCEndpointServiceDescription `json:"description"`
	Metadata      aws.Metadata                         `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

type EC2VPCEndpointServiceHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  EC2VPCEndpointService `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type EC2VPCEndpointServiceHits struct {
	Total SearchTotal                `json:"total"`
	Hits  []EC2VPCEndpointServiceHit `json:"hits"`
}

type EC2VPCEndpointServiceSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  EC2VPCEndpointServiceHits `json:"hits"`
}

type EC2VPCEndpointServicePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2VPCEndpointServicePaginator(filters []BoolFilter, limit *int64) (EC2VPCEndpointServicePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_vpcendpointservice", filters, limit)
	if err != nil {
		return EC2VPCEndpointServicePaginator{}, err
	}

	p := EC2VPCEndpointServicePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2VPCEndpointServicePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2VPCEndpointServicePaginator) NextPage(ctx context.Context) ([]EC2VPCEndpointService, error) {
	var response EC2VPCEndpointServiceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2VPCEndpointService
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2VPCEndpointServiceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2VPCEndpointService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2VPCEndpointService")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2VPCEndpointServicePaginator(buildFilter(d.KeyColumnQuals, listEC2VPCEndpointServiceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2VPCEndpointServiceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"service_name":     "description.VPCEndpoint.ServiceName",
}

func GetEC2VPCEndpointService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2VPCEndpointService")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2VPCEndpointServicePaginator(buildFilter(d.KeyColumnQuals, getEC2VPCEndpointServiceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2VPCEndpointService =============================

// ==========================  START: EC2InstanceAvailability =============================

type EC2InstanceAvailability struct {
	Description   aws.EC2InstanceAvailabilityDescription `json:"description"`
	Metadata      aws.Metadata                           `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

type EC2InstanceAvailabilityHit struct {
	ID      string                  `json:"_id"`
	Score   float64                 `json:"_score"`
	Index   string                  `json:"_index"`
	Type    string                  `json:"_type"`
	Version int64                   `json:"_version,omitempty"`
	Source  EC2InstanceAvailability `json:"_source"`
	Sort    []interface{}           `json:"sort"`
}

type EC2InstanceAvailabilityHits struct {
	Total SearchTotal                  `json:"total"`
	Hits  []EC2InstanceAvailabilityHit `json:"hits"`
}

type EC2InstanceAvailabilitySearchResponse struct {
	PitID string                      `json:"pit_id"`
	Hits  EC2InstanceAvailabilityHits `json:"hits"`
}

type EC2InstanceAvailabilityPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2InstanceAvailabilityPaginator(filters []BoolFilter, limit *int64) (EC2InstanceAvailabilityPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_instanceavailability", filters, limit)
	if err != nil {
		return EC2InstanceAvailabilityPaginator{}, err
	}

	p := EC2InstanceAvailabilityPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2InstanceAvailabilityPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2InstanceAvailabilityPaginator) NextPage(ctx context.Context) ([]EC2InstanceAvailability, error) {
	var response EC2InstanceAvailabilitySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2InstanceAvailability
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2InstanceAvailabilityFilters = map[string]string{
	"instance_type":    "description.InstanceAvailability.InstanceType",
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2InstanceAvailability(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2InstanceAvailability")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2InstanceAvailabilityPaginator(buildFilter(d.KeyColumnQuals, listEC2InstanceAvailabilityFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2InstanceAvailabilityFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetEC2InstanceAvailability(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2InstanceAvailability")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2InstanceAvailabilityPaginator(buildFilter(d.KeyColumnQuals, getEC2InstanceAvailabilityFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2InstanceAvailability =============================

// ==========================  START: EC2InstanceType =============================

type EC2InstanceType struct {
	Description   aws.EC2InstanceTypeDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type EC2InstanceTypeHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  EC2InstanceType `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type EC2InstanceTypeHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []EC2InstanceTypeHit `json:"hits"`
}

type EC2InstanceTypeSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  EC2InstanceTypeHits `json:"hits"`
}

type EC2InstanceTypePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2InstanceTypePaginator(filters []BoolFilter, limit *int64) (EC2InstanceTypePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_instancetype", filters, limit)
	if err != nil {
		return EC2InstanceTypePaginator{}, err
	}

	p := EC2InstanceTypePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2InstanceTypePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2InstanceTypePaginator) NextPage(ctx context.Context) ([]EC2InstanceType, error) {
	var response EC2InstanceTypeSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2InstanceType
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2InstanceTypeFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEC2InstanceType(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2InstanceType")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2InstanceTypePaginator(buildFilter(d.KeyColumnQuals, listEC2InstanceTypeFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2InstanceTypeFilters = map[string]string{
	"instance_type":    "description.InstanceType.InstanceType",
	"keibi_account_id": "metadata.SourceID",
}

func GetEC2InstanceType(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2InstanceType")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2InstanceTypePaginator(buildFilter(d.KeyColumnQuals, getEC2InstanceTypeFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2InstanceType =============================

// ==========================  START: EC2ManagedPrefixList =============================

type EC2ManagedPrefixList struct {
	Description   aws.EC2ManagedPrefixListDescription `json:"description"`
	Metadata      aws.Metadata                        `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type EC2ManagedPrefixListHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  EC2ManagedPrefixList `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type EC2ManagedPrefixListHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []EC2ManagedPrefixListHit `json:"hits"`
}

type EC2ManagedPrefixListSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  EC2ManagedPrefixListHits `json:"hits"`
}

type EC2ManagedPrefixListPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2ManagedPrefixListPaginator(filters []BoolFilter, limit *int64) (EC2ManagedPrefixListPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_managedprefixlist", filters, limit)
	if err != nil {
		return EC2ManagedPrefixListPaginator{}, err
	}

	p := EC2ManagedPrefixListPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2ManagedPrefixListPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2ManagedPrefixListPaginator) NextPage(ctx context.Context) ([]EC2ManagedPrefixList, error) {
	var response EC2ManagedPrefixListSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2ManagedPrefixList
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2ManagedPrefixListFilters = map[string]string{
	"id":               "description.ManagedPrefixList.PrefixListId",
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.ManagedPrefixList.PrefixListName",
	"owner_id":         "description.ManagedPrefixList.OwnerId",
}

func ListEC2ManagedPrefixList(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2ManagedPrefixList")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2ManagedPrefixListPaginator(buildFilter(d.KeyColumnQuals, listEC2ManagedPrefixListFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2ManagedPrefixListFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetEC2ManagedPrefixList(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2ManagedPrefixList")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2ManagedPrefixListPaginator(buildFilter(d.KeyColumnQuals, getEC2ManagedPrefixListFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2ManagedPrefixList =============================

// ==========================  START: EC2SpotPrice =============================

type EC2SpotPrice struct {
	Description   aws.EC2SpotPriceDescription `json:"description"`
	Metadata      aws.Metadata                `json:"metadata"`
	ResourceJobID int                         `json:"resource_job_id"`
	SourceJobID   int                         `json:"source_job_id"`
	ResourceType  string                      `json:"resource_type"`
	SourceType    string                      `json:"source_type"`
	ID            string                      `json:"id"`
	ARN           string                      `json:"arn"`
	SourceID      string                      `json:"source_id"`
}

type EC2SpotPriceHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2SpotPrice  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2SpotPriceHits struct {
	Total SearchTotal       `json:"total"`
	Hits  []EC2SpotPriceHit `json:"hits"`
}

type EC2SpotPriceSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  EC2SpotPriceHits `json:"hits"`
}

type EC2SpotPricePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2SpotPricePaginator(filters []BoolFilter, limit *int64) (EC2SpotPricePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_spotprice", filters, limit)
	if err != nil {
		return EC2SpotPricePaginator{}, err
	}

	p := EC2SpotPricePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2SpotPricePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2SpotPricePaginator) NextPage(ctx context.Context) ([]EC2SpotPrice, error) {
	var response EC2SpotPriceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2SpotPrice
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2SpotPriceFilters = map[string]string{
	"availability_zone":   "description.SpotPrice.AvailabilityZone",
	"instance_type":       "description.SpotPrice.InstanceType",
	"keibi_account_id":    "metadata.SourceID",
	"product_description": "description.SpotPrice.ProductDescription",
}

func ListEC2SpotPrice(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2SpotPrice")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2SpotPricePaginator(buildFilter(d.KeyColumnQuals, listEC2SpotPriceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2SpotPriceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetEC2SpotPrice(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2SpotPrice")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2SpotPricePaginator(buildFilter(d.KeyColumnQuals, getEC2SpotPriceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2SpotPrice =============================

// ==========================  START: EC2TransitGatewayRoute =============================

type EC2TransitGatewayRoute struct {
	Description   aws.EC2TransitGatewayRouteDescription `json:"description"`
	Metadata      aws.Metadata                          `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

type EC2TransitGatewayRouteHit struct {
	ID      string                 `json:"_id"`
	Score   float64                `json:"_score"`
	Index   string                 `json:"_index"`
	Type    string                 `json:"_type"`
	Version int64                  `json:"_version,omitempty"`
	Source  EC2TransitGatewayRoute `json:"_source"`
	Sort    []interface{}          `json:"sort"`
}

type EC2TransitGatewayRouteHits struct {
	Total SearchTotal                 `json:"total"`
	Hits  []EC2TransitGatewayRouteHit `json:"hits"`
}

type EC2TransitGatewayRouteSearchResponse struct {
	PitID string                     `json:"pit_id"`
	Hits  EC2TransitGatewayRouteHits `json:"hits"`
}

type EC2TransitGatewayRoutePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2TransitGatewayRoutePaginator(filters []BoolFilter, limit *int64) (EC2TransitGatewayRoutePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_transitgatewayroute", filters, limit)
	if err != nil {
		return EC2TransitGatewayRoutePaginator{}, err
	}

	p := EC2TransitGatewayRoutePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2TransitGatewayRoutePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2TransitGatewayRoutePaginator) NextPage(ctx context.Context) ([]EC2TransitGatewayRoute, error) {
	var response EC2TransitGatewayRouteSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2TransitGatewayRoute
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2TransitGatewayRouteFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"prefix_list_id":   "description.TransitGatewayRoute.PrefixListId",
	"state":            "description.TransitGatewayRoute.State",
	"type":             "description.TransitGatewayRoute.Type",
}

func ListEC2TransitGatewayRoute(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2TransitGatewayRoute")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2TransitGatewayRoutePaginator(buildFilter(d.KeyColumnQuals, listEC2TransitGatewayRouteFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2TransitGatewayRouteFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetEC2TransitGatewayRoute(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2TransitGatewayRoute")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2TransitGatewayRoutePaginator(buildFilter(d.KeyColumnQuals, getEC2TransitGatewayRouteFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2TransitGatewayRoute =============================

// ==========================  START: EC2TransitGatewayAttachment =============================

type EC2TransitGatewayAttachment struct {
	Description   aws.EC2TransitGatewayAttachmentDescription `json:"description"`
	Metadata      aws.Metadata                               `json:"metadata"`
	ResourceJobID int                                        `json:"resource_job_id"`
	SourceJobID   int                                        `json:"source_job_id"`
	ResourceType  string                                     `json:"resource_type"`
	SourceType    string                                     `json:"source_type"`
	ID            string                                     `json:"id"`
	ARN           string                                     `json:"arn"`
	SourceID      string                                     `json:"source_id"`
}

type EC2TransitGatewayAttachmentHit struct {
	ID      string                      `json:"_id"`
	Score   float64                     `json:"_score"`
	Index   string                      `json:"_index"`
	Type    string                      `json:"_type"`
	Version int64                       `json:"_version,omitempty"`
	Source  EC2TransitGatewayAttachment `json:"_source"`
	Sort    []interface{}               `json:"sort"`
}

type EC2TransitGatewayAttachmentHits struct {
	Total SearchTotal                      `json:"total"`
	Hits  []EC2TransitGatewayAttachmentHit `json:"hits"`
}

type EC2TransitGatewayAttachmentSearchResponse struct {
	PitID string                          `json:"pit_id"`
	Hits  EC2TransitGatewayAttachmentHits `json:"hits"`
}

type EC2TransitGatewayAttachmentPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2TransitGatewayAttachmentPaginator(filters []BoolFilter, limit *int64) (EC2TransitGatewayAttachmentPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_transitgatewayvpcattachment", filters, limit)
	if err != nil {
		return EC2TransitGatewayAttachmentPaginator{}, err
	}

	p := EC2TransitGatewayAttachmentPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2TransitGatewayAttachmentPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2TransitGatewayAttachmentPaginator) NextPage(ctx context.Context) ([]EC2TransitGatewayAttachment, error) {
	var response EC2TransitGatewayAttachmentSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2TransitGatewayAttachment
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2TransitGatewayAttachmentFilters = map[string]string{
	"association_state":                          "description.TransitGatewayAttachment.Association.State",
	"association_transit_gateway_route_table_id": "description.TransitGatewayAttachment.Association.TransitGatewayRouteTableId",
	"keibi_account_id":                           "metadata.SourceID",
	"resource_id":                                "description.TransitGatewayAttachment.ResourceId",
	"resource_owner_id":                          "description.TransitGatewayAttachment.ResourceOwnerId",
	"resource_type":                              "description.TransitGatewayAttachment.ResourceType",
	"state":                                      "description.TransitGatewayAttachment.State",
	"transit_gateway_id":                         "description.TransitGatewayAttachment.TransitGatewayId",
	"transit_gateway_owner_id":                   "description.TransitGatewayAttachment.TransitGatewayOwnerId",
}

func ListEC2TransitGatewayAttachment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2TransitGatewayAttachment")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2TransitGatewayAttachmentPaginator(buildFilter(d.KeyColumnQuals, listEC2TransitGatewayAttachmentFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2TransitGatewayAttachmentFilters = map[string]string{
	"keibi_account_id":              "metadata.SourceID",
	"transit_gateway_attachment_id": "description.TransitGatewayAttachment.TransitGatewayAttachmentId",
}

func GetEC2TransitGatewayAttachment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2TransitGatewayAttachment")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2TransitGatewayAttachmentPaginator(buildFilter(d.KeyColumnQuals, getEC2TransitGatewayAttachmentFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2TransitGatewayAttachment =============================

// ==========================  START: ElasticLoadBalancingV2SslPolicy =============================

type ElasticLoadBalancingV2SslPolicy struct {
	Description   aws.ElasticLoadBalancingV2SslPolicyDescription `json:"description"`
	Metadata      aws.Metadata                                   `json:"metadata"`
	ResourceJobID int                                            `json:"resource_job_id"`
	SourceJobID   int                                            `json:"source_job_id"`
	ResourceType  string                                         `json:"resource_type"`
	SourceType    string                                         `json:"source_type"`
	ID            string                                         `json:"id"`
	ARN           string                                         `json:"arn"`
	SourceID      string                                         `json:"source_id"`
}

type ElasticLoadBalancingV2SslPolicyHit struct {
	ID      string                          `json:"_id"`
	Score   float64                         `json:"_score"`
	Index   string                          `json:"_index"`
	Type    string                          `json:"_type"`
	Version int64                           `json:"_version,omitempty"`
	Source  ElasticLoadBalancingV2SslPolicy `json:"_source"`
	Sort    []interface{}                   `json:"sort"`
}

type ElasticLoadBalancingV2SslPolicyHits struct {
	Total SearchTotal                          `json:"total"`
	Hits  []ElasticLoadBalancingV2SslPolicyHit `json:"hits"`
}

type ElasticLoadBalancingV2SslPolicySearchResponse struct {
	PitID string                              `json:"pit_id"`
	Hits  ElasticLoadBalancingV2SslPolicyHits `json:"hits"`
}

type ElasticLoadBalancingV2SslPolicyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewElasticLoadBalancingV2SslPolicyPaginator(filters []BoolFilter, limit *int64) (ElasticLoadBalancingV2SslPolicyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticloadbalancingv2_sslpolicy", filters, limit)
	if err != nil {
		return ElasticLoadBalancingV2SslPolicyPaginator{}, err
	}

	p := ElasticLoadBalancingV2SslPolicyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ElasticLoadBalancingV2SslPolicyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ElasticLoadBalancingV2SslPolicyPaginator) NextPage(ctx context.Context) ([]ElasticLoadBalancingV2SslPolicy, error) {
	var response ElasticLoadBalancingV2SslPolicySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ElasticLoadBalancingV2SslPolicy
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listElasticLoadBalancingV2SslPolicyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListElasticLoadBalancingV2SslPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListElasticLoadBalancingV2SslPolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewElasticLoadBalancingV2SslPolicyPaginator(buildFilter(d.KeyColumnQuals, listElasticLoadBalancingV2SslPolicyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getElasticLoadBalancingV2SslPolicyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.SslPolicy.Name",
	"region":           "metadata.Region",
}

func GetElasticLoadBalancingV2SslPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetElasticLoadBalancingV2SslPolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewElasticLoadBalancingV2SslPolicyPaginator(buildFilter(d.KeyColumnQuals, getElasticLoadBalancingV2SslPolicyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ElasticLoadBalancingV2SslPolicy =============================

// ==========================  START: ElasticLoadBalancingV2TargetGroup =============================

type ElasticLoadBalancingV2TargetGroup struct {
	Description   aws.ElasticLoadBalancingV2TargetGroupDescription `json:"description"`
	Metadata      aws.Metadata                                     `json:"metadata"`
	ResourceJobID int                                              `json:"resource_job_id"`
	SourceJobID   int                                              `json:"source_job_id"`
	ResourceType  string                                           `json:"resource_type"`
	SourceType    string                                           `json:"source_type"`
	ID            string                                           `json:"id"`
	ARN           string                                           `json:"arn"`
	SourceID      string                                           `json:"source_id"`
}

type ElasticLoadBalancingV2TargetGroupHit struct {
	ID      string                            `json:"_id"`
	Score   float64                           `json:"_score"`
	Index   string                            `json:"_index"`
	Type    string                            `json:"_type"`
	Version int64                             `json:"_version,omitempty"`
	Source  ElasticLoadBalancingV2TargetGroup `json:"_source"`
	Sort    []interface{}                     `json:"sort"`
}

type ElasticLoadBalancingV2TargetGroupHits struct {
	Total SearchTotal                            `json:"total"`
	Hits  []ElasticLoadBalancingV2TargetGroupHit `json:"hits"`
}

type ElasticLoadBalancingV2TargetGroupSearchResponse struct {
	PitID string                                `json:"pit_id"`
	Hits  ElasticLoadBalancingV2TargetGroupHits `json:"hits"`
}

type ElasticLoadBalancingV2TargetGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewElasticLoadBalancingV2TargetGroupPaginator(filters []BoolFilter, limit *int64) (ElasticLoadBalancingV2TargetGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticloadbalancingv2_targetgroup", filters, limit)
	if err != nil {
		return ElasticLoadBalancingV2TargetGroupPaginator{}, err
	}

	p := ElasticLoadBalancingV2TargetGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ElasticLoadBalancingV2TargetGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ElasticLoadBalancingV2TargetGroupPaginator) NextPage(ctx context.Context) ([]ElasticLoadBalancingV2TargetGroup, error) {
	var response ElasticLoadBalancingV2TargetGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ElasticLoadBalancingV2TargetGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listElasticLoadBalancingV2TargetGroupFilters = map[string]string{
	"keibi_account_id":  "metadata.SourceID",
	"target_group_name": "description.TargetGroup.TargetGroupName",
}

func ListElasticLoadBalancingV2TargetGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListElasticLoadBalancingV2TargetGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewElasticLoadBalancingV2TargetGroupPaginator(buildFilter(d.KeyColumnQuals, listElasticLoadBalancingV2TargetGroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getElasticLoadBalancingV2TargetGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"target_group_arn": "description.TargetGroup.TargetGroupArn",
}

func GetElasticLoadBalancingV2TargetGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetElasticLoadBalancingV2TargetGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewElasticLoadBalancingV2TargetGroupPaginator(buildFilter(d.KeyColumnQuals, getElasticLoadBalancingV2TargetGroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ElasticLoadBalancingV2TargetGroup =============================

// ==========================  START: ElasticLoadBalancingV2LoadBalancer =============================

type ElasticLoadBalancingV2LoadBalancer struct {
	Description   aws.ElasticLoadBalancingV2LoadBalancerDescription `json:"description"`
	Metadata      aws.Metadata                                      `json:"metadata"`
	ResourceJobID int                                               `json:"resource_job_id"`
	SourceJobID   int                                               `json:"source_job_id"`
	ResourceType  string                                            `json:"resource_type"`
	SourceType    string                                            `json:"source_type"`
	ID            string                                            `json:"id"`
	ARN           string                                            `json:"arn"`
	SourceID      string                                            `json:"source_id"`
}

type ElasticLoadBalancingV2LoadBalancerHit struct {
	ID      string                             `json:"_id"`
	Score   float64                            `json:"_score"`
	Index   string                             `json:"_index"`
	Type    string                             `json:"_type"`
	Version int64                              `json:"_version,omitempty"`
	Source  ElasticLoadBalancingV2LoadBalancer `json:"_source"`
	Sort    []interface{}                      `json:"sort"`
}

type ElasticLoadBalancingV2LoadBalancerHits struct {
	Total SearchTotal                             `json:"total"`
	Hits  []ElasticLoadBalancingV2LoadBalancerHit `json:"hits"`
}

type ElasticLoadBalancingV2LoadBalancerSearchResponse struct {
	PitID string                                 `json:"pit_id"`
	Hits  ElasticLoadBalancingV2LoadBalancerHits `json:"hits"`
}

type ElasticLoadBalancingV2LoadBalancerPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewElasticLoadBalancingV2LoadBalancerPaginator(filters []BoolFilter, limit *int64) (ElasticLoadBalancingV2LoadBalancerPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticloadbalancingv2_loadbalancer", filters, limit)
	if err != nil {
		return ElasticLoadBalancingV2LoadBalancerPaginator{}, err
	}

	p := ElasticLoadBalancingV2LoadBalancerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ElasticLoadBalancingV2LoadBalancerPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ElasticLoadBalancingV2LoadBalancerPaginator) NextPage(ctx context.Context) ([]ElasticLoadBalancingV2LoadBalancer, error) {
	var response ElasticLoadBalancingV2LoadBalancerSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ElasticLoadBalancingV2LoadBalancer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listElasticLoadBalancingV2LoadBalancerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"type":             "description.LoadBalancer.Type",
}

func ListElasticLoadBalancingV2LoadBalancer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListElasticLoadBalancingV2LoadBalancer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewElasticLoadBalancingV2LoadBalancerPaginator(buildFilter(d.KeyColumnQuals, listElasticLoadBalancingV2LoadBalancerFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getElasticLoadBalancingV2LoadBalancerFilters = map[string]string{
	"arn":              "description.LoadBalancer.LoadBalancerArn",
	"keibi_account_id": "metadata.SourceID",
	"type":             "description.LoadBalancer.Type",
}

func GetElasticLoadBalancingV2LoadBalancer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetElasticLoadBalancingV2LoadBalancer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewElasticLoadBalancingV2LoadBalancerPaginator(buildFilter(d.KeyColumnQuals, getElasticLoadBalancingV2LoadBalancerFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ElasticLoadBalancingV2LoadBalancer =============================

// ==========================  START: ElasticLoadBalancingLoadBalancer =============================

type ElasticLoadBalancingLoadBalancer struct {
	Description   aws.ElasticLoadBalancingLoadBalancerDescription `json:"description"`
	Metadata      aws.Metadata                                    `json:"metadata"`
	ResourceJobID int                                             `json:"resource_job_id"`
	SourceJobID   int                                             `json:"source_job_id"`
	ResourceType  string                                          `json:"resource_type"`
	SourceType    string                                          `json:"source_type"`
	ID            string                                          `json:"id"`
	ARN           string                                          `json:"arn"`
	SourceID      string                                          `json:"source_id"`
}

type ElasticLoadBalancingLoadBalancerHit struct {
	ID      string                           `json:"_id"`
	Score   float64                          `json:"_score"`
	Index   string                           `json:"_index"`
	Type    string                           `json:"_type"`
	Version int64                            `json:"_version,omitempty"`
	Source  ElasticLoadBalancingLoadBalancer `json:"_source"`
	Sort    []interface{}                    `json:"sort"`
}

type ElasticLoadBalancingLoadBalancerHits struct {
	Total SearchTotal                           `json:"total"`
	Hits  []ElasticLoadBalancingLoadBalancerHit `json:"hits"`
}

type ElasticLoadBalancingLoadBalancerSearchResponse struct {
	PitID string                               `json:"pit_id"`
	Hits  ElasticLoadBalancingLoadBalancerHits `json:"hits"`
}

type ElasticLoadBalancingLoadBalancerPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewElasticLoadBalancingLoadBalancerPaginator(filters []BoolFilter, limit *int64) (ElasticLoadBalancingLoadBalancerPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticloadbalancing_loadbalancer", filters, limit)
	if err != nil {
		return ElasticLoadBalancingLoadBalancerPaginator{}, err
	}

	p := ElasticLoadBalancingLoadBalancerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ElasticLoadBalancingLoadBalancerPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ElasticLoadBalancingLoadBalancerPaginator) NextPage(ctx context.Context) ([]ElasticLoadBalancingLoadBalancer, error) {
	var response ElasticLoadBalancingLoadBalancerSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ElasticLoadBalancingLoadBalancer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listElasticLoadBalancingLoadBalancerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListElasticLoadBalancingLoadBalancer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListElasticLoadBalancingLoadBalancer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewElasticLoadBalancingLoadBalancerPaginator(buildFilter(d.KeyColumnQuals, listElasticLoadBalancingLoadBalancerFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getElasticLoadBalancingLoadBalancerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.LoadBalancer.LoadBalancerName",
}

func GetElasticLoadBalancingLoadBalancer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetElasticLoadBalancingLoadBalancer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewElasticLoadBalancingLoadBalancerPaginator(buildFilter(d.KeyColumnQuals, getElasticLoadBalancingLoadBalancerFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ElasticLoadBalancingLoadBalancer =============================

// ==========================  START: ElasticLoadBalancingV2Listener =============================

type ElasticLoadBalancingV2Listener struct {
	Description   aws.ElasticLoadBalancingV2ListenerDescription `json:"description"`
	Metadata      aws.Metadata                                  `json:"metadata"`
	ResourceJobID int                                           `json:"resource_job_id"`
	SourceJobID   int                                           `json:"source_job_id"`
	ResourceType  string                                        `json:"resource_type"`
	SourceType    string                                        `json:"source_type"`
	ID            string                                        `json:"id"`
	ARN           string                                        `json:"arn"`
	SourceID      string                                        `json:"source_id"`
}

type ElasticLoadBalancingV2ListenerHit struct {
	ID      string                         `json:"_id"`
	Score   float64                        `json:"_score"`
	Index   string                         `json:"_index"`
	Type    string                         `json:"_type"`
	Version int64                          `json:"_version,omitempty"`
	Source  ElasticLoadBalancingV2Listener `json:"_source"`
	Sort    []interface{}                  `json:"sort"`
}

type ElasticLoadBalancingV2ListenerHits struct {
	Total SearchTotal                         `json:"total"`
	Hits  []ElasticLoadBalancingV2ListenerHit `json:"hits"`
}

type ElasticLoadBalancingV2ListenerSearchResponse struct {
	PitID string                             `json:"pit_id"`
	Hits  ElasticLoadBalancingV2ListenerHits `json:"hits"`
}

type ElasticLoadBalancingV2ListenerPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewElasticLoadBalancingV2ListenerPaginator(filters []BoolFilter, limit *int64) (ElasticLoadBalancingV2ListenerPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticloadbalancingv2_listener", filters, limit)
	if err != nil {
		return ElasticLoadBalancingV2ListenerPaginator{}, err
	}

	p := ElasticLoadBalancingV2ListenerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ElasticLoadBalancingV2ListenerPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ElasticLoadBalancingV2ListenerPaginator) NextPage(ctx context.Context) ([]ElasticLoadBalancingV2Listener, error) {
	var response ElasticLoadBalancingV2ListenerSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ElasticLoadBalancingV2Listener
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listElasticLoadBalancingV2ListenerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListElasticLoadBalancingV2Listener(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListElasticLoadBalancingV2Listener")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewElasticLoadBalancingV2ListenerPaginator(buildFilter(d.KeyColumnQuals, listElasticLoadBalancingV2ListenerFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getElasticLoadBalancingV2ListenerFilters = map[string]string{
	"arn":              "description.Listener.ListenerArn",
	"keibi_account_id": "metadata.SourceID",
}

func GetElasticLoadBalancingV2Listener(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetElasticLoadBalancingV2Listener")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewElasticLoadBalancingV2ListenerPaginator(buildFilter(d.KeyColumnQuals, getElasticLoadBalancingV2ListenerFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ElasticLoadBalancingV2Listener =============================

// ==========================  START: ElasticLoadBalancingV2Rule =============================

type ElasticLoadBalancingV2Rule struct {
	Description   aws.ElasticLoadBalancingV2RuleDescription `json:"description"`
	Metadata      aws.Metadata                              `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

type ElasticLoadBalancingV2RuleHit struct {
	ID      string                     `json:"_id"`
	Score   float64                    `json:"_score"`
	Index   string                     `json:"_index"`
	Type    string                     `json:"_type"`
	Version int64                      `json:"_version,omitempty"`
	Source  ElasticLoadBalancingV2Rule `json:"_source"`
	Sort    []interface{}              `json:"sort"`
}

type ElasticLoadBalancingV2RuleHits struct {
	Total SearchTotal                     `json:"total"`
	Hits  []ElasticLoadBalancingV2RuleHit `json:"hits"`
}

type ElasticLoadBalancingV2RuleSearchResponse struct {
	PitID string                         `json:"pit_id"`
	Hits  ElasticLoadBalancingV2RuleHits `json:"hits"`
}

type ElasticLoadBalancingV2RulePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewElasticLoadBalancingV2RulePaginator(filters []BoolFilter, limit *int64) (ElasticLoadBalancingV2RulePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticloadbalancingv2_rule", filters, limit)
	if err != nil {
		return ElasticLoadBalancingV2RulePaginator{}, err
	}

	p := ElasticLoadBalancingV2RulePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ElasticLoadBalancingV2RulePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ElasticLoadBalancingV2RulePaginator) NextPage(ctx context.Context) ([]ElasticLoadBalancingV2Rule, error) {
	var response ElasticLoadBalancingV2RuleSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ElasticLoadBalancingV2Rule
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listElasticLoadBalancingV2RuleFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListElasticLoadBalancingV2Rule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListElasticLoadBalancingV2Rule")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewElasticLoadBalancingV2RulePaginator(buildFilter(d.KeyColumnQuals, listElasticLoadBalancingV2RuleFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getElasticLoadBalancingV2RuleFilters = map[string]string{
	"arn":              "description.Rule.RuleArn",
	"keibi_account_id": "metadata.SourceID",
}

func GetElasticLoadBalancingV2Rule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetElasticLoadBalancingV2Rule")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewElasticLoadBalancingV2RulePaginator(buildFilter(d.KeyColumnQuals, getElasticLoadBalancingV2RuleFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ElasticLoadBalancingV2Rule =============================

// ==========================  START: ApplicationLoadBalancerMetricRequestCount =============================

type ApplicationLoadBalancerMetricRequestCount struct {
	Description   aws.ApplicationLoadBalancerMetricRequestCountDescription `json:"description"`
	Metadata      aws.Metadata                                             `json:"metadata"`
	ResourceJobID int                                                      `json:"resource_job_id"`
	SourceJobID   int                                                      `json:"source_job_id"`
	ResourceType  string                                                   `json:"resource_type"`
	SourceType    string                                                   `json:"source_type"`
	ID            string                                                   `json:"id"`
	ARN           string                                                   `json:"arn"`
	SourceID      string                                                   `json:"source_id"`
}

type ApplicationLoadBalancerMetricRequestCountHit struct {
	ID      string                                    `json:"_id"`
	Score   float64                                   `json:"_score"`
	Index   string                                    `json:"_index"`
	Type    string                                    `json:"_type"`
	Version int64                                     `json:"_version,omitempty"`
	Source  ApplicationLoadBalancerMetricRequestCount `json:"_source"`
	Sort    []interface{}                             `json:"sort"`
}

type ApplicationLoadBalancerMetricRequestCountHits struct {
	Total SearchTotal                                    `json:"total"`
	Hits  []ApplicationLoadBalancerMetricRequestCountHit `json:"hits"`
}

type ApplicationLoadBalancerMetricRequestCountSearchResponse struct {
	PitID string                                        `json:"pit_id"`
	Hits  ApplicationLoadBalancerMetricRequestCountHits `json:"hits"`
}

type ApplicationLoadBalancerMetricRequestCountPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewApplicationLoadBalancerMetricRequestCountPaginator(filters []BoolFilter, limit *int64) (ApplicationLoadBalancerMetricRequestCountPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticloadbalancingv2_applicationloadbalancermetricrequestcount", filters, limit)
	if err != nil {
		return ApplicationLoadBalancerMetricRequestCountPaginator{}, err
	}

	p := ApplicationLoadBalancerMetricRequestCountPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ApplicationLoadBalancerMetricRequestCountPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ApplicationLoadBalancerMetricRequestCountPaginator) NextPage(ctx context.Context) ([]ApplicationLoadBalancerMetricRequestCount, error) {
	var response ApplicationLoadBalancerMetricRequestCountSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ApplicationLoadBalancerMetricRequestCount
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listApplicationLoadBalancerMetricRequestCountFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListApplicationLoadBalancerMetricRequestCount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListApplicationLoadBalancerMetricRequestCount")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewApplicationLoadBalancerMetricRequestCountPaginator(buildFilter(d.KeyColumnQuals, listApplicationLoadBalancerMetricRequestCountFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getApplicationLoadBalancerMetricRequestCountFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetApplicationLoadBalancerMetricRequestCount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetApplicationLoadBalancerMetricRequestCount")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewApplicationLoadBalancerMetricRequestCountPaginator(buildFilter(d.KeyColumnQuals, getApplicationLoadBalancerMetricRequestCountFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ApplicationLoadBalancerMetricRequestCount =============================

// ==========================  START: ApplicationLoadBalancerMetricRequestCountDaily =============================

type ApplicationLoadBalancerMetricRequestCountDaily struct {
	Description   aws.ApplicationLoadBalancerMetricRequestCountDailyDescription `json:"description"`
	Metadata      aws.Metadata                                                  `json:"metadata"`
	ResourceJobID int                                                           `json:"resource_job_id"`
	SourceJobID   int                                                           `json:"source_job_id"`
	ResourceType  string                                                        `json:"resource_type"`
	SourceType    string                                                        `json:"source_type"`
	ID            string                                                        `json:"id"`
	ARN           string                                                        `json:"arn"`
	SourceID      string                                                        `json:"source_id"`
}

type ApplicationLoadBalancerMetricRequestCountDailyHit struct {
	ID      string                                         `json:"_id"`
	Score   float64                                        `json:"_score"`
	Index   string                                         `json:"_index"`
	Type    string                                         `json:"_type"`
	Version int64                                          `json:"_version,omitempty"`
	Source  ApplicationLoadBalancerMetricRequestCountDaily `json:"_source"`
	Sort    []interface{}                                  `json:"sort"`
}

type ApplicationLoadBalancerMetricRequestCountDailyHits struct {
	Total SearchTotal                                         `json:"total"`
	Hits  []ApplicationLoadBalancerMetricRequestCountDailyHit `json:"hits"`
}

type ApplicationLoadBalancerMetricRequestCountDailySearchResponse struct {
	PitID string                                             `json:"pit_id"`
	Hits  ApplicationLoadBalancerMetricRequestCountDailyHits `json:"hits"`
}

type ApplicationLoadBalancerMetricRequestCountDailyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewApplicationLoadBalancerMetricRequestCountDailyPaginator(filters []BoolFilter, limit *int64) (ApplicationLoadBalancerMetricRequestCountDailyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticloadbalancingv2_applicationloadbalancermetricrequestcountdaily", filters, limit)
	if err != nil {
		return ApplicationLoadBalancerMetricRequestCountDailyPaginator{}, err
	}

	p := ApplicationLoadBalancerMetricRequestCountDailyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ApplicationLoadBalancerMetricRequestCountDailyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ApplicationLoadBalancerMetricRequestCountDailyPaginator) NextPage(ctx context.Context) ([]ApplicationLoadBalancerMetricRequestCountDaily, error) {
	var response ApplicationLoadBalancerMetricRequestCountDailySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ApplicationLoadBalancerMetricRequestCountDaily
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listApplicationLoadBalancerMetricRequestCountDailyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListApplicationLoadBalancerMetricRequestCountDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListApplicationLoadBalancerMetricRequestCountDaily")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewApplicationLoadBalancerMetricRequestCountDailyPaginator(buildFilter(d.KeyColumnQuals, listApplicationLoadBalancerMetricRequestCountDailyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getApplicationLoadBalancerMetricRequestCountDailyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetApplicationLoadBalancerMetricRequestCountDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetApplicationLoadBalancerMetricRequestCountDaily")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewApplicationLoadBalancerMetricRequestCountDailyPaginator(buildFilter(d.KeyColumnQuals, getApplicationLoadBalancerMetricRequestCountDailyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ApplicationLoadBalancerMetricRequestCountDaily =============================

// ==========================  START: NetworkLoadBalancerMetricNetFlowCount =============================

type NetworkLoadBalancerMetricNetFlowCount struct {
	Description   aws.NetworkLoadBalancerMetricNetFlowCountDescription `json:"description"`
	Metadata      aws.Metadata                                         `json:"metadata"`
	ResourceJobID int                                                  `json:"resource_job_id"`
	SourceJobID   int                                                  `json:"source_job_id"`
	ResourceType  string                                               `json:"resource_type"`
	SourceType    string                                               `json:"source_type"`
	ID            string                                               `json:"id"`
	ARN           string                                               `json:"arn"`
	SourceID      string                                               `json:"source_id"`
}

type NetworkLoadBalancerMetricNetFlowCountHit struct {
	ID      string                                `json:"_id"`
	Score   float64                               `json:"_score"`
	Index   string                                `json:"_index"`
	Type    string                                `json:"_type"`
	Version int64                                 `json:"_version,omitempty"`
	Source  NetworkLoadBalancerMetricNetFlowCount `json:"_source"`
	Sort    []interface{}                         `json:"sort"`
}

type NetworkLoadBalancerMetricNetFlowCountHits struct {
	Total SearchTotal                                `json:"total"`
	Hits  []NetworkLoadBalancerMetricNetFlowCountHit `json:"hits"`
}

type NetworkLoadBalancerMetricNetFlowCountSearchResponse struct {
	PitID string                                    `json:"pit_id"`
	Hits  NetworkLoadBalancerMetricNetFlowCountHits `json:"hits"`
}

type NetworkLoadBalancerMetricNetFlowCountPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewNetworkLoadBalancerMetricNetFlowCountPaginator(filters []BoolFilter, limit *int64) (NetworkLoadBalancerMetricNetFlowCountPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticloadbalancingv2_networkloadbalancermetricnetflowcount", filters, limit)
	if err != nil {
		return NetworkLoadBalancerMetricNetFlowCountPaginator{}, err
	}

	p := NetworkLoadBalancerMetricNetFlowCountPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p NetworkLoadBalancerMetricNetFlowCountPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p NetworkLoadBalancerMetricNetFlowCountPaginator) NextPage(ctx context.Context) ([]NetworkLoadBalancerMetricNetFlowCount, error) {
	var response NetworkLoadBalancerMetricNetFlowCountSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []NetworkLoadBalancerMetricNetFlowCount
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listNetworkLoadBalancerMetricNetFlowCountFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListNetworkLoadBalancerMetricNetFlowCount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListNetworkLoadBalancerMetricNetFlowCount")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewNetworkLoadBalancerMetricNetFlowCountPaginator(buildFilter(d.KeyColumnQuals, listNetworkLoadBalancerMetricNetFlowCountFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getNetworkLoadBalancerMetricNetFlowCountFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetNetworkLoadBalancerMetricNetFlowCount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetNetworkLoadBalancerMetricNetFlowCount")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewNetworkLoadBalancerMetricNetFlowCountPaginator(buildFilter(d.KeyColumnQuals, getNetworkLoadBalancerMetricNetFlowCountFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: NetworkLoadBalancerMetricNetFlowCount =============================

// ==========================  START: NetworkLoadBalancerMetricNetFlowCountDaily =============================

type NetworkLoadBalancerMetricNetFlowCountDaily struct {
	Description   aws.NetworkLoadBalancerMetricNetFlowCountDailyDescription `json:"description"`
	Metadata      aws.Metadata                                              `json:"metadata"`
	ResourceJobID int                                                       `json:"resource_job_id"`
	SourceJobID   int                                                       `json:"source_job_id"`
	ResourceType  string                                                    `json:"resource_type"`
	SourceType    string                                                    `json:"source_type"`
	ID            string                                                    `json:"id"`
	ARN           string                                                    `json:"arn"`
	SourceID      string                                                    `json:"source_id"`
}

type NetworkLoadBalancerMetricNetFlowCountDailyHit struct {
	ID      string                                     `json:"_id"`
	Score   float64                                    `json:"_score"`
	Index   string                                     `json:"_index"`
	Type    string                                     `json:"_type"`
	Version int64                                      `json:"_version,omitempty"`
	Source  NetworkLoadBalancerMetricNetFlowCountDaily `json:"_source"`
	Sort    []interface{}                              `json:"sort"`
}

type NetworkLoadBalancerMetricNetFlowCountDailyHits struct {
	Total SearchTotal                                     `json:"total"`
	Hits  []NetworkLoadBalancerMetricNetFlowCountDailyHit `json:"hits"`
}

type NetworkLoadBalancerMetricNetFlowCountDailySearchResponse struct {
	PitID string                                         `json:"pit_id"`
	Hits  NetworkLoadBalancerMetricNetFlowCountDailyHits `json:"hits"`
}

type NetworkLoadBalancerMetricNetFlowCountDailyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewNetworkLoadBalancerMetricNetFlowCountDailyPaginator(filters []BoolFilter, limit *int64) (NetworkLoadBalancerMetricNetFlowCountDailyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticloadbalancingv2_networkloadbalancermetricnetflowcountdaily", filters, limit)
	if err != nil {
		return NetworkLoadBalancerMetricNetFlowCountDailyPaginator{}, err
	}

	p := NetworkLoadBalancerMetricNetFlowCountDailyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p NetworkLoadBalancerMetricNetFlowCountDailyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p NetworkLoadBalancerMetricNetFlowCountDailyPaginator) NextPage(ctx context.Context) ([]NetworkLoadBalancerMetricNetFlowCountDaily, error) {
	var response NetworkLoadBalancerMetricNetFlowCountDailySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []NetworkLoadBalancerMetricNetFlowCountDaily
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listNetworkLoadBalancerMetricNetFlowCountDailyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListNetworkLoadBalancerMetricNetFlowCountDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListNetworkLoadBalancerMetricNetFlowCountDaily")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewNetworkLoadBalancerMetricNetFlowCountDailyPaginator(buildFilter(d.KeyColumnQuals, listNetworkLoadBalancerMetricNetFlowCountDailyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getNetworkLoadBalancerMetricNetFlowCountDailyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetNetworkLoadBalancerMetricNetFlowCountDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetNetworkLoadBalancerMetricNetFlowCountDaily")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewNetworkLoadBalancerMetricNetFlowCountDailyPaginator(buildFilter(d.KeyColumnQuals, getNetworkLoadBalancerMetricNetFlowCountDailyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: NetworkLoadBalancerMetricNetFlowCountDaily =============================

// ==========================  START: FSXFileSystem =============================

type FSXFileSystem struct {
	Description   aws.FSXFileSystemDescription `json:"description"`
	Metadata      aws.Metadata                 `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

type FSXFileSystemHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  FSXFileSystem `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type FSXFileSystemHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []FSXFileSystemHit `json:"hits"`
}

type FSXFileSystemSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  FSXFileSystemHits `json:"hits"`
}

type FSXFileSystemPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewFSXFileSystemPaginator(filters []BoolFilter, limit *int64) (FSXFileSystemPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_fsx_filesystem", filters, limit)
	if err != nil {
		return FSXFileSystemPaginator{}, err
	}

	p := FSXFileSystemPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p FSXFileSystemPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p FSXFileSystemPaginator) NextPage(ctx context.Context) ([]FSXFileSystem, error) {
	var response FSXFileSystemSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []FSXFileSystem
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listFSXFileSystemFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListFSXFileSystem(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListFSXFileSystem")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewFSXFileSystemPaginator(buildFilter(d.KeyColumnQuals, listFSXFileSystemFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getFSXFileSystemFilters = map[string]string{
	"file_system_id":   "description.FileSystem.FileSystemId",
	"keibi_account_id": "metadata.SourceID",
}

func GetFSXFileSystem(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetFSXFileSystem")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewFSXFileSystemPaginator(buildFilter(d.KeyColumnQuals, getFSXFileSystemFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: FSXFileSystem =============================

// ==========================  START: FSXStorageVirtualMachine =============================

type FSXStorageVirtualMachine struct {
	Description   aws.FSXStorageVirtualMachineDescription `json:"description"`
	Metadata      aws.Metadata                            `json:"metadata"`
	ResourceJobID int                                     `json:"resource_job_id"`
	SourceJobID   int                                     `json:"source_job_id"`
	ResourceType  string                                  `json:"resource_type"`
	SourceType    string                                  `json:"source_type"`
	ID            string                                  `json:"id"`
	ARN           string                                  `json:"arn"`
	SourceID      string                                  `json:"source_id"`
}

type FSXStorageVirtualMachineHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  FSXStorageVirtualMachine `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type FSXStorageVirtualMachineHits struct {
	Total SearchTotal                   `json:"total"`
	Hits  []FSXStorageVirtualMachineHit `json:"hits"`
}

type FSXStorageVirtualMachineSearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  FSXStorageVirtualMachineHits `json:"hits"`
}

type FSXStorageVirtualMachinePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewFSXStorageVirtualMachinePaginator(filters []BoolFilter, limit *int64) (FSXStorageVirtualMachinePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_fsx_storagevirtualmachine", filters, limit)
	if err != nil {
		return FSXStorageVirtualMachinePaginator{}, err
	}

	p := FSXStorageVirtualMachinePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p FSXStorageVirtualMachinePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p FSXStorageVirtualMachinePaginator) NextPage(ctx context.Context) ([]FSXStorageVirtualMachine, error) {
	var response FSXStorageVirtualMachineSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []FSXStorageVirtualMachine
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listFSXStorageVirtualMachineFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListFSXStorageVirtualMachine(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListFSXStorageVirtualMachine")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewFSXStorageVirtualMachinePaginator(buildFilter(d.KeyColumnQuals, listFSXStorageVirtualMachineFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getFSXStorageVirtualMachineFilters = map[string]string{
	"keibi_account_id":           "metadata.SourceID",
	"storage_virtual_machine_id": "description.StorageVirtualMachine.StorageVirtualMachineId",
}

func GetFSXStorageVirtualMachine(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetFSXStorageVirtualMachine")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewFSXStorageVirtualMachinePaginator(buildFilter(d.KeyColumnQuals, getFSXStorageVirtualMachineFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: FSXStorageVirtualMachine =============================

// ==========================  START: FSXTask =============================

type FSXTask struct {
	Description   aws.FSXTaskDescription `json:"description"`
	Metadata      aws.Metadata           `json:"metadata"`
	ResourceJobID int                    `json:"resource_job_id"`
	SourceJobID   int                    `json:"source_job_id"`
	ResourceType  string                 `json:"resource_type"`
	SourceType    string                 `json:"source_type"`
	ID            string                 `json:"id"`
	ARN           string                 `json:"arn"`
	SourceID      string                 `json:"source_id"`
}

type FSXTaskHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  FSXTask       `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type FSXTaskHits struct {
	Total SearchTotal  `json:"total"`
	Hits  []FSXTaskHit `json:"hits"`
}

type FSXTaskSearchResponse struct {
	PitID string      `json:"pit_id"`
	Hits  FSXTaskHits `json:"hits"`
}

type FSXTaskPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewFSXTaskPaginator(filters []BoolFilter, limit *int64) (FSXTaskPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_fsx_task", filters, limit)
	if err != nil {
		return FSXTaskPaginator{}, err
	}

	p := FSXTaskPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p FSXTaskPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p FSXTaskPaginator) NextPage(ctx context.Context) ([]FSXTask, error) {
	var response FSXTaskSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []FSXTask
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listFSXTaskFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListFSXTask(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListFSXTask")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewFSXTaskPaginator(buildFilter(d.KeyColumnQuals, listFSXTaskFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getFSXTaskFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"task_id":          "description.Task.TaskId",
}

func GetFSXTask(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetFSXTask")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewFSXTaskPaginator(buildFilter(d.KeyColumnQuals, getFSXTaskFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: FSXTask =============================

// ==========================  START: FSXVolume =============================

type FSXVolume struct {
	Description   aws.FSXVolumeDescription `json:"description"`
	Metadata      aws.Metadata             `json:"metadata"`
	ResourceJobID int                      `json:"resource_job_id"`
	SourceJobID   int                      `json:"source_job_id"`
	ResourceType  string                   `json:"resource_type"`
	SourceType    string                   `json:"source_type"`
	ID            string                   `json:"id"`
	ARN           string                   `json:"arn"`
	SourceID      string                   `json:"source_id"`
}

type FSXVolumeHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  FSXVolume     `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type FSXVolumeHits struct {
	Total SearchTotal    `json:"total"`
	Hits  []FSXVolumeHit `json:"hits"`
}

type FSXVolumeSearchResponse struct {
	PitID string        `json:"pit_id"`
	Hits  FSXVolumeHits `json:"hits"`
}

type FSXVolumePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewFSXVolumePaginator(filters []BoolFilter, limit *int64) (FSXVolumePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_fsx_volume", filters, limit)
	if err != nil {
		return FSXVolumePaginator{}, err
	}

	p := FSXVolumePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p FSXVolumePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p FSXVolumePaginator) NextPage(ctx context.Context) ([]FSXVolume, error) {
	var response FSXVolumeSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []FSXVolume
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listFSXVolumeFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListFSXVolume(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListFSXVolume")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewFSXVolumePaginator(buildFilter(d.KeyColumnQuals, listFSXVolumeFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getFSXVolumeFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"volume_id":        "description.Volume.VolumeId",
}

func GetFSXVolume(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetFSXVolume")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewFSXVolumePaginator(buildFilter(d.KeyColumnQuals, getFSXVolumeFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: FSXVolume =============================

// ==========================  START: FSXSnapshot =============================

type FSXSnapshot struct {
	Description   aws.FSXSnapshotDescription `json:"description"`
	Metadata      aws.Metadata               `json:"metadata"`
	ResourceJobID int                        `json:"resource_job_id"`
	SourceJobID   int                        `json:"source_job_id"`
	ResourceType  string                     `json:"resource_type"`
	SourceType    string                     `json:"source_type"`
	ID            string                     `json:"id"`
	ARN           string                     `json:"arn"`
	SourceID      string                     `json:"source_id"`
}

type FSXSnapshotHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  FSXSnapshot   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type FSXSnapshotHits struct {
	Total SearchTotal      `json:"total"`
	Hits  []FSXSnapshotHit `json:"hits"`
}

type FSXSnapshotSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  FSXSnapshotHits `json:"hits"`
}

type FSXSnapshotPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewFSXSnapshotPaginator(filters []BoolFilter, limit *int64) (FSXSnapshotPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_fsx_snapshot", filters, limit)
	if err != nil {
		return FSXSnapshotPaginator{}, err
	}

	p := FSXSnapshotPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p FSXSnapshotPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p FSXSnapshotPaginator) NextPage(ctx context.Context) ([]FSXSnapshot, error) {
	var response FSXSnapshotSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []FSXSnapshot
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listFSXSnapshotFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListFSXSnapshot(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListFSXSnapshot")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewFSXSnapshotPaginator(buildFilter(d.KeyColumnQuals, listFSXSnapshotFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getFSXSnapshotFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"snapshot_id":      "description.Snapshot.SnapshotId",
}

func GetFSXSnapshot(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetFSXSnapshot")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewFSXSnapshotPaginator(buildFilter(d.KeyColumnQuals, getFSXSnapshotFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: FSXSnapshot =============================

// ==========================  START: ApplicationAutoScalingTarget =============================

type ApplicationAutoScalingTarget struct {
	Description   aws.ApplicationAutoScalingTargetDescription `json:"description"`
	Metadata      aws.Metadata                                `json:"metadata"`
	ResourceJobID int                                         `json:"resource_job_id"`
	SourceJobID   int                                         `json:"source_job_id"`
	ResourceType  string                                      `json:"resource_type"`
	SourceType    string                                      `json:"source_type"`
	ID            string                                      `json:"id"`
	ARN           string                                      `json:"arn"`
	SourceID      string                                      `json:"source_id"`
}

type ApplicationAutoScalingTargetHit struct {
	ID      string                       `json:"_id"`
	Score   float64                      `json:"_score"`
	Index   string                       `json:"_index"`
	Type    string                       `json:"_type"`
	Version int64                        `json:"_version,omitempty"`
	Source  ApplicationAutoScalingTarget `json:"_source"`
	Sort    []interface{}                `json:"sort"`
}

type ApplicationAutoScalingTargetHits struct {
	Total SearchTotal                       `json:"total"`
	Hits  []ApplicationAutoScalingTargetHit `json:"hits"`
}

type ApplicationAutoScalingTargetSearchResponse struct {
	PitID string                           `json:"pit_id"`
	Hits  ApplicationAutoScalingTargetHits `json:"hits"`
}

type ApplicationAutoScalingTargetPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewApplicationAutoScalingTargetPaginator(filters []BoolFilter, limit *int64) (ApplicationAutoScalingTargetPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_applicationautoscaling_target", filters, limit)
	if err != nil {
		return ApplicationAutoScalingTargetPaginator{}, err
	}

	p := ApplicationAutoScalingTargetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ApplicationAutoScalingTargetPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ApplicationAutoScalingTargetPaginator) NextPage(ctx context.Context) ([]ApplicationAutoScalingTarget, error) {
	var response ApplicationAutoScalingTargetSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ApplicationAutoScalingTarget
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listApplicationAutoScalingTargetFilters = map[string]string{
	"keibi_account_id":   "metadata.SourceID",
	"resource_id":        "description.ScalableTarget.ResourceId",
	"scalable_dimension": "description.ScalableTarget.ScalableDimension",
	"service_namespace":  "description.ScalableTarget.ServiceNamespace",
}

func ListApplicationAutoScalingTarget(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListApplicationAutoScalingTarget")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewApplicationAutoScalingTargetPaginator(buildFilter(d.KeyColumnQuals, listApplicationAutoScalingTargetFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getApplicationAutoScalingTargetFilters = map[string]string{
	"keibi_account_id":  "metadata.SourceID",
	"resource_id":       "description.ScalableTarget.ResourceId",
	"service_namespace": "description.ScalableTarget.ServiceNamespace",
}

func GetApplicationAutoScalingTarget(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetApplicationAutoScalingTarget")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewApplicationAutoScalingTargetPaginator(buildFilter(d.KeyColumnQuals, getApplicationAutoScalingTargetFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ApplicationAutoScalingTarget =============================

// ==========================  START: AutoScalingGroup =============================

type AutoScalingGroup struct {
	Description   aws.AutoScalingGroupDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type AutoScalingGroupHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  AutoScalingGroup `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type AutoScalingGroupHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []AutoScalingGroupHit `json:"hits"`
}

type AutoScalingGroupSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  AutoScalingGroupHits `json:"hits"`
}

type AutoScalingGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAutoScalingGroupPaginator(filters []BoolFilter, limit *int64) (AutoScalingGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_autoscaling_autoscalinggroup", filters, limit)
	if err != nil {
		return AutoScalingGroupPaginator{}, err
	}

	p := AutoScalingGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AutoScalingGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AutoScalingGroupPaginator) NextPage(ctx context.Context) ([]AutoScalingGroup, error) {
	var response AutoScalingGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AutoScalingGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAutoScalingGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListAutoScalingGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAutoScalingGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAutoScalingGroupPaginator(buildFilter(d.KeyColumnQuals, listAutoScalingGroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAutoScalingGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.AutoScalingGroup.AutoScalingGroupName",
}

func GetAutoScalingGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAutoScalingGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAutoScalingGroupPaginator(buildFilter(d.KeyColumnQuals, getAutoScalingGroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AutoScalingGroup =============================

// ==========================  START: AutoScalingLaunchConfiguration =============================

type AutoScalingLaunchConfiguration struct {
	Description   aws.AutoScalingLaunchConfigurationDescription `json:"description"`
	Metadata      aws.Metadata                                  `json:"metadata"`
	ResourceJobID int                                           `json:"resource_job_id"`
	SourceJobID   int                                           `json:"source_job_id"`
	ResourceType  string                                        `json:"resource_type"`
	SourceType    string                                        `json:"source_type"`
	ID            string                                        `json:"id"`
	ARN           string                                        `json:"arn"`
	SourceID      string                                        `json:"source_id"`
}

type AutoScalingLaunchConfigurationHit struct {
	ID      string                         `json:"_id"`
	Score   float64                        `json:"_score"`
	Index   string                         `json:"_index"`
	Type    string                         `json:"_type"`
	Version int64                          `json:"_version,omitempty"`
	Source  AutoScalingLaunchConfiguration `json:"_source"`
	Sort    []interface{}                  `json:"sort"`
}

type AutoScalingLaunchConfigurationHits struct {
	Total SearchTotal                         `json:"total"`
	Hits  []AutoScalingLaunchConfigurationHit `json:"hits"`
}

type AutoScalingLaunchConfigurationSearchResponse struct {
	PitID string                             `json:"pit_id"`
	Hits  AutoScalingLaunchConfigurationHits `json:"hits"`
}

type AutoScalingLaunchConfigurationPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAutoScalingLaunchConfigurationPaginator(filters []BoolFilter, limit *int64) (AutoScalingLaunchConfigurationPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_autoscaling_launchconfiguration", filters, limit)
	if err != nil {
		return AutoScalingLaunchConfigurationPaginator{}, err
	}

	p := AutoScalingLaunchConfigurationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AutoScalingLaunchConfigurationPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AutoScalingLaunchConfigurationPaginator) NextPage(ctx context.Context) ([]AutoScalingLaunchConfiguration, error) {
	var response AutoScalingLaunchConfigurationSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AutoScalingLaunchConfiguration
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAutoScalingLaunchConfigurationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListAutoScalingLaunchConfiguration(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAutoScalingLaunchConfiguration")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAutoScalingLaunchConfigurationPaginator(buildFilter(d.KeyColumnQuals, listAutoScalingLaunchConfigurationFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAutoScalingLaunchConfigurationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.LaunchConfiguration.LaunchConfigurationName",
}

func GetAutoScalingLaunchConfiguration(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAutoScalingLaunchConfiguration")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAutoScalingLaunchConfigurationPaginator(buildFilter(d.KeyColumnQuals, getAutoScalingLaunchConfigurationFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AutoScalingLaunchConfiguration =============================

// ==========================  START: CertificateManagerCertificate =============================

type CertificateManagerCertificate struct {
	Description   aws.CertificateManagerCertificateDescription `json:"description"`
	Metadata      aws.Metadata                                 `json:"metadata"`
	ResourceJobID int                                          `json:"resource_job_id"`
	SourceJobID   int                                          `json:"source_job_id"`
	ResourceType  string                                       `json:"resource_type"`
	SourceType    string                                       `json:"source_type"`
	ID            string                                       `json:"id"`
	ARN           string                                       `json:"arn"`
	SourceID      string                                       `json:"source_id"`
}

type CertificateManagerCertificateHit struct {
	ID      string                        `json:"_id"`
	Score   float64                       `json:"_score"`
	Index   string                        `json:"_index"`
	Type    string                        `json:"_type"`
	Version int64                         `json:"_version,omitempty"`
	Source  CertificateManagerCertificate `json:"_source"`
	Sort    []interface{}                 `json:"sort"`
}

type CertificateManagerCertificateHits struct {
	Total SearchTotal                        `json:"total"`
	Hits  []CertificateManagerCertificateHit `json:"hits"`
}

type CertificateManagerCertificateSearchResponse struct {
	PitID string                            `json:"pit_id"`
	Hits  CertificateManagerCertificateHits `json:"hits"`
}

type CertificateManagerCertificatePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCertificateManagerCertificatePaginator(filters []BoolFilter, limit *int64) (CertificateManagerCertificatePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_certificatemanager_certificate", filters, limit)
	if err != nil {
		return CertificateManagerCertificatePaginator{}, err
	}

	p := CertificateManagerCertificatePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CertificateManagerCertificatePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CertificateManagerCertificatePaginator) NextPage(ctx context.Context) ([]CertificateManagerCertificate, error) {
	var response CertificateManagerCertificateSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CertificateManagerCertificate
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCertificateManagerCertificateFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"status":           "description.Certificate.Status",
}

func ListCertificateManagerCertificate(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCertificateManagerCertificate")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCertificateManagerCertificatePaginator(buildFilter(d.KeyColumnQuals, listCertificateManagerCertificateFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCertificateManagerCertificateFilters = map[string]string{
	"certificate_arn":  "description.Certificate.CertificateArn",
	"keibi_account_id": "metadata.SourceID",
}

func GetCertificateManagerCertificate(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCertificateManagerCertificate")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCertificateManagerCertificatePaginator(buildFilter(d.KeyColumnQuals, getCertificateManagerCertificateFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CertificateManagerCertificate =============================

// ==========================  START: CloudTrailTrail =============================

type CloudTrailTrail struct {
	Description   aws.CloudTrailTrailDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type CloudTrailTrailHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  CloudTrailTrail `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type CloudTrailTrailHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []CloudTrailTrailHit `json:"hits"`
}

type CloudTrailTrailSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  CloudTrailTrailHits `json:"hits"`
}

type CloudTrailTrailPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudTrailTrailPaginator(filters []BoolFilter, limit *int64) (CloudTrailTrailPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudtrail_trail", filters, limit)
	if err != nil {
		return CloudTrailTrailPaginator{}, err
	}

	p := CloudTrailTrailPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudTrailTrailPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudTrailTrailPaginator) NextPage(ctx context.Context) ([]CloudTrailTrail, error) {
	var response CloudTrailTrailSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudTrailTrail
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudTrailTrailFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCloudTrailTrail(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudTrailTrail")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudTrailTrailPaginator(buildFilter(d.KeyColumnQuals, listCloudTrailTrailFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudTrailTrailFilters = map[string]string{
	"arn":              "description.Trail.TrailARN",
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Trail.Name",
}

func GetCloudTrailTrail(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudTrailTrail")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudTrailTrailPaginator(buildFilter(d.KeyColumnQuals, getCloudTrailTrailFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudTrailTrail =============================

// ==========================  START: CloudTrailChannel =============================

type CloudTrailChannel struct {
	Description   aws.CloudTrailChannelDescription `json:"description"`
	Metadata      aws.Metadata                     `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

type CloudTrailChannelHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  CloudTrailChannel `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type CloudTrailChannelHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []CloudTrailChannelHit `json:"hits"`
}

type CloudTrailChannelSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  CloudTrailChannelHits `json:"hits"`
}

type CloudTrailChannelPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudTrailChannelPaginator(filters []BoolFilter, limit *int64) (CloudTrailChannelPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudtrail_channel", filters, limit)
	if err != nil {
		return CloudTrailChannelPaginator{}, err
	}

	p := CloudTrailChannelPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudTrailChannelPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudTrailChannelPaginator) NextPage(ctx context.Context) ([]CloudTrailChannel, error) {
	var response CloudTrailChannelSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudTrailChannel
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudTrailChannelFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCloudTrailChannel(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudTrailChannel")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudTrailChannelPaginator(buildFilter(d.KeyColumnQuals, listCloudTrailChannelFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudTrailChannelFilters = map[string]string{
	"arn":              "description.Channel.ChannelArn",
	"keibi_account_id": "metadata.SourceID",
}

func GetCloudTrailChannel(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudTrailChannel")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudTrailChannelPaginator(buildFilter(d.KeyColumnQuals, getCloudTrailChannelFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudTrailChannel =============================

// ==========================  START: CloudTrailEventDataStore =============================

type CloudTrailEventDataStore struct {
	Description   aws.CloudTrailEventDataStoreDescription `json:"description"`
	Metadata      aws.Metadata                            `json:"metadata"`
	ResourceJobID int                                     `json:"resource_job_id"`
	SourceJobID   int                                     `json:"source_job_id"`
	ResourceType  string                                  `json:"resource_type"`
	SourceType    string                                  `json:"source_type"`
	ID            string                                  `json:"id"`
	ARN           string                                  `json:"arn"`
	SourceID      string                                  `json:"source_id"`
}

type CloudTrailEventDataStoreHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  CloudTrailEventDataStore `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type CloudTrailEventDataStoreHits struct {
	Total SearchTotal                   `json:"total"`
	Hits  []CloudTrailEventDataStoreHit `json:"hits"`
}

type CloudTrailEventDataStoreSearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  CloudTrailEventDataStoreHits `json:"hits"`
}

type CloudTrailEventDataStorePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudTrailEventDataStorePaginator(filters []BoolFilter, limit *int64) (CloudTrailEventDataStorePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudtrail_eventdatastore", filters, limit)
	if err != nil {
		return CloudTrailEventDataStorePaginator{}, err
	}

	p := CloudTrailEventDataStorePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudTrailEventDataStorePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudTrailEventDataStorePaginator) NextPage(ctx context.Context) ([]CloudTrailEventDataStore, error) {
	var response CloudTrailEventDataStoreSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudTrailEventDataStore
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudTrailEventDataStoreFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCloudTrailEventDataStore(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudTrailEventDataStore")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudTrailEventDataStorePaginator(buildFilter(d.KeyColumnQuals, listCloudTrailEventDataStoreFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudTrailEventDataStoreFilters = map[string]string{
	"arn":              "description.EventDataStore.EventDataStoreArn",
	"keibi_account_id": "metadata.SourceID",
}

func GetCloudTrailEventDataStore(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudTrailEventDataStore")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudTrailEventDataStorePaginator(buildFilter(d.KeyColumnQuals, getCloudTrailEventDataStoreFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudTrailEventDataStore =============================

// ==========================  START: CloudTrailImport =============================

type CloudTrailImport struct {
	Description   aws.CloudTrailImportDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type CloudTrailImportHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  CloudTrailImport `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type CloudTrailImportHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []CloudTrailImportHit `json:"hits"`
}

type CloudTrailImportSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  CloudTrailImportHits `json:"hits"`
}

type CloudTrailImportPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudTrailImportPaginator(filters []BoolFilter, limit *int64) (CloudTrailImportPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudtrail_import", filters, limit)
	if err != nil {
		return CloudTrailImportPaginator{}, err
	}

	p := CloudTrailImportPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudTrailImportPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudTrailImportPaginator) NextPage(ctx context.Context) ([]CloudTrailImport, error) {
	var response CloudTrailImportSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudTrailImport
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudTrailImportFilters = map[string]string{
	"import_status":    "description.Import.ImportStatus",
	"keibi_account_id": "metadata.SourceID",
}

func ListCloudTrailImport(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudTrailImport")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudTrailImportPaginator(buildFilter(d.KeyColumnQuals, listCloudTrailImportFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudTrailImportFilters = map[string]string{
	"import_id":        "description.Import.ImportId",
	"keibi_account_id": "metadata.SourceID",
}

func GetCloudTrailImport(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudTrailImport")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudTrailImportPaginator(buildFilter(d.KeyColumnQuals, getCloudTrailImportFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudTrailImport =============================

// ==========================  START: CloudTrailQuery =============================

type CloudTrailQuery struct {
	Description   aws.CloudTrailQueryDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type CloudTrailQueryHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  CloudTrailQuery `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type CloudTrailQueryHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []CloudTrailQueryHit `json:"hits"`
}

type CloudTrailQuerySearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  CloudTrailQueryHits `json:"hits"`
}

type CloudTrailQueryPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudTrailQueryPaginator(filters []BoolFilter, limit *int64) (CloudTrailQueryPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudtrail_query", filters, limit)
	if err != nil {
		return CloudTrailQueryPaginator{}, err
	}

	p := CloudTrailQueryPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudTrailQueryPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudTrailQueryPaginator) NextPage(ctx context.Context) ([]CloudTrailQuery, error) {
	var response CloudTrailQuerySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudTrailQuery
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudTrailQueryFilters = map[string]string{
	"creation_time":        "description.Query.QueryStatistics.CreationTime",
	"event_data_store_arn": "description.EventDataStoreARN",
	"keibi_account_id":     "metadata.SourceID",
	"query_status":         "description.Query.QueryStatus",
}

func ListCloudTrailQuery(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudTrailQuery")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudTrailQueryPaginator(buildFilter(d.KeyColumnQuals, listCloudTrailQueryFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudTrailQueryFilters = map[string]string{
	"event_data_store_arn": "description.EventDataStoreARN",
	"keibi_account_id":     "metadata.SourceID",
	"query_id":             "description.Query.QueryId",
}

func GetCloudTrailQuery(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudTrailQuery")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudTrailQueryPaginator(buildFilter(d.KeyColumnQuals, getCloudTrailQueryFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudTrailQuery =============================

// ==========================  START: CloudTrailTrailEvent =============================

type CloudTrailTrailEvent struct {
	Description   aws.CloudTrailTrailEventDescription `json:"description"`
	Metadata      aws.Metadata                        `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type CloudTrailTrailEventHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  CloudTrailTrailEvent `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type CloudTrailTrailEventHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []CloudTrailTrailEventHit `json:"hits"`
}

type CloudTrailTrailEventSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  CloudTrailTrailEventHits `json:"hits"`
}

type CloudTrailTrailEventPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudTrailTrailEventPaginator(filters []BoolFilter, limit *int64) (CloudTrailTrailEventPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudtrail_trailevent", filters, limit)
	if err != nil {
		return CloudTrailTrailEventPaginator{}, err
	}

	p := CloudTrailTrailEventPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudTrailTrailEventPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudTrailTrailEventPaginator) NextPage(ctx context.Context) ([]CloudTrailTrailEvent, error) {
	var response CloudTrailTrailEventSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudTrailTrailEvent
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudTrailTrailEventFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"log_stream_name":  "description.TrailEvent.LogStreamName",
	"timestamp":        "description.TrailEvent.Timestamp",
}

func ListCloudTrailTrailEvent(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudTrailTrailEvent")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudTrailTrailEventPaginator(buildFilter(d.KeyColumnQuals, listCloudTrailTrailEventFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudTrailTrailEventFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetCloudTrailTrailEvent(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudTrailTrailEvent")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudTrailTrailEventPaginator(buildFilter(d.KeyColumnQuals, getCloudTrailTrailEventFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudTrailTrailEvent =============================

// ==========================  START: IAMAccount =============================

type IAMAccount struct {
	Description   aws.IAMAccountDescription `json:"description"`
	Metadata      aws.Metadata              `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	ARN           string                    `json:"arn"`
	SourceID      string                    `json:"source_id"`
}

type IAMAccountHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  IAMAccount    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type IAMAccountHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []IAMAccountHit `json:"hits"`
}

type IAMAccountSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  IAMAccountHits `json:"hits"`
}

type IAMAccountPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMAccountPaginator(filters []BoolFilter, limit *int64) (IAMAccountPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_account", filters, limit)
	if err != nil {
		return IAMAccountPaginator{}, err
	}

	p := IAMAccountPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMAccountPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMAccountPaginator) NextPage(ctx context.Context) ([]IAMAccount, error) {
	var response IAMAccountSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMAccount
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMAccountFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListIAMAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMAccount")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMAccountPaginator(buildFilter(d.KeyColumnQuals, listIAMAccountFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMAccountFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetIAMAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMAccount")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMAccountPaginator(buildFilter(d.KeyColumnQuals, getIAMAccountFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMAccount =============================

// ==========================  START: IAMAccountSummary =============================

type IAMAccountSummary struct {
	Description   aws.IAMAccountSummaryDescription `json:"description"`
	Metadata      aws.Metadata                     `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

type IAMAccountSummaryHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  IAMAccountSummary `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type IAMAccountSummaryHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []IAMAccountSummaryHit `json:"hits"`
}

type IAMAccountSummarySearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  IAMAccountSummaryHits `json:"hits"`
}

type IAMAccountSummaryPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMAccountSummaryPaginator(filters []BoolFilter, limit *int64) (IAMAccountSummaryPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_accountsummary", filters, limit)
	if err != nil {
		return IAMAccountSummaryPaginator{}, err
	}

	p := IAMAccountSummaryPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMAccountSummaryPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMAccountSummaryPaginator) NextPage(ctx context.Context) ([]IAMAccountSummary, error) {
	var response IAMAccountSummarySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMAccountSummary
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMAccountSummaryFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListIAMAccountSummary(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMAccountSummary")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMAccountSummaryPaginator(buildFilter(d.KeyColumnQuals, listIAMAccountSummaryFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMAccountSummaryFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetIAMAccountSummary(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMAccountSummary")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMAccountSummaryPaginator(buildFilter(d.KeyColumnQuals, getIAMAccountSummaryFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMAccountSummary =============================

// ==========================  START: IAMAccessKey =============================

type IAMAccessKey struct {
	Description   aws.IAMAccessKeyDescription `json:"description"`
	Metadata      aws.Metadata                `json:"metadata"`
	ResourceJobID int                         `json:"resource_job_id"`
	SourceJobID   int                         `json:"source_job_id"`
	ResourceType  string                      `json:"resource_type"`
	SourceType    string                      `json:"source_type"`
	ID            string                      `json:"id"`
	ARN           string                      `json:"arn"`
	SourceID      string                      `json:"source_id"`
}

type IAMAccessKeyHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  IAMAccessKey  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type IAMAccessKeyHits struct {
	Total SearchTotal       `json:"total"`
	Hits  []IAMAccessKeyHit `json:"hits"`
}

type IAMAccessKeySearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  IAMAccessKeyHits `json:"hits"`
}

type IAMAccessKeyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMAccessKeyPaginator(filters []BoolFilter, limit *int64) (IAMAccessKeyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_accesskey", filters, limit)
	if err != nil {
		return IAMAccessKeyPaginator{}, err
	}

	p := IAMAccessKeyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMAccessKeyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMAccessKeyPaginator) NextPage(ctx context.Context) ([]IAMAccessKey, error) {
	var response IAMAccessKeySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMAccessKey
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMAccessKeyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListIAMAccessKey(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMAccessKey")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMAccessKeyPaginator(buildFilter(d.KeyColumnQuals, listIAMAccessKeyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMAccessKeyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetIAMAccessKey(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMAccessKey")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMAccessKeyPaginator(buildFilter(d.KeyColumnQuals, getIAMAccessKeyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMAccessKey =============================

// ==========================  START: IAMAccountPasswordPolicy =============================

type IAMAccountPasswordPolicy struct {
	Description   aws.IAMAccountPasswordPolicyDescription `json:"description"`
	Metadata      aws.Metadata                            `json:"metadata"`
	ResourceJobID int                                     `json:"resource_job_id"`
	SourceJobID   int                                     `json:"source_job_id"`
	ResourceType  string                                  `json:"resource_type"`
	SourceType    string                                  `json:"source_type"`
	ID            string                                  `json:"id"`
	ARN           string                                  `json:"arn"`
	SourceID      string                                  `json:"source_id"`
}

type IAMAccountPasswordPolicyHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  IAMAccountPasswordPolicy `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type IAMAccountPasswordPolicyHits struct {
	Total SearchTotal                   `json:"total"`
	Hits  []IAMAccountPasswordPolicyHit `json:"hits"`
}

type IAMAccountPasswordPolicySearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  IAMAccountPasswordPolicyHits `json:"hits"`
}

type IAMAccountPasswordPolicyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMAccountPasswordPolicyPaginator(filters []BoolFilter, limit *int64) (IAMAccountPasswordPolicyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_accountpasswordpolicy", filters, limit)
	if err != nil {
		return IAMAccountPasswordPolicyPaginator{}, err
	}

	p := IAMAccountPasswordPolicyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMAccountPasswordPolicyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMAccountPasswordPolicyPaginator) NextPage(ctx context.Context) ([]IAMAccountPasswordPolicy, error) {
	var response IAMAccountPasswordPolicySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMAccountPasswordPolicy
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMAccountPasswordPolicyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListIAMAccountPasswordPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMAccountPasswordPolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMAccountPasswordPolicyPaginator(buildFilter(d.KeyColumnQuals, listIAMAccountPasswordPolicyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMAccountPasswordPolicyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetIAMAccountPasswordPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMAccountPasswordPolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMAccountPasswordPolicyPaginator(buildFilter(d.KeyColumnQuals, getIAMAccountPasswordPolicyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMAccountPasswordPolicy =============================

// ==========================  START: IAMUser =============================

type IAMUser struct {
	Description   aws.IAMUserDescription `json:"description"`
	Metadata      aws.Metadata           `json:"metadata"`
	ResourceJobID int                    `json:"resource_job_id"`
	SourceJobID   int                    `json:"source_job_id"`
	ResourceType  string                 `json:"resource_type"`
	SourceType    string                 `json:"source_type"`
	ID            string                 `json:"id"`
	ARN           string                 `json:"arn"`
	SourceID      string                 `json:"source_id"`
}

type IAMUserHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  IAMUser       `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type IAMUserHits struct {
	Total SearchTotal  `json:"total"`
	Hits  []IAMUserHit `json:"hits"`
}

type IAMUserSearchResponse struct {
	PitID string      `json:"pit_id"`
	Hits  IAMUserHits `json:"hits"`
}

type IAMUserPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMUserPaginator(filters []BoolFilter, limit *int64) (IAMUserPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_user", filters, limit)
	if err != nil {
		return IAMUserPaginator{}, err
	}

	p := IAMUserPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMUserPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMUserPaginator) NextPage(ctx context.Context) ([]IAMUser, error) {
	var response IAMUserSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMUser
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMUserFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListIAMUser(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMUser")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMUserPaginator(buildFilter(d.KeyColumnQuals, listIAMUserFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMUserFilters = map[string]string{
	"arn":              "description.User.Arn",
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.User.UserName",
}

func GetIAMUser(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMUser")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMUserPaginator(buildFilter(d.KeyColumnQuals, getIAMUserFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMUser =============================

// ==========================  START: IAMGroup =============================

type IAMGroup struct {
	Description   aws.IAMGroupDescription `json:"description"`
	Metadata      aws.Metadata            `json:"metadata"`
	ResourceJobID int                     `json:"resource_job_id"`
	SourceJobID   int                     `json:"source_job_id"`
	ResourceType  string                  `json:"resource_type"`
	SourceType    string                  `json:"source_type"`
	ID            string                  `json:"id"`
	ARN           string                  `json:"arn"`
	SourceID      string                  `json:"source_id"`
}

type IAMGroupHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  IAMGroup      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type IAMGroupHits struct {
	Total SearchTotal   `json:"total"`
	Hits  []IAMGroupHit `json:"hits"`
}

type IAMGroupSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  IAMGroupHits `json:"hits"`
}

type IAMGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMGroupPaginator(filters []BoolFilter, limit *int64) (IAMGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_group", filters, limit)
	if err != nil {
		return IAMGroupPaginator{}, err
	}

	p := IAMGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMGroupPaginator) NextPage(ctx context.Context) ([]IAMGroup, error) {
	var response IAMGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListIAMGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMGroupPaginator(buildFilter(d.KeyColumnQuals, listIAMGroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMGroupFilters = map[string]string{
	"arn":              "description.Group.Arn",
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Group.GroupName",
}

func GetIAMGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMGroupPaginator(buildFilter(d.KeyColumnQuals, getIAMGroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMGroup =============================

// ==========================  START: IAMRole =============================

type IAMRole struct {
	Description   aws.IAMRoleDescription `json:"description"`
	Metadata      aws.Metadata           `json:"metadata"`
	ResourceJobID int                    `json:"resource_job_id"`
	SourceJobID   int                    `json:"source_job_id"`
	ResourceType  string                 `json:"resource_type"`
	SourceType    string                 `json:"source_type"`
	ID            string                 `json:"id"`
	ARN           string                 `json:"arn"`
	SourceID      string                 `json:"source_id"`
}

type IAMRoleHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  IAMRole       `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type IAMRoleHits struct {
	Total SearchTotal  `json:"total"`
	Hits  []IAMRoleHit `json:"hits"`
}

type IAMRoleSearchResponse struct {
	PitID string      `json:"pit_id"`
	Hits  IAMRoleHits `json:"hits"`
}

type IAMRolePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMRolePaginator(filters []BoolFilter, limit *int64) (IAMRolePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_role", filters, limit)
	if err != nil {
		return IAMRolePaginator{}, err
	}

	p := IAMRolePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMRolePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMRolePaginator) NextPage(ctx context.Context) ([]IAMRole, error) {
	var response IAMRoleSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMRole
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMRoleFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListIAMRole(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMRole")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMRolePaginator(buildFilter(d.KeyColumnQuals, listIAMRoleFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMRoleFilters = map[string]string{
	"arn":              "description.Role.Arn",
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Role.RoleName",
}

func GetIAMRole(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMRole")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMRolePaginator(buildFilter(d.KeyColumnQuals, getIAMRoleFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMRole =============================

// ==========================  START: IAMServerCertificate =============================

type IAMServerCertificate struct {
	Description   aws.IAMServerCertificateDescription `json:"description"`
	Metadata      aws.Metadata                        `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type IAMServerCertificateHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  IAMServerCertificate `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type IAMServerCertificateHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []IAMServerCertificateHit `json:"hits"`
}

type IAMServerCertificateSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  IAMServerCertificateHits `json:"hits"`
}

type IAMServerCertificatePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMServerCertificatePaginator(filters []BoolFilter, limit *int64) (IAMServerCertificatePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_servercertificate", filters, limit)
	if err != nil {
		return IAMServerCertificatePaginator{}, err
	}

	p := IAMServerCertificatePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMServerCertificatePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMServerCertificatePaginator) NextPage(ctx context.Context) ([]IAMServerCertificate, error) {
	var response IAMServerCertificateSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMServerCertificate
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMServerCertificateFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListIAMServerCertificate(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMServerCertificate")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMServerCertificatePaginator(buildFilter(d.KeyColumnQuals, listIAMServerCertificateFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMServerCertificateFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.ServerCertificate.ServerCertificateMetadata.ServerCertificateName",
}

func GetIAMServerCertificate(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMServerCertificate")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMServerCertificatePaginator(buildFilter(d.KeyColumnQuals, getIAMServerCertificateFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMServerCertificate =============================

// ==========================  START: IAMPolicy =============================

type IAMPolicy struct {
	Description   aws.IAMPolicyDescription `json:"description"`
	Metadata      aws.Metadata             `json:"metadata"`
	ResourceJobID int                      `json:"resource_job_id"`
	SourceJobID   int                      `json:"source_job_id"`
	ResourceType  string                   `json:"resource_type"`
	SourceType    string                   `json:"source_type"`
	ID            string                   `json:"id"`
	ARN           string                   `json:"arn"`
	SourceID      string                   `json:"source_id"`
}

type IAMPolicyHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  IAMPolicy     `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type IAMPolicyHits struct {
	Total SearchTotal    `json:"total"`
	Hits  []IAMPolicyHit `json:"hits"`
}

type IAMPolicySearchResponse struct {
	PitID string        `json:"pit_id"`
	Hits  IAMPolicyHits `json:"hits"`
}

type IAMPolicyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMPolicyPaginator(filters []BoolFilter, limit *int64) (IAMPolicyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_policy", filters, limit)
	if err != nil {
		return IAMPolicyPaginator{}, err
	}

	p := IAMPolicyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMPolicyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMPolicyPaginator) NextPage(ctx context.Context) ([]IAMPolicy, error) {
	var response IAMPolicySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMPolicy
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMPolicyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListIAMPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMPolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMPolicyPaginator(buildFilter(d.KeyColumnQuals, listIAMPolicyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMPolicyFilters = map[string]string{
	"arn":              "description.Policy.Arn",
	"keibi_account_id": "metadata.SourceID",
}

func GetIAMPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMPolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMPolicyPaginator(buildFilter(d.KeyColumnQuals, getIAMPolicyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMPolicy =============================

// ==========================  START: IAMCredentialReport =============================

type IAMCredentialReport struct {
	Description   aws.IAMCredentialReportDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type IAMCredentialReportHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  IAMCredentialReport `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type IAMCredentialReportHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []IAMCredentialReportHit `json:"hits"`
}

type IAMCredentialReportSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  IAMCredentialReportHits `json:"hits"`
}

type IAMCredentialReportPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMCredentialReportPaginator(filters []BoolFilter, limit *int64) (IAMCredentialReportPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_credentialreport", filters, limit)
	if err != nil {
		return IAMCredentialReportPaginator{}, err
	}

	p := IAMCredentialReportPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMCredentialReportPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMCredentialReportPaginator) NextPage(ctx context.Context) ([]IAMCredentialReport, error) {
	var response IAMCredentialReportSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMCredentialReport
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMCredentialReportFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListIAMCredentialReport(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMCredentialReport")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMCredentialReportPaginator(buildFilter(d.KeyColumnQuals, listIAMCredentialReportFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMCredentialReportFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetIAMCredentialReport(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMCredentialReport")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMCredentialReportPaginator(buildFilter(d.KeyColumnQuals, getIAMCredentialReportFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMCredentialReport =============================

// ==========================  START: IAMVirtualMFADevice =============================

type IAMVirtualMFADevice struct {
	Description   aws.IAMVirtualMFADeviceDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type IAMVirtualMFADeviceHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  IAMVirtualMFADevice `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type IAMVirtualMFADeviceHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []IAMVirtualMFADeviceHit `json:"hits"`
}

type IAMVirtualMFADeviceSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  IAMVirtualMFADeviceHits `json:"hits"`
}

type IAMVirtualMFADevicePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMVirtualMFADevicePaginator(filters []BoolFilter, limit *int64) (IAMVirtualMFADevicePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_virtualmfadevices", filters, limit)
	if err != nil {
		return IAMVirtualMFADevicePaginator{}, err
	}

	p := IAMVirtualMFADevicePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMVirtualMFADevicePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMVirtualMFADevicePaginator) NextPage(ctx context.Context) ([]IAMVirtualMFADevice, error) {
	var response IAMVirtualMFADeviceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMVirtualMFADevice
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMVirtualMFADeviceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListIAMVirtualMFADevice(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMVirtualMFADevice")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMVirtualMFADevicePaginator(buildFilter(d.KeyColumnQuals, listIAMVirtualMFADeviceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMVirtualMFADeviceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetIAMVirtualMFADevice(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMVirtualMFADevice")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMVirtualMFADevicePaginator(buildFilter(d.KeyColumnQuals, getIAMVirtualMFADeviceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMVirtualMFADevice =============================

// ==========================  START: IAMPolicyAttachment =============================

type IAMPolicyAttachment struct {
	Description   aws.IAMPolicyAttachmentDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type IAMPolicyAttachmentHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  IAMPolicyAttachment `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type IAMPolicyAttachmentHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []IAMPolicyAttachmentHit `json:"hits"`
}

type IAMPolicyAttachmentSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  IAMPolicyAttachmentHits `json:"hits"`
}

type IAMPolicyAttachmentPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMPolicyAttachmentPaginator(filters []BoolFilter, limit *int64) (IAMPolicyAttachmentPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_policyattachment", filters, limit)
	if err != nil {
		return IAMPolicyAttachmentPaginator{}, err
	}

	p := IAMPolicyAttachmentPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMPolicyAttachmentPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMPolicyAttachmentPaginator) NextPage(ctx context.Context) ([]IAMPolicyAttachment, error) {
	var response IAMPolicyAttachmentSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMPolicyAttachment
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMPolicyAttachmentFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListIAMPolicyAttachment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMPolicyAttachment")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMPolicyAttachmentPaginator(buildFilter(d.KeyColumnQuals, listIAMPolicyAttachmentFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMPolicyAttachmentFilters = map[string]string{
	"is_attached":      "description.IsAttached",
	"keibi_account_id": "metadata.SourceID",
}

func GetIAMPolicyAttachment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMPolicyAttachment")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMPolicyAttachmentPaginator(buildFilter(d.KeyColumnQuals, getIAMPolicyAttachmentFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMPolicyAttachment =============================

// ==========================  START: IAMSamlProvider =============================

type IAMSamlProvider struct {
	Description   aws.IAMSamlProviderDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type IAMSamlProviderHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  IAMSamlProvider `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type IAMSamlProviderHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []IAMSamlProviderHit `json:"hits"`
}

type IAMSamlProviderSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  IAMSamlProviderHits `json:"hits"`
}

type IAMSamlProviderPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMSamlProviderPaginator(filters []BoolFilter, limit *int64) (IAMSamlProviderPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_samlprovider", filters, limit)
	if err != nil {
		return IAMSamlProviderPaginator{}, err
	}

	p := IAMSamlProviderPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMSamlProviderPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMSamlProviderPaginator) NextPage(ctx context.Context) ([]IAMSamlProvider, error) {
	var response IAMSamlProviderSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMSamlProvider
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMSamlProviderFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListIAMSamlProvider(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMSamlProvider")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMSamlProviderPaginator(buildFilter(d.KeyColumnQuals, listIAMSamlProviderFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMSamlProviderFilters = map[string]string{
	"arn":              "ARN",
	"keibi_account_id": "metadata.SourceID",
}

func GetIAMSamlProvider(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMSamlProvider")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMSamlProviderPaginator(buildFilter(d.KeyColumnQuals, getIAMSamlProviderFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMSamlProvider =============================

// ==========================  START: IAMServiceSpecificCredential =============================

type IAMServiceSpecificCredential struct {
	Description   aws.IAMServiceSpecificCredentialDescription `json:"description"`
	Metadata      aws.Metadata                                `json:"metadata"`
	ResourceJobID int                                         `json:"resource_job_id"`
	SourceJobID   int                                         `json:"source_job_id"`
	ResourceType  string                                      `json:"resource_type"`
	SourceType    string                                      `json:"source_type"`
	ID            string                                      `json:"id"`
	ARN           string                                      `json:"arn"`
	SourceID      string                                      `json:"source_id"`
}

type IAMServiceSpecificCredentialHit struct {
	ID      string                       `json:"_id"`
	Score   float64                      `json:"_score"`
	Index   string                       `json:"_index"`
	Type    string                       `json:"_type"`
	Version int64                        `json:"_version,omitempty"`
	Source  IAMServiceSpecificCredential `json:"_source"`
	Sort    []interface{}                `json:"sort"`
}

type IAMServiceSpecificCredentialHits struct {
	Total SearchTotal                       `json:"total"`
	Hits  []IAMServiceSpecificCredentialHit `json:"hits"`
}

type IAMServiceSpecificCredentialSearchResponse struct {
	PitID string                           `json:"pit_id"`
	Hits  IAMServiceSpecificCredentialHits `json:"hits"`
}

type IAMServiceSpecificCredentialPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMServiceSpecificCredentialPaginator(filters []BoolFilter, limit *int64) (IAMServiceSpecificCredentialPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_servicespecificcredential", filters, limit)
	if err != nil {
		return IAMServiceSpecificCredentialPaginator{}, err
	}

	p := IAMServiceSpecificCredentialPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMServiceSpecificCredentialPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMServiceSpecificCredentialPaginator) NextPage(ctx context.Context) ([]IAMServiceSpecificCredential, error) {
	var response IAMServiceSpecificCredentialSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMServiceSpecificCredential
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMServiceSpecificCredentialFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"service_name":     "description.ServiceSpecificCredential.ServiceName",
	"user_name":        "description.ServiceSpecificCredential.UserName",
}

func ListIAMServiceSpecificCredential(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMServiceSpecificCredential")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMServiceSpecificCredentialPaginator(buildFilter(d.KeyColumnQuals, listIAMServiceSpecificCredentialFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMServiceSpecificCredentialFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetIAMServiceSpecificCredential(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMServiceSpecificCredential")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMServiceSpecificCredentialPaginator(buildFilter(d.KeyColumnQuals, getIAMServiceSpecificCredentialFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMServiceSpecificCredential =============================

// ==========================  START: RDSDBCluster =============================

type RDSDBCluster struct {
	Description   aws.RDSDBClusterDescription `json:"description"`
	Metadata      aws.Metadata                `json:"metadata"`
	ResourceJobID int                         `json:"resource_job_id"`
	SourceJobID   int                         `json:"source_job_id"`
	ResourceType  string                      `json:"resource_type"`
	SourceType    string                      `json:"source_type"`
	ID            string                      `json:"id"`
	ARN           string                      `json:"arn"`
	SourceID      string                      `json:"source_id"`
}

type RDSDBClusterHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  RDSDBCluster  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type RDSDBClusterHits struct {
	Total SearchTotal       `json:"total"`
	Hits  []RDSDBClusterHit `json:"hits"`
}

type RDSDBClusterSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  RDSDBClusterHits `json:"hits"`
}

type RDSDBClusterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRDSDBClusterPaginator(filters []BoolFilter, limit *int64) (RDSDBClusterPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_rds_dbcluster", filters, limit)
	if err != nil {
		return RDSDBClusterPaginator{}, err
	}

	p := RDSDBClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RDSDBClusterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p RDSDBClusterPaginator) NextPage(ctx context.Context) ([]RDSDBCluster, error) {
	var response RDSDBClusterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RDSDBCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRDSDBClusterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListRDSDBCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRDSDBCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRDSDBClusterPaginator(buildFilter(d.KeyColumnQuals, listRDSDBClusterFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRDSDBClusterFilters = map[string]string{
	"db_cluster_identifier": "description.DBCluster.DBClusterIdentifier",
	"keibi_account_id":      "metadata.SourceID",
}

func GetRDSDBCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRDSDBCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRDSDBClusterPaginator(buildFilter(d.KeyColumnQuals, getRDSDBClusterFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RDSDBCluster =============================

// ==========================  START: RDSDBClusterSnapshot =============================

type RDSDBClusterSnapshot struct {
	Description   aws.RDSDBClusterSnapshotDescription `json:"description"`
	Metadata      aws.Metadata                        `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type RDSDBClusterSnapshotHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  RDSDBClusterSnapshot `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type RDSDBClusterSnapshotHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []RDSDBClusterSnapshotHit `json:"hits"`
}

type RDSDBClusterSnapshotSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  RDSDBClusterSnapshotHits `json:"hits"`
}

type RDSDBClusterSnapshotPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRDSDBClusterSnapshotPaginator(filters []BoolFilter, limit *int64) (RDSDBClusterSnapshotPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_rds_dbclustersnapshot", filters, limit)
	if err != nil {
		return RDSDBClusterSnapshotPaginator{}, err
	}

	p := RDSDBClusterSnapshotPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RDSDBClusterSnapshotPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p RDSDBClusterSnapshotPaginator) NextPage(ctx context.Context) ([]RDSDBClusterSnapshot, error) {
	var response RDSDBClusterSnapshotSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RDSDBClusterSnapshot
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRDSDBClusterSnapshotFilters = map[string]string{
	"db_cluster_identifier":          "description.DBClusterSnapshot.DBClusterIdentifier",
	"db_cluster_snapshot_identifier": "description.DBClusterSnapshot.DBClusterSnapshotIdentifier",
	"engine":                         "description.DBClusterSnapshot.Engine",
	"keibi_account_id":               "metadata.SourceID",
	"type":                           "description.DBClusterSnapshot.SnapshotType",
}

func ListRDSDBClusterSnapshot(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRDSDBClusterSnapshot")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRDSDBClusterSnapshotPaginator(buildFilter(d.KeyColumnQuals, listRDSDBClusterSnapshotFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRDSDBClusterSnapshotFilters = map[string]string{
	"db_cluster_snapshot_identifier": "description.DBClusterSnapshot.DBClusterIdentifier",
	"keibi_account_id":               "metadata.SourceID",
}

func GetRDSDBClusterSnapshot(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRDSDBClusterSnapshot")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRDSDBClusterSnapshotPaginator(buildFilter(d.KeyColumnQuals, getRDSDBClusterSnapshotFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RDSDBClusterSnapshot =============================

// ==========================  START: RDSDBEventSubscription =============================

type RDSDBEventSubscription struct {
	Description   aws.RDSDBEventSubscriptionDescription `json:"description"`
	Metadata      aws.Metadata                          `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

type RDSDBEventSubscriptionHit struct {
	ID      string                 `json:"_id"`
	Score   float64                `json:"_score"`
	Index   string                 `json:"_index"`
	Type    string                 `json:"_type"`
	Version int64                  `json:"_version,omitempty"`
	Source  RDSDBEventSubscription `json:"_source"`
	Sort    []interface{}          `json:"sort"`
}

type RDSDBEventSubscriptionHits struct {
	Total SearchTotal                 `json:"total"`
	Hits  []RDSDBEventSubscriptionHit `json:"hits"`
}

type RDSDBEventSubscriptionSearchResponse struct {
	PitID string                     `json:"pit_id"`
	Hits  RDSDBEventSubscriptionHits `json:"hits"`
}

type RDSDBEventSubscriptionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRDSDBEventSubscriptionPaginator(filters []BoolFilter, limit *int64) (RDSDBEventSubscriptionPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_rds_eventsubscription", filters, limit)
	if err != nil {
		return RDSDBEventSubscriptionPaginator{}, err
	}

	p := RDSDBEventSubscriptionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RDSDBEventSubscriptionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p RDSDBEventSubscriptionPaginator) NextPage(ctx context.Context) ([]RDSDBEventSubscription, error) {
	var response RDSDBEventSubscriptionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RDSDBEventSubscription
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRDSDBEventSubscriptionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListRDSDBEventSubscription(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRDSDBEventSubscription")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRDSDBEventSubscriptionPaginator(buildFilter(d.KeyColumnQuals, listRDSDBEventSubscriptionFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRDSDBEventSubscriptionFilters = map[string]string{
	"cust_subscription_id": "description.EventSubscription.CustSubscriptionId",
	"keibi_account_id":     "metadata.SourceID",
}

func GetRDSDBEventSubscription(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRDSDBEventSubscription")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRDSDBEventSubscriptionPaginator(buildFilter(d.KeyColumnQuals, getRDSDBEventSubscriptionFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RDSDBEventSubscription =============================

// ==========================  START: RDSDBInstance =============================

type RDSDBInstance struct {
	Description   aws.RDSDBInstanceDescription `json:"description"`
	Metadata      aws.Metadata                 `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

type RDSDBInstanceHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  RDSDBInstance `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type RDSDBInstanceHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []RDSDBInstanceHit `json:"hits"`
}

type RDSDBInstanceSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  RDSDBInstanceHits `json:"hits"`
}

type RDSDBInstancePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRDSDBInstancePaginator(filters []BoolFilter, limit *int64) (RDSDBInstancePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_rds_dbinstance", filters, limit)
	if err != nil {
		return RDSDBInstancePaginator{}, err
	}

	p := RDSDBInstancePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RDSDBInstancePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p RDSDBInstancePaginator) NextPage(ctx context.Context) ([]RDSDBInstance, error) {
	var response RDSDBInstanceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RDSDBInstance
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRDSDBInstanceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListRDSDBInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRDSDBInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRDSDBInstancePaginator(buildFilter(d.KeyColumnQuals, listRDSDBInstanceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRDSDBInstanceFilters = map[string]string{
	"db_instance_identifier": "description.DBInstance.DBInstanceIdentifier",
	"keibi_account_id":       "metadata.SourceID",
}

func GetRDSDBInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRDSDBInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRDSDBInstancePaginator(buildFilter(d.KeyColumnQuals, getRDSDBInstanceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RDSDBInstance =============================

// ==========================  START: RDSDBSnapshot =============================

type RDSDBSnapshot struct {
	Description   aws.RDSDBSnapshotDescription `json:"description"`
	Metadata      aws.Metadata                 `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

type RDSDBSnapshotHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  RDSDBSnapshot `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type RDSDBSnapshotHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []RDSDBSnapshotHit `json:"hits"`
}

type RDSDBSnapshotSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  RDSDBSnapshotHits `json:"hits"`
}

type RDSDBSnapshotPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRDSDBSnapshotPaginator(filters []BoolFilter, limit *int64) (RDSDBSnapshotPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_rds_dbsnapshot", filters, limit)
	if err != nil {
		return RDSDBSnapshotPaginator{}, err
	}

	p := RDSDBSnapshotPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RDSDBSnapshotPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p RDSDBSnapshotPaginator) NextPage(ctx context.Context) ([]RDSDBSnapshot, error) {
	var response RDSDBSnapshotSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RDSDBSnapshot
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRDSDBSnapshotFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListRDSDBSnapshot(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRDSDBSnapshot")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRDSDBSnapshotPaginator(buildFilter(d.KeyColumnQuals, listRDSDBSnapshotFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRDSDBSnapshotFilters = map[string]string{
	"db_snapshot_identifier": "description.DBSnapshot.DBInstanceIdentifier",
	"keibi_account_id":       "metadata.SourceID",
}

func GetRDSDBSnapshot(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRDSDBSnapshot")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRDSDBSnapshotPaginator(buildFilter(d.KeyColumnQuals, getRDSDBSnapshotFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RDSDBSnapshot =============================

// ==========================  START: RDSGlobalCluster =============================

type RDSGlobalCluster struct {
	Description   aws.RDSGlobalClusterDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type RDSGlobalClusterHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  RDSGlobalCluster `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type RDSGlobalClusterHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []RDSGlobalClusterHit `json:"hits"`
}

type RDSGlobalClusterSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  RDSGlobalClusterHits `json:"hits"`
}

type RDSGlobalClusterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRDSGlobalClusterPaginator(filters []BoolFilter, limit *int64) (RDSGlobalClusterPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_rds_globalcluster", filters, limit)
	if err != nil {
		return RDSGlobalClusterPaginator{}, err
	}

	p := RDSGlobalClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RDSGlobalClusterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p RDSGlobalClusterPaginator) NextPage(ctx context.Context) ([]RDSGlobalCluster, error) {
	var response RDSGlobalClusterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RDSGlobalCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRDSGlobalClusterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListRDSGlobalCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRDSGlobalCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRDSGlobalClusterPaginator(buildFilter(d.KeyColumnQuals, listRDSGlobalClusterFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRDSGlobalClusterFilters = map[string]string{
	"global_cluster_identifier": "description.DBGlobalCluster.GlobalClusterIdentifier",
	"keibi_account_id":          "metadata.SourceID",
}

func GetRDSGlobalCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRDSGlobalCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRDSGlobalClusterPaginator(buildFilter(d.KeyColumnQuals, getRDSGlobalClusterFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RDSGlobalCluster =============================

// ==========================  START: RedshiftCluster =============================

type RedshiftCluster struct {
	Description   aws.RedshiftClusterDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type RedshiftClusterHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  RedshiftCluster `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type RedshiftClusterHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []RedshiftClusterHit `json:"hits"`
}

type RedshiftClusterSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  RedshiftClusterHits `json:"hits"`
}

type RedshiftClusterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRedshiftClusterPaginator(filters []BoolFilter, limit *int64) (RedshiftClusterPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_redshift_cluster", filters, limit)
	if err != nil {
		return RedshiftClusterPaginator{}, err
	}

	p := RedshiftClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RedshiftClusterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p RedshiftClusterPaginator) NextPage(ctx context.Context) ([]RedshiftCluster, error) {
	var response RedshiftClusterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RedshiftCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRedshiftClusterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListRedshiftCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRedshiftCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRedshiftClusterPaginator(buildFilter(d.KeyColumnQuals, listRedshiftClusterFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRedshiftClusterFilters = map[string]string{
	"cluster_identifier": "description.Cluster",
	"keibi_account_id":   "metadata.SourceID",
}

func GetRedshiftCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRedshiftCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRedshiftClusterPaginator(buildFilter(d.KeyColumnQuals, getRedshiftClusterFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RedshiftCluster =============================

// ==========================  START: RedshiftClusterParameterGroup =============================

type RedshiftClusterParameterGroup struct {
	Description   aws.RedshiftClusterParameterGroupDescription `json:"description"`
	Metadata      aws.Metadata                                 `json:"metadata"`
	ResourceJobID int                                          `json:"resource_job_id"`
	SourceJobID   int                                          `json:"source_job_id"`
	ResourceType  string                                       `json:"resource_type"`
	SourceType    string                                       `json:"source_type"`
	ID            string                                       `json:"id"`
	ARN           string                                       `json:"arn"`
	SourceID      string                                       `json:"source_id"`
}

type RedshiftClusterParameterGroupHit struct {
	ID      string                        `json:"_id"`
	Score   float64                       `json:"_score"`
	Index   string                        `json:"_index"`
	Type    string                        `json:"_type"`
	Version int64                         `json:"_version,omitempty"`
	Source  RedshiftClusterParameterGroup `json:"_source"`
	Sort    []interface{}                 `json:"sort"`
}

type RedshiftClusterParameterGroupHits struct {
	Total SearchTotal                        `json:"total"`
	Hits  []RedshiftClusterParameterGroupHit `json:"hits"`
}

type RedshiftClusterParameterGroupSearchResponse struct {
	PitID string                            `json:"pit_id"`
	Hits  RedshiftClusterParameterGroupHits `json:"hits"`
}

type RedshiftClusterParameterGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRedshiftClusterParameterGroupPaginator(filters []BoolFilter, limit *int64) (RedshiftClusterParameterGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_redshift_clusterparametergroup", filters, limit)
	if err != nil {
		return RedshiftClusterParameterGroupPaginator{}, err
	}

	p := RedshiftClusterParameterGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RedshiftClusterParameterGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p RedshiftClusterParameterGroupPaginator) NextPage(ctx context.Context) ([]RedshiftClusterParameterGroup, error) {
	var response RedshiftClusterParameterGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RedshiftClusterParameterGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRedshiftClusterParameterGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListRedshiftClusterParameterGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRedshiftClusterParameterGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRedshiftClusterParameterGroupPaginator(buildFilter(d.KeyColumnQuals, listRedshiftClusterParameterGroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRedshiftClusterParameterGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.ClusterParameterGroup.ParameterGroupName",
}

func GetRedshiftClusterParameterGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRedshiftClusterParameterGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRedshiftClusterParameterGroupPaginator(buildFilter(d.KeyColumnQuals, getRedshiftClusterParameterGroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RedshiftClusterParameterGroup =============================

// ==========================  START: RedshiftSnapshot =============================

type RedshiftSnapshot struct {
	Description   aws.RedshiftSnapshotDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type RedshiftSnapshotHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  RedshiftSnapshot `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type RedshiftSnapshotHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []RedshiftSnapshotHit `json:"hits"`
}

type RedshiftSnapshotSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  RedshiftSnapshotHits `json:"hits"`
}

type RedshiftSnapshotPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRedshiftSnapshotPaginator(filters []BoolFilter, limit *int64) (RedshiftSnapshotPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_redshift_snapshot", filters, limit)
	if err != nil {
		return RedshiftSnapshotPaginator{}, err
	}

	p := RedshiftSnapshotPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RedshiftSnapshotPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p RedshiftSnapshotPaginator) NextPage(ctx context.Context) ([]RedshiftSnapshot, error) {
	var response RedshiftSnapshotSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RedshiftSnapshot
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRedshiftSnapshotFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListRedshiftSnapshot(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRedshiftSnapshot")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRedshiftSnapshotPaginator(buildFilter(d.KeyColumnQuals, listRedshiftSnapshotFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRedshiftSnapshotFilters = map[string]string{
	"keibi_account_id":    "metadata.SourceID",
	"snapshot_identifier": "description.Snapshot.SnapshotIdentifier",
}

func GetRedshiftSnapshot(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRedshiftSnapshot")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRedshiftSnapshotPaginator(buildFilter(d.KeyColumnQuals, getRedshiftSnapshotFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RedshiftSnapshot =============================

// ==========================  START: RedshiftServerlessNamespace =============================

type RedshiftServerlessNamespace struct {
	Description   aws.RedshiftServerlessNamespaceDescription `json:"description"`
	Metadata      aws.Metadata                               `json:"metadata"`
	ResourceJobID int                                        `json:"resource_job_id"`
	SourceJobID   int                                        `json:"source_job_id"`
	ResourceType  string                                     `json:"resource_type"`
	SourceType    string                                     `json:"source_type"`
	ID            string                                     `json:"id"`
	ARN           string                                     `json:"arn"`
	SourceID      string                                     `json:"source_id"`
}

type RedshiftServerlessNamespaceHit struct {
	ID      string                      `json:"_id"`
	Score   float64                     `json:"_score"`
	Index   string                      `json:"_index"`
	Type    string                      `json:"_type"`
	Version int64                       `json:"_version,omitempty"`
	Source  RedshiftServerlessNamespace `json:"_source"`
	Sort    []interface{}               `json:"sort"`
}

type RedshiftServerlessNamespaceHits struct {
	Total SearchTotal                      `json:"total"`
	Hits  []RedshiftServerlessNamespaceHit `json:"hits"`
}

type RedshiftServerlessNamespaceSearchResponse struct {
	PitID string                          `json:"pit_id"`
	Hits  RedshiftServerlessNamespaceHits `json:"hits"`
}

type RedshiftServerlessNamespacePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRedshiftServerlessNamespacePaginator(filters []BoolFilter, limit *int64) (RedshiftServerlessNamespacePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_redshiftserverless_namespace", filters, limit)
	if err != nil {
		return RedshiftServerlessNamespacePaginator{}, err
	}

	p := RedshiftServerlessNamespacePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RedshiftServerlessNamespacePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p RedshiftServerlessNamespacePaginator) NextPage(ctx context.Context) ([]RedshiftServerlessNamespace, error) {
	var response RedshiftServerlessNamespaceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RedshiftServerlessNamespace
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRedshiftServerlessNamespaceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListRedshiftServerlessNamespace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRedshiftServerlessNamespace")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRedshiftServerlessNamespacePaginator(buildFilter(d.KeyColumnQuals, listRedshiftServerlessNamespaceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRedshiftServerlessNamespaceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"namespace_name":   "description.Namespace.NamespaceName",
}

func GetRedshiftServerlessNamespace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRedshiftServerlessNamespace")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRedshiftServerlessNamespacePaginator(buildFilter(d.KeyColumnQuals, getRedshiftServerlessNamespaceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RedshiftServerlessNamespace =============================

// ==========================  START: RedshiftServerlessSnapshot =============================

type RedshiftServerlessSnapshot struct {
	Description   aws.RedshiftServerlessSnapshotDescription `json:"description"`
	Metadata      aws.Metadata                              `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

type RedshiftServerlessSnapshotHit struct {
	ID      string                     `json:"_id"`
	Score   float64                    `json:"_score"`
	Index   string                     `json:"_index"`
	Type    string                     `json:"_type"`
	Version int64                      `json:"_version,omitempty"`
	Source  RedshiftServerlessSnapshot `json:"_source"`
	Sort    []interface{}              `json:"sort"`
}

type RedshiftServerlessSnapshotHits struct {
	Total SearchTotal                     `json:"total"`
	Hits  []RedshiftServerlessSnapshotHit `json:"hits"`
}

type RedshiftServerlessSnapshotSearchResponse struct {
	PitID string                         `json:"pit_id"`
	Hits  RedshiftServerlessSnapshotHits `json:"hits"`
}

type RedshiftServerlessSnapshotPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRedshiftServerlessSnapshotPaginator(filters []BoolFilter, limit *int64) (RedshiftServerlessSnapshotPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_redshiftserverless_snapshot", filters, limit)
	if err != nil {
		return RedshiftServerlessSnapshotPaginator{}, err
	}

	p := RedshiftServerlessSnapshotPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RedshiftServerlessSnapshotPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p RedshiftServerlessSnapshotPaginator) NextPage(ctx context.Context) ([]RedshiftServerlessSnapshot, error) {
	var response RedshiftServerlessSnapshotSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RedshiftServerlessSnapshot
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRedshiftServerlessSnapshotFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListRedshiftServerlessSnapshot(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRedshiftServerlessSnapshot")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRedshiftServerlessSnapshotPaginator(buildFilter(d.KeyColumnQuals, listRedshiftServerlessSnapshotFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRedshiftServerlessSnapshotFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"snapshot_name":    "description.Snapshot.SnapshotName",
}

func GetRedshiftServerlessSnapshot(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRedshiftServerlessSnapshot")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRedshiftServerlessSnapshotPaginator(buildFilter(d.KeyColumnQuals, getRedshiftServerlessSnapshotFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RedshiftServerlessSnapshot =============================

// ==========================  START: SNSTopic =============================

type SNSTopic struct {
	Description   aws.SNSTopicDescription `json:"description"`
	Metadata      aws.Metadata            `json:"metadata"`
	ResourceJobID int                     `json:"resource_job_id"`
	SourceJobID   int                     `json:"source_job_id"`
	ResourceType  string                  `json:"resource_type"`
	SourceType    string                  `json:"source_type"`
	ID            string                  `json:"id"`
	ARN           string                  `json:"arn"`
	SourceID      string                  `json:"source_id"`
}

type SNSTopicHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  SNSTopic      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type SNSTopicHits struct {
	Total SearchTotal   `json:"total"`
	Hits  []SNSTopicHit `json:"hits"`
}

type SNSTopicSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  SNSTopicHits `json:"hits"`
}

type SNSTopicPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSNSTopicPaginator(filters []BoolFilter, limit *int64) (SNSTopicPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_sns_topic", filters, limit)
	if err != nil {
		return SNSTopicPaginator{}, err
	}

	p := SNSTopicPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SNSTopicPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SNSTopicPaginator) NextPage(ctx context.Context) ([]SNSTopic, error) {
	var response SNSTopicSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SNSTopic
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSNSTopicFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSNSTopic(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSNSTopic")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSNSTopicPaginator(buildFilter(d.KeyColumnQuals, listSNSTopicFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSNSTopicFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"topic_arn":        "description.Attributes.TopicArn",
}

func GetSNSTopic(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSNSTopic")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSNSTopicPaginator(buildFilter(d.KeyColumnQuals, getSNSTopicFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SNSTopic =============================

// ==========================  START: SNSSubscription =============================

type SNSSubscription struct {
	Description   aws.SNSSubscriptionDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type SNSSubscriptionHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  SNSSubscription `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type SNSSubscriptionHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []SNSSubscriptionHit `json:"hits"`
}

type SNSSubscriptionSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  SNSSubscriptionHits `json:"hits"`
}

type SNSSubscriptionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSNSSubscriptionPaginator(filters []BoolFilter, limit *int64) (SNSSubscriptionPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_sns_subscription", filters, limit)
	if err != nil {
		return SNSSubscriptionPaginator{}, err
	}

	p := SNSSubscriptionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SNSSubscriptionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SNSSubscriptionPaginator) NextPage(ctx context.Context) ([]SNSSubscription, error) {
	var response SNSSubscriptionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SNSSubscription
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSNSSubscriptionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSNSSubscription(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSNSSubscription")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSNSSubscriptionPaginator(buildFilter(d.KeyColumnQuals, listSNSSubscriptionFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSNSSubscriptionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"subscription_arn": "description.Subscription.SubscriptionArn",
}

func GetSNSSubscription(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSNSSubscription")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSNSSubscriptionPaginator(buildFilter(d.KeyColumnQuals, getSNSSubscriptionFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SNSSubscription =============================

// ==========================  START: SQSQueue =============================

type SQSQueue struct {
	Description   aws.SQSQueueDescription `json:"description"`
	Metadata      aws.Metadata            `json:"metadata"`
	ResourceJobID int                     `json:"resource_job_id"`
	SourceJobID   int                     `json:"source_job_id"`
	ResourceType  string                  `json:"resource_type"`
	SourceType    string                  `json:"source_type"`
	ID            string                  `json:"id"`
	ARN           string                  `json:"arn"`
	SourceID      string                  `json:"source_id"`
}

type SQSQueueHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  SQSQueue      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type SQSQueueHits struct {
	Total SearchTotal   `json:"total"`
	Hits  []SQSQueueHit `json:"hits"`
}

type SQSQueueSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  SQSQueueHits `json:"hits"`
}

type SQSQueuePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSQSQueuePaginator(filters []BoolFilter, limit *int64) (SQSQueuePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_sqs_queue", filters, limit)
	if err != nil {
		return SQSQueuePaginator{}, err
	}

	p := SQSQueuePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SQSQueuePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SQSQueuePaginator) NextPage(ctx context.Context) ([]SQSQueue, error) {
	var response SQSQueueSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SQSQueue
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSQSQueueFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSQSQueue(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSQSQueue")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSQSQueuePaginator(buildFilter(d.KeyColumnQuals, listSQSQueueFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSQSQueueFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"queue_url":        "description.Attributes.QueueUrl",
}

func GetSQSQueue(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSQSQueue")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSQSQueuePaginator(buildFilter(d.KeyColumnQuals, getSQSQueueFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SQSQueue =============================

// ==========================  START: S3Bucket =============================

type S3Bucket struct {
	Description   aws.S3BucketDescription `json:"description"`
	Metadata      aws.Metadata            `json:"metadata"`
	ResourceJobID int                     `json:"resource_job_id"`
	SourceJobID   int                     `json:"source_job_id"`
	ResourceType  string                  `json:"resource_type"`
	SourceType    string                  `json:"source_type"`
	ID            string                  `json:"id"`
	ARN           string                  `json:"arn"`
	SourceID      string                  `json:"source_id"`
}

type S3BucketHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  S3Bucket      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type S3BucketHits struct {
	Total SearchTotal   `json:"total"`
	Hits  []S3BucketHit `json:"hits"`
}

type S3BucketSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  S3BucketHits `json:"hits"`
}

type S3BucketPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewS3BucketPaginator(filters []BoolFilter, limit *int64) (S3BucketPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_s3_bucket", filters, limit)
	if err != nil {
		return S3BucketPaginator{}, err
	}

	p := S3BucketPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p S3BucketPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p S3BucketPaginator) NextPage(ctx context.Context) ([]S3Bucket, error) {
	var response S3BucketSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []S3Bucket
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listS3BucketFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListS3Bucket(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListS3Bucket")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewS3BucketPaginator(buildFilter(d.KeyColumnQuals, listS3BucketFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getS3BucketFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Bucket.Name",
}

func GetS3Bucket(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetS3Bucket")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewS3BucketPaginator(buildFilter(d.KeyColumnQuals, getS3BucketFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: S3Bucket =============================

// ==========================  START: S3AccountSetting =============================

type S3AccountSetting struct {
	Description   aws.S3AccountSettingDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type S3AccountSettingHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  S3AccountSetting `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type S3AccountSettingHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []S3AccountSettingHit `json:"hits"`
}

type S3AccountSettingSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  S3AccountSettingHits `json:"hits"`
}

type S3AccountSettingPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewS3AccountSettingPaginator(filters []BoolFilter, limit *int64) (S3AccountSettingPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_s3_accountsettingdescription", filters, limit)
	if err != nil {
		return S3AccountSettingPaginator{}, err
	}

	p := S3AccountSettingPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p S3AccountSettingPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p S3AccountSettingPaginator) NextPage(ctx context.Context) ([]S3AccountSetting, error) {
	var response S3AccountSettingSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []S3AccountSetting
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listS3AccountSettingFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListS3AccountSetting(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListS3AccountSetting")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewS3AccountSettingPaginator(buildFilter(d.KeyColumnQuals, listS3AccountSettingFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getS3AccountSettingFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetS3AccountSetting(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetS3AccountSetting")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewS3AccountSettingPaginator(buildFilter(d.KeyColumnQuals, getS3AccountSettingFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: S3AccountSetting =============================

// ==========================  START: SageMakerEndpointConfiguration =============================

type SageMakerEndpointConfiguration struct {
	Description   aws.SageMakerEndpointConfigurationDescription `json:"description"`
	Metadata      aws.Metadata                                  `json:"metadata"`
	ResourceJobID int                                           `json:"resource_job_id"`
	SourceJobID   int                                           `json:"source_job_id"`
	ResourceType  string                                        `json:"resource_type"`
	SourceType    string                                        `json:"source_type"`
	ID            string                                        `json:"id"`
	ARN           string                                        `json:"arn"`
	SourceID      string                                        `json:"source_id"`
}

type SageMakerEndpointConfigurationHit struct {
	ID      string                         `json:"_id"`
	Score   float64                        `json:"_score"`
	Index   string                         `json:"_index"`
	Type    string                         `json:"_type"`
	Version int64                          `json:"_version,omitempty"`
	Source  SageMakerEndpointConfiguration `json:"_source"`
	Sort    []interface{}                  `json:"sort"`
}

type SageMakerEndpointConfigurationHits struct {
	Total SearchTotal                         `json:"total"`
	Hits  []SageMakerEndpointConfigurationHit `json:"hits"`
}

type SageMakerEndpointConfigurationSearchResponse struct {
	PitID string                             `json:"pit_id"`
	Hits  SageMakerEndpointConfigurationHits `json:"hits"`
}

type SageMakerEndpointConfigurationPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSageMakerEndpointConfigurationPaginator(filters []BoolFilter, limit *int64) (SageMakerEndpointConfigurationPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_sagemaker_endpointconfiguration", filters, limit)
	if err != nil {
		return SageMakerEndpointConfigurationPaginator{}, err
	}

	p := SageMakerEndpointConfigurationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SageMakerEndpointConfigurationPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SageMakerEndpointConfigurationPaginator) NextPage(ctx context.Context) ([]SageMakerEndpointConfiguration, error) {
	var response SageMakerEndpointConfigurationSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SageMakerEndpointConfiguration
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSageMakerEndpointConfigurationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSageMakerEndpointConfiguration(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSageMakerEndpointConfiguration")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSageMakerEndpointConfigurationPaginator(buildFilter(d.KeyColumnQuals, listSageMakerEndpointConfigurationFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSageMakerEndpointConfigurationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.EndpointConfig.EndpointConfigName",
}

func GetSageMakerEndpointConfiguration(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSageMakerEndpointConfiguration")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSageMakerEndpointConfigurationPaginator(buildFilter(d.KeyColumnQuals, getSageMakerEndpointConfigurationFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SageMakerEndpointConfiguration =============================

// ==========================  START: SageMakerNotebookInstance =============================

type SageMakerNotebookInstance struct {
	Description   aws.SageMakerNotebookInstanceDescription `json:"description"`
	Metadata      aws.Metadata                             `json:"metadata"`
	ResourceJobID int                                      `json:"resource_job_id"`
	SourceJobID   int                                      `json:"source_job_id"`
	ResourceType  string                                   `json:"resource_type"`
	SourceType    string                                   `json:"source_type"`
	ID            string                                   `json:"id"`
	ARN           string                                   `json:"arn"`
	SourceID      string                                   `json:"source_id"`
}

type SageMakerNotebookInstanceHit struct {
	ID      string                    `json:"_id"`
	Score   float64                   `json:"_score"`
	Index   string                    `json:"_index"`
	Type    string                    `json:"_type"`
	Version int64                     `json:"_version,omitempty"`
	Source  SageMakerNotebookInstance `json:"_source"`
	Sort    []interface{}             `json:"sort"`
}

type SageMakerNotebookInstanceHits struct {
	Total SearchTotal                    `json:"total"`
	Hits  []SageMakerNotebookInstanceHit `json:"hits"`
}

type SageMakerNotebookInstanceSearchResponse struct {
	PitID string                        `json:"pit_id"`
	Hits  SageMakerNotebookInstanceHits `json:"hits"`
}

type SageMakerNotebookInstancePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSageMakerNotebookInstancePaginator(filters []BoolFilter, limit *int64) (SageMakerNotebookInstancePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_sagemaker_notebookinstance", filters, limit)
	if err != nil {
		return SageMakerNotebookInstancePaginator{}, err
	}

	p := SageMakerNotebookInstancePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SageMakerNotebookInstancePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SageMakerNotebookInstancePaginator) NextPage(ctx context.Context) ([]SageMakerNotebookInstance, error) {
	var response SageMakerNotebookInstanceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SageMakerNotebookInstance
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSageMakerNotebookInstanceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSageMakerNotebookInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSageMakerNotebookInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSageMakerNotebookInstancePaginator(buildFilter(d.KeyColumnQuals, listSageMakerNotebookInstanceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSageMakerNotebookInstanceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.NotebookInstance.NotebookInstanceName",
}

func GetSageMakerNotebookInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSageMakerNotebookInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSageMakerNotebookInstancePaginator(buildFilter(d.KeyColumnQuals, getSageMakerNotebookInstanceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SageMakerNotebookInstance =============================

// ==========================  START: SecretsManagerSecret =============================

type SecretsManagerSecret struct {
	Description   aws.SecretsManagerSecretDescription `json:"description"`
	Metadata      aws.Metadata                        `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type SecretsManagerSecretHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  SecretsManagerSecret `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type SecretsManagerSecretHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []SecretsManagerSecretHit `json:"hits"`
}

type SecretsManagerSecretSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  SecretsManagerSecretHits `json:"hits"`
}

type SecretsManagerSecretPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSecretsManagerSecretPaginator(filters []BoolFilter, limit *int64) (SecretsManagerSecretPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_secretsmanager_secret", filters, limit)
	if err != nil {
		return SecretsManagerSecretPaginator{}, err
	}

	p := SecretsManagerSecretPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SecretsManagerSecretPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SecretsManagerSecretPaginator) NextPage(ctx context.Context) ([]SecretsManagerSecret, error) {
	var response SecretsManagerSecretSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SecretsManagerSecret
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSecretsManagerSecretFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSecretsManagerSecret(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSecretsManagerSecret")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSecretsManagerSecretPaginator(buildFilter(d.KeyColumnQuals, listSecretsManagerSecretFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSecretsManagerSecretFilters = map[string]string{
	"arn":              "description.Secret.ARN",
	"keibi_account_id": "metadata.SourceID",
}

func GetSecretsManagerSecret(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSecretsManagerSecret")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSecretsManagerSecretPaginator(buildFilter(d.KeyColumnQuals, getSecretsManagerSecretFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SecretsManagerSecret =============================

// ==========================  START: SecurityHubHub =============================

type SecurityHubHub struct {
	Description   aws.SecurityHubHubDescription `json:"description"`
	Metadata      aws.Metadata                  `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

type SecurityHubHubHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  SecurityHubHub `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type SecurityHubHubHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []SecurityHubHubHit `json:"hits"`
}

type SecurityHubHubSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  SecurityHubHubHits `json:"hits"`
}

type SecurityHubHubPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSecurityHubHubPaginator(filters []BoolFilter, limit *int64) (SecurityHubHubPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_securityhub_hub", filters, limit)
	if err != nil {
		return SecurityHubHubPaginator{}, err
	}

	p := SecurityHubHubPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SecurityHubHubPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SecurityHubHubPaginator) NextPage(ctx context.Context) ([]SecurityHubHub, error) {
	var response SecurityHubHubSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SecurityHubHub
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSecurityHubHubFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSecurityHubHub(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSecurityHubHub")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSecurityHubHubPaginator(buildFilter(d.KeyColumnQuals, listSecurityHubHubFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSecurityHubHubFilters = map[string]string{
	"hub_arn":          "description.Hub.HubArn",
	"keibi_account_id": "metadata.SourceID",
}

func GetSecurityHubHub(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSecurityHubHub")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSecurityHubHubPaginator(buildFilter(d.KeyColumnQuals, getSecurityHubHubFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SecurityHubHub =============================

// ==========================  START: SSMManagedInstance =============================

type SSMManagedInstance struct {
	Description   aws.SSMManagedInstanceDescription `json:"description"`
	Metadata      aws.Metadata                      `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

type SSMManagedInstanceHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  SSMManagedInstance `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type SSMManagedInstanceHits struct {
	Total SearchTotal             `json:"total"`
	Hits  []SSMManagedInstanceHit `json:"hits"`
}

type SSMManagedInstanceSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  SSMManagedInstanceHits `json:"hits"`
}

type SSMManagedInstancePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSSMManagedInstancePaginator(filters []BoolFilter, limit *int64) (SSMManagedInstancePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ssm_managedinstance", filters, limit)
	if err != nil {
		return SSMManagedInstancePaginator{}, err
	}

	p := SSMManagedInstancePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SSMManagedInstancePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SSMManagedInstancePaginator) NextPage(ctx context.Context) ([]SSMManagedInstance, error) {
	var response SSMManagedInstanceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SSMManagedInstance
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSSMManagedInstanceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSSMManagedInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSSMManagedInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSSMManagedInstancePaginator(buildFilter(d.KeyColumnQuals, listSSMManagedInstanceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSSMManagedInstanceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetSSMManagedInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSSMManagedInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSSMManagedInstancePaginator(buildFilter(d.KeyColumnQuals, getSSMManagedInstanceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SSMManagedInstance =============================

// ==========================  START: SSMManagedInstanceCompliance =============================

type SSMManagedInstanceCompliance struct {
	Description   aws.SSMManagedInstanceComplianceDescription `json:"description"`
	Metadata      aws.Metadata                                `json:"metadata"`
	ResourceJobID int                                         `json:"resource_job_id"`
	SourceJobID   int                                         `json:"source_job_id"`
	ResourceType  string                                      `json:"resource_type"`
	SourceType    string                                      `json:"source_type"`
	ID            string                                      `json:"id"`
	ARN           string                                      `json:"arn"`
	SourceID      string                                      `json:"source_id"`
}

type SSMManagedInstanceComplianceHit struct {
	ID      string                       `json:"_id"`
	Score   float64                      `json:"_score"`
	Index   string                       `json:"_index"`
	Type    string                       `json:"_type"`
	Version int64                        `json:"_version,omitempty"`
	Source  SSMManagedInstanceCompliance `json:"_source"`
	Sort    []interface{}                `json:"sort"`
}

type SSMManagedInstanceComplianceHits struct {
	Total SearchTotal                       `json:"total"`
	Hits  []SSMManagedInstanceComplianceHit `json:"hits"`
}

type SSMManagedInstanceComplianceSearchResponse struct {
	PitID string                           `json:"pit_id"`
	Hits  SSMManagedInstanceComplianceHits `json:"hits"`
}

type SSMManagedInstanceCompliancePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSSMManagedInstanceCompliancePaginator(filters []BoolFilter, limit *int64) (SSMManagedInstanceCompliancePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ssm_managedinstancecompliance", filters, limit)
	if err != nil {
		return SSMManagedInstanceCompliancePaginator{}, err
	}

	p := SSMManagedInstanceCompliancePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SSMManagedInstanceCompliancePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SSMManagedInstanceCompliancePaginator) NextPage(ctx context.Context) ([]SSMManagedInstanceCompliance, error) {
	var response SSMManagedInstanceComplianceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SSMManagedInstanceCompliance
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSSMManagedInstanceComplianceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"resource_id":      "description.ComplianceItem.ResourceId",
}

func ListSSMManagedInstanceCompliance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSSMManagedInstanceCompliance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSSMManagedInstanceCompliancePaginator(buildFilter(d.KeyColumnQuals, listSSMManagedInstanceComplianceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSSMManagedInstanceComplianceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetSSMManagedInstanceCompliance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSSMManagedInstanceCompliance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSSMManagedInstanceCompliancePaginator(buildFilter(d.KeyColumnQuals, getSSMManagedInstanceComplianceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SSMManagedInstanceCompliance =============================

// ==========================  START: ECSTaskDefinition =============================

type ECSTaskDefinition struct {
	Description   aws.ECSTaskDefinitionDescription `json:"description"`
	Metadata      aws.Metadata                     `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

type ECSTaskDefinitionHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  ECSTaskDefinition `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type ECSTaskDefinitionHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []ECSTaskDefinitionHit `json:"hits"`
}

type ECSTaskDefinitionSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  ECSTaskDefinitionHits `json:"hits"`
}

type ECSTaskDefinitionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewECSTaskDefinitionPaginator(filters []BoolFilter, limit *int64) (ECSTaskDefinitionPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ecs_taskdefinition", filters, limit)
	if err != nil {
		return ECSTaskDefinitionPaginator{}, err
	}

	p := ECSTaskDefinitionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ECSTaskDefinitionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ECSTaskDefinitionPaginator) NextPage(ctx context.Context) ([]ECSTaskDefinition, error) {
	var response ECSTaskDefinitionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ECSTaskDefinition
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listECSTaskDefinitionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListECSTaskDefinition(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListECSTaskDefinition")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewECSTaskDefinitionPaginator(buildFilter(d.KeyColumnQuals, listECSTaskDefinitionFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getECSTaskDefinitionFilters = map[string]string{
	"keibi_account_id":    "metadata.SourceID",
	"task_definition_arn": "description.TaskDefinition.TaskDefinitionArn",
}

func GetECSTaskDefinition(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetECSTaskDefinition")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewECSTaskDefinitionPaginator(buildFilter(d.KeyColumnQuals, getECSTaskDefinitionFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ECSTaskDefinition =============================

// ==========================  START: ECSCluster =============================

type ECSCluster struct {
	Description   aws.ECSClusterDescription `json:"description"`
	Metadata      aws.Metadata              `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	ARN           string                    `json:"arn"`
	SourceID      string                    `json:"source_id"`
}

type ECSClusterHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  ECSCluster    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type ECSClusterHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []ECSClusterHit `json:"hits"`
}

type ECSClusterSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  ECSClusterHits `json:"hits"`
}

type ECSClusterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewECSClusterPaginator(filters []BoolFilter, limit *int64) (ECSClusterPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ecs_cluster", filters, limit)
	if err != nil {
		return ECSClusterPaginator{}, err
	}

	p := ECSClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ECSClusterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ECSClusterPaginator) NextPage(ctx context.Context) ([]ECSCluster, error) {
	var response ECSClusterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ECSCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listECSClusterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListECSCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListECSCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewECSClusterPaginator(buildFilter(d.KeyColumnQuals, listECSClusterFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getECSClusterFilters = map[string]string{
	"cluster_arn":      "description.Cluster.ClusterArn",
	"keibi_account_id": "metadata.SourceID",
}

func GetECSCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetECSCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewECSClusterPaginator(buildFilter(d.KeyColumnQuals, getECSClusterFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ECSCluster =============================

// ==========================  START: ECSService =============================

type ECSService struct {
	Description   aws.ECSServiceDescription `json:"description"`
	Metadata      aws.Metadata              `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	ARN           string                    `json:"arn"`
	SourceID      string                    `json:"source_id"`
}

type ECSServiceHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  ECSService    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type ECSServiceHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []ECSServiceHit `json:"hits"`
}

type ECSServiceSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  ECSServiceHits `json:"hits"`
}

type ECSServicePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewECSServicePaginator(filters []BoolFilter, limit *int64) (ECSServicePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ecs_service", filters, limit)
	if err != nil {
		return ECSServicePaginator{}, err
	}

	p := ECSServicePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ECSServicePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ECSServicePaginator) NextPage(ctx context.Context) ([]ECSService, error) {
	var response ECSServiceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ECSService
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listECSServiceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListECSService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListECSService")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewECSServicePaginator(buildFilter(d.KeyColumnQuals, listECSServiceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getECSServiceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetECSService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetECSService")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewECSServicePaginator(buildFilter(d.KeyColumnQuals, getECSServiceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ECSService =============================

// ==========================  START: ECSContainerInstance =============================

type ECSContainerInstance struct {
	Description   aws.ECSContainerInstanceDescription `json:"description"`
	Metadata      aws.Metadata                        `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type ECSContainerInstanceHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  ECSContainerInstance `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type ECSContainerInstanceHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []ECSContainerInstanceHit `json:"hits"`
}

type ECSContainerInstanceSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  ECSContainerInstanceHits `json:"hits"`
}

type ECSContainerInstancePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewECSContainerInstancePaginator(filters []BoolFilter, limit *int64) (ECSContainerInstancePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ecs_containerinstance", filters, limit)
	if err != nil {
		return ECSContainerInstancePaginator{}, err
	}

	p := ECSContainerInstancePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ECSContainerInstancePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ECSContainerInstancePaginator) NextPage(ctx context.Context) ([]ECSContainerInstance, error) {
	var response ECSContainerInstanceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ECSContainerInstance
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listECSContainerInstanceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListECSContainerInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListECSContainerInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewECSContainerInstancePaginator(buildFilter(d.KeyColumnQuals, listECSContainerInstanceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getECSContainerInstanceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetECSContainerInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetECSContainerInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewECSContainerInstancePaginator(buildFilter(d.KeyColumnQuals, getECSContainerInstanceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ECSContainerInstance =============================

// ==========================  START: ECSTaskSet =============================

type ECSTaskSet struct {
	Description   aws.ECSTaskSetDescription `json:"description"`
	Metadata      aws.Metadata              `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	ARN           string                    `json:"arn"`
	SourceID      string                    `json:"source_id"`
}

type ECSTaskSetHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  ECSTaskSet    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type ECSTaskSetHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []ECSTaskSetHit `json:"hits"`
}

type ECSTaskSetSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  ECSTaskSetHits `json:"hits"`
}

type ECSTaskSetPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewECSTaskSetPaginator(filters []BoolFilter, limit *int64) (ECSTaskSetPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ecs_taskset", filters, limit)
	if err != nil {
		return ECSTaskSetPaginator{}, err
	}

	p := ECSTaskSetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ECSTaskSetPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ECSTaskSetPaginator) NextPage(ctx context.Context) ([]ECSTaskSet, error) {
	var response ECSTaskSetSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ECSTaskSet
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listECSTaskSetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListECSTaskSet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListECSTaskSet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewECSTaskSetPaginator(buildFilter(d.KeyColumnQuals, listECSTaskSetFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getECSTaskSetFilters = map[string]string{
	"id":               "description.TaskSet.Id",
	"keibi_account_id": "metadata.SourceID",
}

func GetECSTaskSet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetECSTaskSet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewECSTaskSetPaginator(buildFilter(d.KeyColumnQuals, getECSTaskSetFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ECSTaskSet =============================

// ==========================  START: ECSTask =============================

type ECSTask struct {
	Description   aws.ECSTaskDescription `json:"description"`
	Metadata      aws.Metadata           `json:"metadata"`
	ResourceJobID int                    `json:"resource_job_id"`
	SourceJobID   int                    `json:"source_job_id"`
	ResourceType  string                 `json:"resource_type"`
	SourceType    string                 `json:"source_type"`
	ID            string                 `json:"id"`
	ARN           string                 `json:"arn"`
	SourceID      string                 `json:"source_id"`
}

type ECSTaskHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  ECSTask       `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type ECSTaskHits struct {
	Total SearchTotal  `json:"total"`
	Hits  []ECSTaskHit `json:"hits"`
}

type ECSTaskSearchResponse struct {
	PitID string      `json:"pit_id"`
	Hits  ECSTaskHits `json:"hits"`
}

type ECSTaskPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewECSTaskPaginator(filters []BoolFilter, limit *int64) (ECSTaskPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ecs_task", filters, limit)
	if err != nil {
		return ECSTaskPaginator{}, err
	}

	p := ECSTaskPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ECSTaskPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ECSTaskPaginator) NextPage(ctx context.Context) ([]ECSTask, error) {
	var response ECSTaskSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ECSTask
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listECSTaskFilters = map[string]string{
	"container_instance_arn": "description.Task.ContainerInstanceArn",
	"desired_status":         "description.Task.DesiredStatus",
	"keibi_account_id":       "metadata.SourceID",
	"launch_type":            "description.Task.LaunchType",
	"service_name":           "description.ServiceName",
}

func ListECSTask(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListECSTask")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewECSTaskPaginator(buildFilter(d.KeyColumnQuals, listECSTaskFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getECSTaskFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetECSTask(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetECSTask")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewECSTaskPaginator(buildFilter(d.KeyColumnQuals, getECSTaskFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ECSTask =============================

// ==========================  START: EFSFileSystem =============================

type EFSFileSystem struct {
	Description   aws.EFSFileSystemDescription `json:"description"`
	Metadata      aws.Metadata                 `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

type EFSFileSystemHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EFSFileSystem `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EFSFileSystemHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []EFSFileSystemHit `json:"hits"`
}

type EFSFileSystemSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  EFSFileSystemHits `json:"hits"`
}

type EFSFileSystemPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEFSFileSystemPaginator(filters []BoolFilter, limit *int64) (EFSFileSystemPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_efs_filesystem", filters, limit)
	if err != nil {
		return EFSFileSystemPaginator{}, err
	}

	p := EFSFileSystemPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EFSFileSystemPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EFSFileSystemPaginator) NextPage(ctx context.Context) ([]EFSFileSystem, error) {
	var response EFSFileSystemSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EFSFileSystem
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEFSFileSystemFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEFSFileSystem(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEFSFileSystem")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEFSFileSystemPaginator(buildFilter(d.KeyColumnQuals, listEFSFileSystemFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEFSFileSystemFilters = map[string]string{
	"aws_efs_file_system": "description.FileSystem.FileSystemId",
	"keibi_account_id":    "metadata.SourceID",
}

func GetEFSFileSystem(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEFSFileSystem")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEFSFileSystemPaginator(buildFilter(d.KeyColumnQuals, getEFSFileSystemFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EFSFileSystem =============================

// ==========================  START: EFSAccessPoint =============================

type EFSAccessPoint struct {
	Description   aws.EFSAccessPointDescription `json:"description"`
	Metadata      aws.Metadata                  `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

type EFSAccessPointHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  EFSAccessPoint `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type EFSAccessPointHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []EFSAccessPointHit `json:"hits"`
}

type EFSAccessPointSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  EFSAccessPointHits `json:"hits"`
}

type EFSAccessPointPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEFSAccessPointPaginator(filters []BoolFilter, limit *int64) (EFSAccessPointPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_efs_accesspoint", filters, limit)
	if err != nil {
		return EFSAccessPointPaginator{}, err
	}

	p := EFSAccessPointPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EFSAccessPointPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EFSAccessPointPaginator) NextPage(ctx context.Context) ([]EFSAccessPoint, error) {
	var response EFSAccessPointSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EFSAccessPoint
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEFSAccessPointFilters = map[string]string{
	"file_system_id":   "description.AccessPoint.FileSystemId",
	"keibi_account_id": "metadata.SourceID",
}

func ListEFSAccessPoint(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEFSAccessPoint")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEFSAccessPointPaginator(buildFilter(d.KeyColumnQuals, listEFSAccessPointFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEFSAccessPointFilters = map[string]string{
	"access_point_id":  "description.AccessPoint.AccessPointId",
	"keibi_account_id": "metadata.SourceID",
}

func GetEFSAccessPoint(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEFSAccessPoint")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEFSAccessPointPaginator(buildFilter(d.KeyColumnQuals, getEFSAccessPointFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EFSAccessPoint =============================

// ==========================  START: EFSMountTarget =============================

type EFSMountTarget struct {
	Description   aws.EFSMountTargetDescription `json:"description"`
	Metadata      aws.Metadata                  `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

type EFSMountTargetHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  EFSMountTarget `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type EFSMountTargetHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []EFSMountTargetHit `json:"hits"`
}

type EFSMountTargetSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  EFSMountTargetHits `json:"hits"`
}

type EFSMountTargetPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEFSMountTargetPaginator(filters []BoolFilter, limit *int64) (EFSMountTargetPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_efs_mounttarget", filters, limit)
	if err != nil {
		return EFSMountTargetPaginator{}, err
	}

	p := EFSMountTargetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EFSMountTargetPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EFSMountTargetPaginator) NextPage(ctx context.Context) ([]EFSMountTarget, error) {
	var response EFSMountTargetSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EFSMountTarget
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEFSMountTargetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEFSMountTarget(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEFSMountTarget")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEFSMountTargetPaginator(buildFilter(d.KeyColumnQuals, listEFSMountTargetFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEFSMountTargetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"mount_target_id":  "description.MountTarget.MountTargetId",
}

func GetEFSMountTarget(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEFSMountTarget")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEFSMountTargetPaginator(buildFilter(d.KeyColumnQuals, getEFSMountTargetFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EFSMountTarget =============================

// ==========================  START: EKSCluster =============================

type EKSCluster struct {
	Description   aws.EKSClusterDescription `json:"description"`
	Metadata      aws.Metadata              `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	ARN           string                    `json:"arn"`
	SourceID      string                    `json:"source_id"`
}

type EKSClusterHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EKSCluster    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EKSClusterHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []EKSClusterHit `json:"hits"`
}

type EKSClusterSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  EKSClusterHits `json:"hits"`
}

type EKSClusterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEKSClusterPaginator(filters []BoolFilter, limit *int64) (EKSClusterPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_eks_cluster", filters, limit)
	if err != nil {
		return EKSClusterPaginator{}, err
	}

	p := EKSClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EKSClusterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EKSClusterPaginator) NextPage(ctx context.Context) ([]EKSCluster, error) {
	var response EKSClusterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EKSCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEKSClusterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEKSCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEKSCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEKSClusterPaginator(buildFilter(d.KeyColumnQuals, listEKSClusterFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEKSClusterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Cluster.Name",
}

func GetEKSCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEKSCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEKSClusterPaginator(buildFilter(d.KeyColumnQuals, getEKSClusterFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EKSCluster =============================

// ==========================  START: EKSAddon =============================

type EKSAddon struct {
	Description   aws.EKSAddonDescription `json:"description"`
	Metadata      aws.Metadata            `json:"metadata"`
	ResourceJobID int                     `json:"resource_job_id"`
	SourceJobID   int                     `json:"source_job_id"`
	ResourceType  string                  `json:"resource_type"`
	SourceType    string                  `json:"source_type"`
	ID            string                  `json:"id"`
	ARN           string                  `json:"arn"`
	SourceID      string                  `json:"source_id"`
}

type EKSAddonHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EKSAddon      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EKSAddonHits struct {
	Total SearchTotal   `json:"total"`
	Hits  []EKSAddonHit `json:"hits"`
}

type EKSAddonSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  EKSAddonHits `json:"hits"`
}

type EKSAddonPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEKSAddonPaginator(filters []BoolFilter, limit *int64) (EKSAddonPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_eks_addon", filters, limit)
	if err != nil {
		return EKSAddonPaginator{}, err
	}

	p := EKSAddonPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EKSAddonPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EKSAddonPaginator) NextPage(ctx context.Context) ([]EKSAddon, error) {
	var response EKSAddonSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EKSAddon
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEKSAddonFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEKSAddon(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEKSAddon")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEKSAddonPaginator(buildFilter(d.KeyColumnQuals, listEKSAddonFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEKSAddonFilters = map[string]string{
	"addon_name":       "description.Addon.AddonName",
	"cluster_name":     "description.Addon.ClusterName",
	"keibi_account_id": "metadata.SourceID",
}

func GetEKSAddon(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEKSAddon")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEKSAddonPaginator(buildFilter(d.KeyColumnQuals, getEKSAddonFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EKSAddon =============================

// ==========================  START: EKSIdentityProviderConfig =============================

type EKSIdentityProviderConfig struct {
	Description   aws.EKSIdentityProviderConfigDescription `json:"description"`
	Metadata      aws.Metadata                             `json:"metadata"`
	ResourceJobID int                                      `json:"resource_job_id"`
	SourceJobID   int                                      `json:"source_job_id"`
	ResourceType  string                                   `json:"resource_type"`
	SourceType    string                                   `json:"source_type"`
	ID            string                                   `json:"id"`
	ARN           string                                   `json:"arn"`
	SourceID      string                                   `json:"source_id"`
}

type EKSIdentityProviderConfigHit struct {
	ID      string                    `json:"_id"`
	Score   float64                   `json:"_score"`
	Index   string                    `json:"_index"`
	Type    string                    `json:"_type"`
	Version int64                     `json:"_version,omitempty"`
	Source  EKSIdentityProviderConfig `json:"_source"`
	Sort    []interface{}             `json:"sort"`
}

type EKSIdentityProviderConfigHits struct {
	Total SearchTotal                    `json:"total"`
	Hits  []EKSIdentityProviderConfigHit `json:"hits"`
}

type EKSIdentityProviderConfigSearchResponse struct {
	PitID string                        `json:"pit_id"`
	Hits  EKSIdentityProviderConfigHits `json:"hits"`
}

type EKSIdentityProviderConfigPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEKSIdentityProviderConfigPaginator(filters []BoolFilter, limit *int64) (EKSIdentityProviderConfigPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_eks_identityproviderconfig", filters, limit)
	if err != nil {
		return EKSIdentityProviderConfigPaginator{}, err
	}

	p := EKSIdentityProviderConfigPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EKSIdentityProviderConfigPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EKSIdentityProviderConfigPaginator) NextPage(ctx context.Context) ([]EKSIdentityProviderConfig, error) {
	var response EKSIdentityProviderConfigSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EKSIdentityProviderConfig
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEKSIdentityProviderConfigFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEKSIdentityProviderConfig(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEKSIdentityProviderConfig")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEKSIdentityProviderConfigPaginator(buildFilter(d.KeyColumnQuals, listEKSIdentityProviderConfigFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEKSIdentityProviderConfigFilters = map[string]string{
	"cluster_name":     "description.IdentityProviderConfig.ClusterName",
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.ConfigName",
	"type":             "description.ConfigType",
}

func GetEKSIdentityProviderConfig(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEKSIdentityProviderConfig")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEKSIdentityProviderConfigPaginator(buildFilter(d.KeyColumnQuals, getEKSIdentityProviderConfigFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EKSIdentityProviderConfig =============================

// ==========================  START: EKSNodegroup =============================

type EKSNodegroup struct {
	Description   aws.EKSNodegroupDescription `json:"description"`
	Metadata      aws.Metadata                `json:"metadata"`
	ResourceJobID int                         `json:"resource_job_id"`
	SourceJobID   int                         `json:"source_job_id"`
	ResourceType  string                      `json:"resource_type"`
	SourceType    string                      `json:"source_type"`
	ID            string                      `json:"id"`
	ARN           string                      `json:"arn"`
	SourceID      string                      `json:"source_id"`
}

type EKSNodegroupHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EKSNodegroup  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EKSNodegroupHits struct {
	Total SearchTotal       `json:"total"`
	Hits  []EKSNodegroupHit `json:"hits"`
}

type EKSNodegroupSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  EKSNodegroupHits `json:"hits"`
}

type EKSNodegroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEKSNodegroupPaginator(filters []BoolFilter, limit *int64) (EKSNodegroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_eks_nodegroup", filters, limit)
	if err != nil {
		return EKSNodegroupPaginator{}, err
	}

	p := EKSNodegroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EKSNodegroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EKSNodegroupPaginator) NextPage(ctx context.Context) ([]EKSNodegroup, error) {
	var response EKSNodegroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EKSNodegroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEKSNodegroupFilters = map[string]string{
	"cluster_name":     "description.Nodegroup.ClusterName",
	"keibi_account_id": "metadata.SourceID",
}

func ListEKSNodegroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEKSNodegroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEKSNodegroupPaginator(buildFilter(d.KeyColumnQuals, listEKSNodegroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEKSNodegroupFilters = map[string]string{
	"cluster_name":     "description.Nodegroup.ClusterName",
	"keibi_account_id": "metadata.SourceID",
	"nodegroup_name":   "description.Nodegroup.NodegroupName",
}

func GetEKSNodegroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEKSNodegroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEKSNodegroupPaginator(buildFilter(d.KeyColumnQuals, getEKSNodegroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EKSNodegroup =============================

// ==========================  START: EKSAddonVersion =============================

type EKSAddonVersion struct {
	Description   aws.EKSAddonVersionDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type EKSAddonVersionHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  EKSAddonVersion `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type EKSAddonVersionHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []EKSAddonVersionHit `json:"hits"`
}

type EKSAddonVersionSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  EKSAddonVersionHits `json:"hits"`
}

type EKSAddonVersionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEKSAddonVersionPaginator(filters []BoolFilter, limit *int64) (EKSAddonVersionPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_eks_addonversion", filters, limit)
	if err != nil {
		return EKSAddonVersionPaginator{}, err
	}

	p := EKSAddonVersionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EKSAddonVersionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EKSAddonVersionPaginator) NextPage(ctx context.Context) ([]EKSAddonVersion, error) {
	var response EKSAddonVersionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EKSAddonVersion
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEKSAddonVersionFilters = map[string]string{
	"addon_name":       "description.AddonName",
	"keibi_account_id": "metadata.SourceID",
}

func ListEKSAddonVersion(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEKSAddonVersion")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEKSAddonVersionPaginator(buildFilter(d.KeyColumnQuals, listEKSAddonVersionFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEKSAddonVersionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetEKSAddonVersion(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEKSAddonVersion")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEKSAddonVersionPaginator(buildFilter(d.KeyColumnQuals, getEKSAddonVersionFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EKSAddonVersion =============================

// ==========================  START: EKSFargateProfile =============================

type EKSFargateProfile struct {
	Description   aws.EKSFargateProfileDescription `json:"description"`
	Metadata      aws.Metadata                     `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

type EKSFargateProfileHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  EKSFargateProfile `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type EKSFargateProfileHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []EKSFargateProfileHit `json:"hits"`
}

type EKSFargateProfileSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  EKSFargateProfileHits `json:"hits"`
}

type EKSFargateProfilePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEKSFargateProfilePaginator(filters []BoolFilter, limit *int64) (EKSFargateProfilePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_eks_fargateprofile", filters, limit)
	if err != nil {
		return EKSFargateProfilePaginator{}, err
	}

	p := EKSFargateProfilePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EKSFargateProfilePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EKSFargateProfilePaginator) NextPage(ctx context.Context) ([]EKSFargateProfile, error) {
	var response EKSFargateProfileSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EKSFargateProfile
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEKSFargateProfileFilters = map[string]string{
	"cluster_name":     "description.Fargate.ClusterName",
	"keibi_account_id": "metadata.SourceID",
}

func ListEKSFargateProfile(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEKSFargateProfile")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEKSFargateProfilePaginator(buildFilter(d.KeyColumnQuals, listEKSFargateProfileFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEKSFargateProfileFilters = map[string]string{
	"cluster_name":         "description.Fargate.ClusterName",
	"fargate_profile_name": "description.Fargate.FargateProfileName",
	"keibi_account_id":     "metadata.SourceID",
}

func GetEKSFargateProfile(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEKSFargateProfile")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEKSFargateProfilePaginator(buildFilter(d.KeyColumnQuals, getEKSFargateProfileFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EKSFargateProfile =============================

// ==========================  START: WAFv2WebACL =============================

type WAFv2WebACL struct {
	Description   aws.WAFv2WebACLDescription `json:"description"`
	Metadata      aws.Metadata               `json:"metadata"`
	ResourceJobID int                        `json:"resource_job_id"`
	SourceJobID   int                        `json:"source_job_id"`
	ResourceType  string                     `json:"resource_type"`
	SourceType    string                     `json:"source_type"`
	ID            string                     `json:"id"`
	ARN           string                     `json:"arn"`
	SourceID      string                     `json:"source_id"`
}

type WAFv2WebACLHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  WAFv2WebACL   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type WAFv2WebACLHits struct {
	Total SearchTotal      `json:"total"`
	Hits  []WAFv2WebACLHit `json:"hits"`
}

type WAFv2WebACLSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  WAFv2WebACLHits `json:"hits"`
}

type WAFv2WebACLPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewWAFv2WebACLPaginator(filters []BoolFilter, limit *int64) (WAFv2WebACLPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_wafv2_webacl", filters, limit)
	if err != nil {
		return WAFv2WebACLPaginator{}, err
	}

	p := WAFv2WebACLPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p WAFv2WebACLPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p WAFv2WebACLPaginator) NextPage(ctx context.Context) ([]WAFv2WebACL, error) {
	var response WAFv2WebACLSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []WAFv2WebACL
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listWAFv2WebACLFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListWAFv2WebACL(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListWAFv2WebACL")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewWAFv2WebACLPaginator(buildFilter(d.KeyColumnQuals, listWAFv2WebACLFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getWAFv2WebACLFilters = map[string]string{
	"id":               "description.WebACL.Id",
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.WebACL.Name",
	"scope":            "description.Scope",
}

func GetWAFv2WebACL(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetWAFv2WebACL")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewWAFv2WebACLPaginator(buildFilter(d.KeyColumnQuals, getWAFv2WebACLFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: WAFv2WebACL =============================

// ==========================  START: KMSKey =============================

type KMSKey struct {
	Description   aws.KMSKeyDescription `json:"description"`
	Metadata      aws.Metadata          `json:"metadata"`
	ResourceJobID int                   `json:"resource_job_id"`
	SourceJobID   int                   `json:"source_job_id"`
	ResourceType  string                `json:"resource_type"`
	SourceType    string                `json:"source_type"`
	ID            string                `json:"id"`
	ARN           string                `json:"arn"`
	SourceID      string                `json:"source_id"`
}

type KMSKeyHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  KMSKey        `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type KMSKeyHits struct {
	Total SearchTotal `json:"total"`
	Hits  []KMSKeyHit `json:"hits"`
}

type KMSKeySearchResponse struct {
	PitID string     `json:"pit_id"`
	Hits  KMSKeyHits `json:"hits"`
}

type KMSKeyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewKMSKeyPaginator(filters []BoolFilter, limit *int64) (KMSKeyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_kms_key", filters, limit)
	if err != nil {
		return KMSKeyPaginator{}, err
	}

	p := KMSKeyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p KMSKeyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p KMSKeyPaginator) NextPage(ctx context.Context) ([]KMSKey, error) {
	var response KMSKeySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []KMSKey
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listKMSKeyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListKMSKey(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListKMSKey")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewKMSKeyPaginator(buildFilter(d.KeyColumnQuals, listKMSKeyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getKMSKeyFilters = map[string]string{
	"id":               "description.Metadata.KeyId",
	"keibi_account_id": "metadata.SourceID",
}

func GetKMSKey(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetKMSKey")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewKMSKeyPaginator(buildFilter(d.KeyColumnQuals, getKMSKeyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: KMSKey =============================

// ==========================  START: LambdaFunction =============================

type LambdaFunction struct {
	Description   aws.LambdaFunctionDescription `json:"description"`
	Metadata      aws.Metadata                  `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

type LambdaFunctionHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  LambdaFunction `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type LambdaFunctionHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []LambdaFunctionHit `json:"hits"`
}

type LambdaFunctionSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  LambdaFunctionHits `json:"hits"`
}

type LambdaFunctionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewLambdaFunctionPaginator(filters []BoolFilter, limit *int64) (LambdaFunctionPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_lambda_function", filters, limit)
	if err != nil {
		return LambdaFunctionPaginator{}, err
	}

	p := LambdaFunctionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LambdaFunctionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p LambdaFunctionPaginator) NextPage(ctx context.Context) ([]LambdaFunction, error) {
	var response LambdaFunctionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []LambdaFunction
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listLambdaFunctionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListLambdaFunction(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLambdaFunction")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewLambdaFunctionPaginator(buildFilter(d.KeyColumnQuals, listLambdaFunctionFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLambdaFunctionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Function.Configuration.FunctionName",
}

func GetLambdaFunction(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLambdaFunction")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewLambdaFunctionPaginator(buildFilter(d.KeyColumnQuals, getLambdaFunctionFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: LambdaFunction =============================

// ==========================  START: LambdaFunctionVersion =============================

type LambdaFunctionVersion struct {
	Description   aws.LambdaFunctionVersionDescription `json:"description"`
	Metadata      aws.Metadata                         `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

type LambdaFunctionVersionHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  LambdaFunctionVersion `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type LambdaFunctionVersionHits struct {
	Total SearchTotal                `json:"total"`
	Hits  []LambdaFunctionVersionHit `json:"hits"`
}

type LambdaFunctionVersionSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  LambdaFunctionVersionHits `json:"hits"`
}

type LambdaFunctionVersionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewLambdaFunctionVersionPaginator(filters []BoolFilter, limit *int64) (LambdaFunctionVersionPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_lambda_function_version", filters, limit)
	if err != nil {
		return LambdaFunctionVersionPaginator{}, err
	}

	p := LambdaFunctionVersionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LambdaFunctionVersionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p LambdaFunctionVersionPaginator) NextPage(ctx context.Context) ([]LambdaFunctionVersion, error) {
	var response LambdaFunctionVersionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []LambdaFunctionVersion
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listLambdaFunctionVersionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListLambdaFunctionVersion(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLambdaFunctionVersion")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewLambdaFunctionVersionPaginator(buildFilter(d.KeyColumnQuals, listLambdaFunctionVersionFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLambdaFunctionVersionFilters = map[string]string{
	"id":               "description.ID",
	"keibi_account_id": "metadata.SourceID",
}

func GetLambdaFunctionVersion(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLambdaFunctionVersion")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewLambdaFunctionVersionPaginator(buildFilter(d.KeyColumnQuals, getLambdaFunctionVersionFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: LambdaFunctionVersion =============================

// ==========================  START: S3AccessPoint =============================

type S3AccessPoint struct {
	Description   aws.S3AccessPointDescription `json:"description"`
	Metadata      aws.Metadata                 `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

type S3AccessPointHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  S3AccessPoint `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type S3AccessPointHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []S3AccessPointHit `json:"hits"`
}

type S3AccessPointSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  S3AccessPointHits `json:"hits"`
}

type S3AccessPointPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewS3AccessPointPaginator(filters []BoolFilter, limit *int64) (S3AccessPointPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_s3_accesspoint", filters, limit)
	if err != nil {
		return S3AccessPointPaginator{}, err
	}

	p := S3AccessPointPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p S3AccessPointPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p S3AccessPointPaginator) NextPage(ctx context.Context) ([]S3AccessPoint, error) {
	var response S3AccessPointSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []S3AccessPoint
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listS3AccessPointFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListS3AccessPoint(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListS3AccessPoint")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewS3AccessPointPaginator(buildFilter(d.KeyColumnQuals, listS3AccessPointFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getS3AccessPointFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.AccessPoint.Name",
	"region":           "metadata.region",
}

func GetS3AccessPoint(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetS3AccessPoint")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewS3AccessPointPaginator(buildFilter(d.KeyColumnQuals, getS3AccessPointFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: S3AccessPoint =============================

// ==========================  START: CostExplorerByAccountMonthly =============================

type CostExplorerByAccountMonthly struct {
	Description   aws.CostExplorerByAccountMonthlyDescription `json:"description"`
	Metadata      aws.Metadata                                `json:"metadata"`
	ResourceJobID int                                         `json:"resource_job_id"`
	SourceJobID   int                                         `json:"source_job_id"`
	ResourceType  string                                      `json:"resource_type"`
	SourceType    string                                      `json:"source_type"`
	ID            string                                      `json:"id"`
	ARN           string                                      `json:"arn"`
	SourceID      string                                      `json:"source_id"`
}

type CostExplorerByAccountMonthlyHit struct {
	ID      string                       `json:"_id"`
	Score   float64                      `json:"_score"`
	Index   string                       `json:"_index"`
	Type    string                       `json:"_type"`
	Version int64                        `json:"_version,omitempty"`
	Source  CostExplorerByAccountMonthly `json:"_source"`
	Sort    []interface{}                `json:"sort"`
}

type CostExplorerByAccountMonthlyHits struct {
	Total SearchTotal                       `json:"total"`
	Hits  []CostExplorerByAccountMonthlyHit `json:"hits"`
}

type CostExplorerByAccountMonthlySearchResponse struct {
	PitID string                           `json:"pit_id"`
	Hits  CostExplorerByAccountMonthlyHits `json:"hits"`
}

type CostExplorerByAccountMonthlyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCostExplorerByAccountMonthlyPaginator(filters []BoolFilter, limit *int64) (CostExplorerByAccountMonthlyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_costexplorer_byaccountmonthly", filters, limit)
	if err != nil {
		return CostExplorerByAccountMonthlyPaginator{}, err
	}

	p := CostExplorerByAccountMonthlyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CostExplorerByAccountMonthlyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CostExplorerByAccountMonthlyPaginator) NextPage(ctx context.Context) ([]CostExplorerByAccountMonthly, error) {
	var response CostExplorerByAccountMonthlySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CostExplorerByAccountMonthly
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCostExplorerByAccountMonthlyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCostExplorerByAccountMonthly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCostExplorerByAccountMonthly")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCostExplorerByAccountMonthlyPaginator(buildFilter(d.KeyColumnQuals, listCostExplorerByAccountMonthlyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCostExplorerByAccountMonthlyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetCostExplorerByAccountMonthly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCostExplorerByAccountMonthly")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCostExplorerByAccountMonthlyPaginator(buildFilter(d.KeyColumnQuals, getCostExplorerByAccountMonthlyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CostExplorerByAccountMonthly =============================

// ==========================  START: CostExplorerByServiceMonthly =============================

type CostExplorerByServiceMonthly struct {
	Description   aws.CostExplorerByServiceMonthlyDescription `json:"description"`
	Metadata      aws.Metadata                                `json:"metadata"`
	ResourceJobID int                                         `json:"resource_job_id"`
	SourceJobID   int                                         `json:"source_job_id"`
	ResourceType  string                                      `json:"resource_type"`
	SourceType    string                                      `json:"source_type"`
	ID            string                                      `json:"id"`
	ARN           string                                      `json:"arn"`
	SourceID      string                                      `json:"source_id"`
}

type CostExplorerByServiceMonthlyHit struct {
	ID      string                       `json:"_id"`
	Score   float64                      `json:"_score"`
	Index   string                       `json:"_index"`
	Type    string                       `json:"_type"`
	Version int64                        `json:"_version,omitempty"`
	Source  CostExplorerByServiceMonthly `json:"_source"`
	Sort    []interface{}                `json:"sort"`
}

type CostExplorerByServiceMonthlyHits struct {
	Total SearchTotal                       `json:"total"`
	Hits  []CostExplorerByServiceMonthlyHit `json:"hits"`
}

type CostExplorerByServiceMonthlySearchResponse struct {
	PitID string                           `json:"pit_id"`
	Hits  CostExplorerByServiceMonthlyHits `json:"hits"`
}

type CostExplorerByServiceMonthlyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCostExplorerByServiceMonthlyPaginator(filters []BoolFilter, limit *int64) (CostExplorerByServiceMonthlyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_costexplorer_byservicemonthly", filters, limit)
	if err != nil {
		return CostExplorerByServiceMonthlyPaginator{}, err
	}

	p := CostExplorerByServiceMonthlyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CostExplorerByServiceMonthlyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CostExplorerByServiceMonthlyPaginator) NextPage(ctx context.Context) ([]CostExplorerByServiceMonthly, error) {
	var response CostExplorerByServiceMonthlySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CostExplorerByServiceMonthly
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCostExplorerByServiceMonthlyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCostExplorerByServiceMonthly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCostExplorerByServiceMonthly")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCostExplorerByServiceMonthlyPaginator(buildFilter(d.KeyColumnQuals, listCostExplorerByServiceMonthlyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCostExplorerByServiceMonthlyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetCostExplorerByServiceMonthly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCostExplorerByServiceMonthly")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCostExplorerByServiceMonthlyPaginator(buildFilter(d.KeyColumnQuals, getCostExplorerByServiceMonthlyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CostExplorerByServiceMonthly =============================

// ==========================  START: CostExplorerByRecordTypeMonthly =============================

type CostExplorerByRecordTypeMonthly struct {
	Description   aws.CostExplorerByRecordTypeMonthlyDescription `json:"description"`
	Metadata      aws.Metadata                                   `json:"metadata"`
	ResourceJobID int                                            `json:"resource_job_id"`
	SourceJobID   int                                            `json:"source_job_id"`
	ResourceType  string                                         `json:"resource_type"`
	SourceType    string                                         `json:"source_type"`
	ID            string                                         `json:"id"`
	ARN           string                                         `json:"arn"`
	SourceID      string                                         `json:"source_id"`
}

type CostExplorerByRecordTypeMonthlyHit struct {
	ID      string                          `json:"_id"`
	Score   float64                         `json:"_score"`
	Index   string                          `json:"_index"`
	Type    string                          `json:"_type"`
	Version int64                           `json:"_version,omitempty"`
	Source  CostExplorerByRecordTypeMonthly `json:"_source"`
	Sort    []interface{}                   `json:"sort"`
}

type CostExplorerByRecordTypeMonthlyHits struct {
	Total SearchTotal                          `json:"total"`
	Hits  []CostExplorerByRecordTypeMonthlyHit `json:"hits"`
}

type CostExplorerByRecordTypeMonthlySearchResponse struct {
	PitID string                              `json:"pit_id"`
	Hits  CostExplorerByRecordTypeMonthlyHits `json:"hits"`
}

type CostExplorerByRecordTypeMonthlyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCostExplorerByRecordTypeMonthlyPaginator(filters []BoolFilter, limit *int64) (CostExplorerByRecordTypeMonthlyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_costexplorer_byrecordtypemonthly", filters, limit)
	if err != nil {
		return CostExplorerByRecordTypeMonthlyPaginator{}, err
	}

	p := CostExplorerByRecordTypeMonthlyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CostExplorerByRecordTypeMonthlyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CostExplorerByRecordTypeMonthlyPaginator) NextPage(ctx context.Context) ([]CostExplorerByRecordTypeMonthly, error) {
	var response CostExplorerByRecordTypeMonthlySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CostExplorerByRecordTypeMonthly
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCostExplorerByRecordTypeMonthlyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCostExplorerByRecordTypeMonthly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCostExplorerByRecordTypeMonthly")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCostExplorerByRecordTypeMonthlyPaginator(buildFilter(d.KeyColumnQuals, listCostExplorerByRecordTypeMonthlyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCostExplorerByRecordTypeMonthlyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetCostExplorerByRecordTypeMonthly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCostExplorerByRecordTypeMonthly")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCostExplorerByRecordTypeMonthlyPaginator(buildFilter(d.KeyColumnQuals, getCostExplorerByRecordTypeMonthlyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CostExplorerByRecordTypeMonthly =============================

// ==========================  START: CostExplorerByServiceUsageTypeMonthly =============================

type CostExplorerByServiceUsageTypeMonthly struct {
	Description   aws.CostExplorerByServiceUsageTypeMonthlyDescription `json:"description"`
	Metadata      aws.Metadata                                         `json:"metadata"`
	ResourceJobID int                                                  `json:"resource_job_id"`
	SourceJobID   int                                                  `json:"source_job_id"`
	ResourceType  string                                               `json:"resource_type"`
	SourceType    string                                               `json:"source_type"`
	ID            string                                               `json:"id"`
	ARN           string                                               `json:"arn"`
	SourceID      string                                               `json:"source_id"`
}

type CostExplorerByServiceUsageTypeMonthlyHit struct {
	ID      string                                `json:"_id"`
	Score   float64                               `json:"_score"`
	Index   string                                `json:"_index"`
	Type    string                                `json:"_type"`
	Version int64                                 `json:"_version,omitempty"`
	Source  CostExplorerByServiceUsageTypeMonthly `json:"_source"`
	Sort    []interface{}                         `json:"sort"`
}

type CostExplorerByServiceUsageTypeMonthlyHits struct {
	Total SearchTotal                                `json:"total"`
	Hits  []CostExplorerByServiceUsageTypeMonthlyHit `json:"hits"`
}

type CostExplorerByServiceUsageTypeMonthlySearchResponse struct {
	PitID string                                    `json:"pit_id"`
	Hits  CostExplorerByServiceUsageTypeMonthlyHits `json:"hits"`
}

type CostExplorerByServiceUsageTypeMonthlyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCostExplorerByServiceUsageTypeMonthlyPaginator(filters []BoolFilter, limit *int64) (CostExplorerByServiceUsageTypeMonthlyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_costexplorer_byusagetypemonthly", filters, limit)
	if err != nil {
		return CostExplorerByServiceUsageTypeMonthlyPaginator{}, err
	}

	p := CostExplorerByServiceUsageTypeMonthlyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CostExplorerByServiceUsageTypeMonthlyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CostExplorerByServiceUsageTypeMonthlyPaginator) NextPage(ctx context.Context) ([]CostExplorerByServiceUsageTypeMonthly, error) {
	var response CostExplorerByServiceUsageTypeMonthlySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CostExplorerByServiceUsageTypeMonthly
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCostExplorerByServiceUsageTypeMonthlyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCostExplorerByServiceUsageTypeMonthly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCostExplorerByServiceUsageTypeMonthly")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCostExplorerByServiceUsageTypeMonthlyPaginator(buildFilter(d.KeyColumnQuals, listCostExplorerByServiceUsageTypeMonthlyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCostExplorerByServiceUsageTypeMonthlyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetCostExplorerByServiceUsageTypeMonthly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCostExplorerByServiceUsageTypeMonthly")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCostExplorerByServiceUsageTypeMonthlyPaginator(buildFilter(d.KeyColumnQuals, getCostExplorerByServiceUsageTypeMonthlyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CostExplorerByServiceUsageTypeMonthly =============================

// ==========================  START: CostExplorerForcastMonthly =============================

type CostExplorerForcastMonthly struct {
	Description   aws.CostExplorerForcastMonthlyDescription `json:"description"`
	Metadata      aws.Metadata                              `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

type CostExplorerForcastMonthlyHit struct {
	ID      string                     `json:"_id"`
	Score   float64                    `json:"_score"`
	Index   string                     `json:"_index"`
	Type    string                     `json:"_type"`
	Version int64                      `json:"_version,omitempty"`
	Source  CostExplorerForcastMonthly `json:"_source"`
	Sort    []interface{}              `json:"sort"`
}

type CostExplorerForcastMonthlyHits struct {
	Total SearchTotal                     `json:"total"`
	Hits  []CostExplorerForcastMonthlyHit `json:"hits"`
}

type CostExplorerForcastMonthlySearchResponse struct {
	PitID string                         `json:"pit_id"`
	Hits  CostExplorerForcastMonthlyHits `json:"hits"`
}

type CostExplorerForcastMonthlyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCostExplorerForcastMonthlyPaginator(filters []BoolFilter, limit *int64) (CostExplorerForcastMonthlyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_costexplorer_forcastmonthly", filters, limit)
	if err != nil {
		return CostExplorerForcastMonthlyPaginator{}, err
	}

	p := CostExplorerForcastMonthlyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CostExplorerForcastMonthlyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CostExplorerForcastMonthlyPaginator) NextPage(ctx context.Context) ([]CostExplorerForcastMonthly, error) {
	var response CostExplorerForcastMonthlySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CostExplorerForcastMonthly
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCostExplorerForcastMonthlyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCostExplorerForcastMonthly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCostExplorerForcastMonthly")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCostExplorerForcastMonthlyPaginator(buildFilter(d.KeyColumnQuals, listCostExplorerForcastMonthlyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCostExplorerForcastMonthlyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetCostExplorerForcastMonthly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCostExplorerForcastMonthly")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCostExplorerForcastMonthlyPaginator(buildFilter(d.KeyColumnQuals, getCostExplorerForcastMonthlyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CostExplorerForcastMonthly =============================

// ==========================  START: CostExplorerByAccountDaily =============================

type CostExplorerByAccountDaily struct {
	Description   aws.CostExplorerByAccountDailyDescription `json:"description"`
	Metadata      aws.Metadata                              `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

type CostExplorerByAccountDailyHit struct {
	ID      string                     `json:"_id"`
	Score   float64                    `json:"_score"`
	Index   string                     `json:"_index"`
	Type    string                     `json:"_type"`
	Version int64                      `json:"_version,omitempty"`
	Source  CostExplorerByAccountDaily `json:"_source"`
	Sort    []interface{}              `json:"sort"`
}

type CostExplorerByAccountDailyHits struct {
	Total SearchTotal                     `json:"total"`
	Hits  []CostExplorerByAccountDailyHit `json:"hits"`
}

type CostExplorerByAccountDailySearchResponse struct {
	PitID string                         `json:"pit_id"`
	Hits  CostExplorerByAccountDailyHits `json:"hits"`
}

type CostExplorerByAccountDailyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCostExplorerByAccountDailyPaginator(filters []BoolFilter, limit *int64) (CostExplorerByAccountDailyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_costexplorer_byaccountdaily", filters, limit)
	if err != nil {
		return CostExplorerByAccountDailyPaginator{}, err
	}

	p := CostExplorerByAccountDailyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CostExplorerByAccountDailyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CostExplorerByAccountDailyPaginator) NextPage(ctx context.Context) ([]CostExplorerByAccountDaily, error) {
	var response CostExplorerByAccountDailySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CostExplorerByAccountDaily
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCostExplorerByAccountDailyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCostExplorerByAccountDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCostExplorerByAccountDaily")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCostExplorerByAccountDailyPaginator(buildFilter(d.KeyColumnQuals, listCostExplorerByAccountDailyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCostExplorerByAccountDailyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetCostExplorerByAccountDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCostExplorerByAccountDaily")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCostExplorerByAccountDailyPaginator(buildFilter(d.KeyColumnQuals, getCostExplorerByAccountDailyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CostExplorerByAccountDaily =============================

// ==========================  START: CostExplorerByServiceDaily =============================

type CostExplorerByServiceDaily struct {
	Description   aws.CostExplorerByServiceDailyDescription `json:"description"`
	Metadata      aws.Metadata                              `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

type CostExplorerByServiceDailyHit struct {
	ID      string                     `json:"_id"`
	Score   float64                    `json:"_score"`
	Index   string                     `json:"_index"`
	Type    string                     `json:"_type"`
	Version int64                      `json:"_version,omitempty"`
	Source  CostExplorerByServiceDaily `json:"_source"`
	Sort    []interface{}              `json:"sort"`
}

type CostExplorerByServiceDailyHits struct {
	Total SearchTotal                     `json:"total"`
	Hits  []CostExplorerByServiceDailyHit `json:"hits"`
}

type CostExplorerByServiceDailySearchResponse struct {
	PitID string                         `json:"pit_id"`
	Hits  CostExplorerByServiceDailyHits `json:"hits"`
}

type CostExplorerByServiceDailyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCostExplorerByServiceDailyPaginator(filters []BoolFilter, limit *int64) (CostExplorerByServiceDailyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_costexplorer_byservicedaily", filters, limit)
	if err != nil {
		return CostExplorerByServiceDailyPaginator{}, err
	}

	p := CostExplorerByServiceDailyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CostExplorerByServiceDailyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CostExplorerByServiceDailyPaginator) NextPage(ctx context.Context) ([]CostExplorerByServiceDaily, error) {
	var response CostExplorerByServiceDailySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CostExplorerByServiceDaily
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCostExplorerByServiceDailyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCostExplorerByServiceDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCostExplorerByServiceDaily")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCostExplorerByServiceDailyPaginator(buildFilter(d.KeyColumnQuals, listCostExplorerByServiceDailyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCostExplorerByServiceDailyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetCostExplorerByServiceDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCostExplorerByServiceDaily")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCostExplorerByServiceDailyPaginator(buildFilter(d.KeyColumnQuals, getCostExplorerByServiceDailyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CostExplorerByServiceDaily =============================

// ==========================  START: CostExplorerByRecordTypeDaily =============================

type CostExplorerByRecordTypeDaily struct {
	Description   aws.CostExplorerByRecordTypeDailyDescription `json:"description"`
	Metadata      aws.Metadata                                 `json:"metadata"`
	ResourceJobID int                                          `json:"resource_job_id"`
	SourceJobID   int                                          `json:"source_job_id"`
	ResourceType  string                                       `json:"resource_type"`
	SourceType    string                                       `json:"source_type"`
	ID            string                                       `json:"id"`
	ARN           string                                       `json:"arn"`
	SourceID      string                                       `json:"source_id"`
}

type CostExplorerByRecordTypeDailyHit struct {
	ID      string                        `json:"_id"`
	Score   float64                       `json:"_score"`
	Index   string                        `json:"_index"`
	Type    string                        `json:"_type"`
	Version int64                         `json:"_version,omitempty"`
	Source  CostExplorerByRecordTypeDaily `json:"_source"`
	Sort    []interface{}                 `json:"sort"`
}

type CostExplorerByRecordTypeDailyHits struct {
	Total SearchTotal                        `json:"total"`
	Hits  []CostExplorerByRecordTypeDailyHit `json:"hits"`
}

type CostExplorerByRecordTypeDailySearchResponse struct {
	PitID string                            `json:"pit_id"`
	Hits  CostExplorerByRecordTypeDailyHits `json:"hits"`
}

type CostExplorerByRecordTypeDailyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCostExplorerByRecordTypeDailyPaginator(filters []BoolFilter, limit *int64) (CostExplorerByRecordTypeDailyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_costexplorer_byrecordtypedaily", filters, limit)
	if err != nil {
		return CostExplorerByRecordTypeDailyPaginator{}, err
	}

	p := CostExplorerByRecordTypeDailyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CostExplorerByRecordTypeDailyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CostExplorerByRecordTypeDailyPaginator) NextPage(ctx context.Context) ([]CostExplorerByRecordTypeDaily, error) {
	var response CostExplorerByRecordTypeDailySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CostExplorerByRecordTypeDaily
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCostExplorerByRecordTypeDailyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCostExplorerByRecordTypeDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCostExplorerByRecordTypeDaily")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCostExplorerByRecordTypeDailyPaginator(buildFilter(d.KeyColumnQuals, listCostExplorerByRecordTypeDailyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCostExplorerByRecordTypeDailyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetCostExplorerByRecordTypeDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCostExplorerByRecordTypeDaily")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCostExplorerByRecordTypeDailyPaginator(buildFilter(d.KeyColumnQuals, getCostExplorerByRecordTypeDailyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CostExplorerByRecordTypeDaily =============================

// ==========================  START: CostExplorerByServiceUsageTypeDaily =============================

type CostExplorerByServiceUsageTypeDaily struct {
	Description   aws.CostExplorerByServiceUsageTypeDailyDescription `json:"description"`
	Metadata      aws.Metadata                                       `json:"metadata"`
	ResourceJobID int                                                `json:"resource_job_id"`
	SourceJobID   int                                                `json:"source_job_id"`
	ResourceType  string                                             `json:"resource_type"`
	SourceType    string                                             `json:"source_type"`
	ID            string                                             `json:"id"`
	ARN           string                                             `json:"arn"`
	SourceID      string                                             `json:"source_id"`
}

type CostExplorerByServiceUsageTypeDailyHit struct {
	ID      string                              `json:"_id"`
	Score   float64                             `json:"_score"`
	Index   string                              `json:"_index"`
	Type    string                              `json:"_type"`
	Version int64                               `json:"_version,omitempty"`
	Source  CostExplorerByServiceUsageTypeDaily `json:"_source"`
	Sort    []interface{}                       `json:"sort"`
}

type CostExplorerByServiceUsageTypeDailyHits struct {
	Total SearchTotal                              `json:"total"`
	Hits  []CostExplorerByServiceUsageTypeDailyHit `json:"hits"`
}

type CostExplorerByServiceUsageTypeDailySearchResponse struct {
	PitID string                                  `json:"pit_id"`
	Hits  CostExplorerByServiceUsageTypeDailyHits `json:"hits"`
}

type CostExplorerByServiceUsageTypeDailyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCostExplorerByServiceUsageTypeDailyPaginator(filters []BoolFilter, limit *int64) (CostExplorerByServiceUsageTypeDailyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_costexplorer_byusagetypedaily", filters, limit)
	if err != nil {
		return CostExplorerByServiceUsageTypeDailyPaginator{}, err
	}

	p := CostExplorerByServiceUsageTypeDailyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CostExplorerByServiceUsageTypeDailyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CostExplorerByServiceUsageTypeDailyPaginator) NextPage(ctx context.Context) ([]CostExplorerByServiceUsageTypeDaily, error) {
	var response CostExplorerByServiceUsageTypeDailySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CostExplorerByServiceUsageTypeDaily
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCostExplorerByServiceUsageTypeDailyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCostExplorerByServiceUsageTypeDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCostExplorerByServiceUsageTypeDaily")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCostExplorerByServiceUsageTypeDailyPaginator(buildFilter(d.KeyColumnQuals, listCostExplorerByServiceUsageTypeDailyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCostExplorerByServiceUsageTypeDailyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetCostExplorerByServiceUsageTypeDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCostExplorerByServiceUsageTypeDaily")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCostExplorerByServiceUsageTypeDailyPaginator(buildFilter(d.KeyColumnQuals, getCostExplorerByServiceUsageTypeDailyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CostExplorerByServiceUsageTypeDaily =============================

// ==========================  START: CostExplorerForcastDaily =============================

type CostExplorerForcastDaily struct {
	Description   aws.CostExplorerForcastDailyDescription `json:"description"`
	Metadata      aws.Metadata                            `json:"metadata"`
	ResourceJobID int                                     `json:"resource_job_id"`
	SourceJobID   int                                     `json:"source_job_id"`
	ResourceType  string                                  `json:"resource_type"`
	SourceType    string                                  `json:"source_type"`
	ID            string                                  `json:"id"`
	ARN           string                                  `json:"arn"`
	SourceID      string                                  `json:"source_id"`
}

type CostExplorerForcastDailyHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  CostExplorerForcastDaily `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type CostExplorerForcastDailyHits struct {
	Total SearchTotal                   `json:"total"`
	Hits  []CostExplorerForcastDailyHit `json:"hits"`
}

type CostExplorerForcastDailySearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  CostExplorerForcastDailyHits `json:"hits"`
}

type CostExplorerForcastDailyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCostExplorerForcastDailyPaginator(filters []BoolFilter, limit *int64) (CostExplorerForcastDailyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_costexplorer_forcastdaily", filters, limit)
	if err != nil {
		return CostExplorerForcastDailyPaginator{}, err
	}

	p := CostExplorerForcastDailyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CostExplorerForcastDailyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CostExplorerForcastDailyPaginator) NextPage(ctx context.Context) ([]CostExplorerForcastDaily, error) {
	var response CostExplorerForcastDailySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CostExplorerForcastDaily
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCostExplorerForcastDailyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCostExplorerForcastDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCostExplorerForcastDaily")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCostExplorerForcastDailyPaginator(buildFilter(d.KeyColumnQuals, listCostExplorerForcastDailyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCostExplorerForcastDailyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetCostExplorerForcastDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCostExplorerForcastDaily")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCostExplorerForcastDailyPaginator(buildFilter(d.KeyColumnQuals, getCostExplorerForcastDailyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CostExplorerForcastDaily =============================

// ==========================  START: ECRRepository =============================

type ECRRepository struct {
	Description   aws.ECRRepositoryDescription `json:"description"`
	Metadata      aws.Metadata                 `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

type ECRRepositoryHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  ECRRepository `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type ECRRepositoryHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []ECRRepositoryHit `json:"hits"`
}

type ECRRepositorySearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  ECRRepositoryHits `json:"hits"`
}

type ECRRepositoryPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewECRRepositoryPaginator(filters []BoolFilter, limit *int64) (ECRRepositoryPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ecr_repository", filters, limit)
	if err != nil {
		return ECRRepositoryPaginator{}, err
	}

	p := ECRRepositoryPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ECRRepositoryPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ECRRepositoryPaginator) NextPage(ctx context.Context) ([]ECRRepository, error) {
	var response ECRRepositorySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ECRRepository
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listECRRepositoryFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListECRRepository(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListECRRepository")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewECRRepositoryPaginator(buildFilter(d.KeyColumnQuals, listECRRepositoryFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getECRRepositoryFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"repository_name":  "description.Repository.RepositoryName",
}

func GetECRRepository(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetECRRepository")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewECRRepositoryPaginator(buildFilter(d.KeyColumnQuals, getECRRepositoryFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ECRRepository =============================

// ==========================  START: ECRImage =============================

type ECRImage struct {
	Description   aws.ECRImageDescription `json:"description"`
	Metadata      aws.Metadata            `json:"metadata"`
	ResourceJobID int                     `json:"resource_job_id"`
	SourceJobID   int                     `json:"source_job_id"`
	ResourceType  string                  `json:"resource_type"`
	SourceType    string                  `json:"source_type"`
	ID            string                  `json:"id"`
	ARN           string                  `json:"arn"`
	SourceID      string                  `json:"source_id"`
}

type ECRImageHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  ECRImage      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type ECRImageHits struct {
	Total SearchTotal   `json:"total"`
	Hits  []ECRImageHit `json:"hits"`
}

type ECRImageSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  ECRImageHits `json:"hits"`
}

type ECRImagePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewECRImagePaginator(filters []BoolFilter, limit *int64) (ECRImagePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ecr_image", filters, limit)
	if err != nil {
		return ECRImagePaginator{}, err
	}

	p := ECRImagePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ECRImagePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ECRImagePaginator) NextPage(ctx context.Context) ([]ECRImage, error) {
	var response ECRImageSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ECRImage
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listECRImageFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"registry_id":      "description.Image.RegistryId",
	"repository_name":  "description.Image.RepositoryName",
}

func ListECRImage(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListECRImage")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewECRImagePaginator(buildFilter(d.KeyColumnQuals, listECRImageFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getECRImageFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetECRImage(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetECRImage")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewECRImagePaginator(buildFilter(d.KeyColumnQuals, getECRImageFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ECRImage =============================

// ==========================  START: ECRPublicRepository =============================

type ECRPublicRepository struct {
	Description   aws.ECRPublicRepositoryDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type ECRPublicRepositoryHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  ECRPublicRepository `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type ECRPublicRepositoryHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []ECRPublicRepositoryHit `json:"hits"`
}

type ECRPublicRepositorySearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  ECRPublicRepositoryHits `json:"hits"`
}

type ECRPublicRepositoryPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewECRPublicRepositoryPaginator(filters []BoolFilter, limit *int64) (ECRPublicRepositoryPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ecrpublic_repository", filters, limit)
	if err != nil {
		return ECRPublicRepositoryPaginator{}, err
	}

	p := ECRPublicRepositoryPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ECRPublicRepositoryPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ECRPublicRepositoryPaginator) NextPage(ctx context.Context) ([]ECRPublicRepository, error) {
	var response ECRPublicRepositorySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ECRPublicRepository
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listECRPublicRepositoryFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListECRPublicRepository(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListECRPublicRepository")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewECRPublicRepositoryPaginator(buildFilter(d.KeyColumnQuals, listECRPublicRepositoryFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getECRPublicRepositoryFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"repository_name":  "description.PublicRepository.RepositoryName",
}

func GetECRPublicRepository(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetECRPublicRepository")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewECRPublicRepositoryPaginator(buildFilter(d.KeyColumnQuals, getECRPublicRepositoryFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ECRPublicRepository =============================

// ==========================  START: ECRPublicRegistry =============================

type ECRPublicRegistry struct {
	Description   aws.ECRPublicRegistryDescription `json:"description"`
	Metadata      aws.Metadata                     `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

type ECRPublicRegistryHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  ECRPublicRegistry `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type ECRPublicRegistryHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []ECRPublicRegistryHit `json:"hits"`
}

type ECRPublicRegistrySearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  ECRPublicRegistryHits `json:"hits"`
}

type ECRPublicRegistryPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewECRPublicRegistryPaginator(filters []BoolFilter, limit *int64) (ECRPublicRegistryPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ecrpublic_registry", filters, limit)
	if err != nil {
		return ECRPublicRegistryPaginator{}, err
	}

	p := ECRPublicRegistryPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ECRPublicRegistryPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ECRPublicRegistryPaginator) NextPage(ctx context.Context) ([]ECRPublicRegistry, error) {
	var response ECRPublicRegistrySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ECRPublicRegistry
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listECRPublicRegistryFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListECRPublicRegistry(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListECRPublicRegistry")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewECRPublicRegistryPaginator(buildFilter(d.KeyColumnQuals, listECRPublicRegistryFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getECRPublicRegistryFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"registry_id":      "description.PublicRegistry.RegistryId",
}

func GetECRPublicRegistry(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetECRPublicRegistry")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewECRPublicRegistryPaginator(buildFilter(d.KeyColumnQuals, getECRPublicRegistryFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ECRPublicRegistry =============================

// ==========================  START: EventBridgeBus =============================

type EventBridgeBus struct {
	Description   aws.EventBridgeBusDescription `json:"description"`
	Metadata      aws.Metadata                  `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

type EventBridgeBusHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  EventBridgeBus `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type EventBridgeBusHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []EventBridgeBusHit `json:"hits"`
}

type EventBridgeBusSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  EventBridgeBusHits `json:"hits"`
}

type EventBridgeBusPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEventBridgeBusPaginator(filters []BoolFilter, limit *int64) (EventBridgeBusPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_eventbridge_eventbus", filters, limit)
	if err != nil {
		return EventBridgeBusPaginator{}, err
	}

	p := EventBridgeBusPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EventBridgeBusPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EventBridgeBusPaginator) NextPage(ctx context.Context) ([]EventBridgeBus, error) {
	var response EventBridgeBusSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EventBridgeBus
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEventBridgeBusFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEventBridgeBus(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEventBridgeBus")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEventBridgeBusPaginator(buildFilter(d.KeyColumnQuals, listEventBridgeBusFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEventBridgeBusFilters = map[string]string{
	"arn":              "description.Bus.Arn",
	"keibi_account_id": "metadata.SourceID",
}

func GetEventBridgeBus(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEventBridgeBus")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEventBridgeBusPaginator(buildFilter(d.KeyColumnQuals, getEventBridgeBusFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EventBridgeBus =============================

// ==========================  START: EventBridgeRule =============================

type EventBridgeRule struct {
	Description   aws.EventBridgeRuleDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type EventBridgeRuleHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  EventBridgeRule `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type EventBridgeRuleHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []EventBridgeRuleHit `json:"hits"`
}

type EventBridgeRuleSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  EventBridgeRuleHits `json:"hits"`
}

type EventBridgeRulePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEventBridgeRulePaginator(filters []BoolFilter, limit *int64) (EventBridgeRulePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_eventbridge_eventrule", filters, limit)
	if err != nil {
		return EventBridgeRulePaginator{}, err
	}

	p := EventBridgeRulePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EventBridgeRulePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EventBridgeRulePaginator) NextPage(ctx context.Context) ([]EventBridgeRule, error) {
	var response EventBridgeRuleSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EventBridgeRule
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEventBridgeRuleFilters = map[string]string{
	"event_bus_name":   "description.Rule.EventBusName",
	"keibi_account_id": "metadata.SourceID",
	"name_prefix":      "description.Rule.Name",
}

func ListEventBridgeRule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEventBridgeRule")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEventBridgeRulePaginator(buildFilter(d.KeyColumnQuals, listEventBridgeRuleFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEventBridgeRuleFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Rule.Name",
}

func GetEventBridgeRule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEventBridgeRule")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEventBridgeRulePaginator(buildFilter(d.KeyColumnQuals, getEventBridgeRuleFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EventBridgeRule =============================

// ==========================  START: AppStreamApplication =============================

type AppStreamApplication struct {
	Description   aws.AppStreamApplicationDescription `json:"description"`
	Metadata      aws.Metadata                        `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type AppStreamApplicationHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  AppStreamApplication `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type AppStreamApplicationHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []AppStreamApplicationHit `json:"hits"`
}

type AppStreamApplicationSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  AppStreamApplicationHits `json:"hits"`
}

type AppStreamApplicationPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAppStreamApplicationPaginator(filters []BoolFilter, limit *int64) (AppStreamApplicationPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_appstream_application", filters, limit)
	if err != nil {
		return AppStreamApplicationPaginator{}, err
	}

	p := AppStreamApplicationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AppStreamApplicationPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AppStreamApplicationPaginator) NextPage(ctx context.Context) ([]AppStreamApplication, error) {
	var response AppStreamApplicationSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AppStreamApplication
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAppStreamApplicationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListAppStreamApplication(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAppStreamApplication")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAppStreamApplicationPaginator(buildFilter(d.KeyColumnQuals, listAppStreamApplicationFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAppStreamApplicationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Application.Name",
}

func GetAppStreamApplication(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAppStreamApplication")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAppStreamApplicationPaginator(buildFilter(d.KeyColumnQuals, getAppStreamApplicationFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AppStreamApplication =============================

// ==========================  START: AppStreamStack =============================

type AppStreamStack struct {
	Description   aws.AppStreamStackDescription `json:"description"`
	Metadata      aws.Metadata                  `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

type AppStreamStackHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  AppStreamStack `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type AppStreamStackHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []AppStreamStackHit `json:"hits"`
}

type AppStreamStackSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  AppStreamStackHits `json:"hits"`
}

type AppStreamStackPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAppStreamStackPaginator(filters []BoolFilter, limit *int64) (AppStreamStackPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_appstream_stack", filters, limit)
	if err != nil {
		return AppStreamStackPaginator{}, err
	}

	p := AppStreamStackPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AppStreamStackPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AppStreamStackPaginator) NextPage(ctx context.Context) ([]AppStreamStack, error) {
	var response AppStreamStackSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AppStreamStack
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAppStreamStackFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListAppStreamStack(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAppStreamStack")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAppStreamStackPaginator(buildFilter(d.KeyColumnQuals, listAppStreamStackFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAppStreamStackFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Stack.Name",
}

func GetAppStreamStack(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAppStreamStack")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAppStreamStackPaginator(buildFilter(d.KeyColumnQuals, getAppStreamStackFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AppStreamStack =============================

// ==========================  START: AppStreamFleet =============================

type AppStreamFleet struct {
	Description   aws.AppStreamFleetDescription `json:"description"`
	Metadata      aws.Metadata                  `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

type AppStreamFleetHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  AppStreamFleet `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type AppStreamFleetHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []AppStreamFleetHit `json:"hits"`
}

type AppStreamFleetSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  AppStreamFleetHits `json:"hits"`
}

type AppStreamFleetPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAppStreamFleetPaginator(filters []BoolFilter, limit *int64) (AppStreamFleetPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_appstream_fleet", filters, limit)
	if err != nil {
		return AppStreamFleetPaginator{}, err
	}

	p := AppStreamFleetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AppStreamFleetPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AppStreamFleetPaginator) NextPage(ctx context.Context) ([]AppStreamFleet, error) {
	var response AppStreamFleetSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AppStreamFleet
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAppStreamFleetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListAppStreamFleet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAppStreamFleet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAppStreamFleetPaginator(buildFilter(d.KeyColumnQuals, listAppStreamFleetFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAppStreamFleetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Fleet.Name",
}

func GetAppStreamFleet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAppStreamFleet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAppStreamFleetPaginator(buildFilter(d.KeyColumnQuals, getAppStreamFleetFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AppStreamFleet =============================

// ==========================  START: KinesisStream =============================

type KinesisStream struct {
	Description   aws.KinesisStreamDescription `json:"description"`
	Metadata      aws.Metadata                 `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

type KinesisStreamHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  KinesisStream `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type KinesisStreamHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []KinesisStreamHit `json:"hits"`
}

type KinesisStreamSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  KinesisStreamHits `json:"hits"`
}

type KinesisStreamPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewKinesisStreamPaginator(filters []BoolFilter, limit *int64) (KinesisStreamPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_kinesis_stream", filters, limit)
	if err != nil {
		return KinesisStreamPaginator{}, err
	}

	p := KinesisStreamPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p KinesisStreamPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p KinesisStreamPaginator) NextPage(ctx context.Context) ([]KinesisStream, error) {
	var response KinesisStreamSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []KinesisStream
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listKinesisStreamFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListKinesisStream(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListKinesisStream")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewKinesisStreamPaginator(buildFilter(d.KeyColumnQuals, listKinesisStreamFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getKinesisStreamFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"stream_name":      "description.Stream.StreamName",
}

func GetKinesisStream(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetKinesisStream")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewKinesisStreamPaginator(buildFilter(d.KeyColumnQuals, getKinesisStreamFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: KinesisStream =============================

// ==========================  START: KinesisAnalyticsV2Application =============================

type KinesisAnalyticsV2Application struct {
	Description   aws.KinesisAnalyticsV2ApplicationDescription `json:"description"`
	Metadata      aws.Metadata                                 `json:"metadata"`
	ResourceJobID int                                          `json:"resource_job_id"`
	SourceJobID   int                                          `json:"source_job_id"`
	ResourceType  string                                       `json:"resource_type"`
	SourceType    string                                       `json:"source_type"`
	ID            string                                       `json:"id"`
	ARN           string                                       `json:"arn"`
	SourceID      string                                       `json:"source_id"`
}

type KinesisAnalyticsV2ApplicationHit struct {
	ID      string                        `json:"_id"`
	Score   float64                       `json:"_score"`
	Index   string                        `json:"_index"`
	Type    string                        `json:"_type"`
	Version int64                         `json:"_version,omitempty"`
	Source  KinesisAnalyticsV2Application `json:"_source"`
	Sort    []interface{}                 `json:"sort"`
}

type KinesisAnalyticsV2ApplicationHits struct {
	Total SearchTotal                        `json:"total"`
	Hits  []KinesisAnalyticsV2ApplicationHit `json:"hits"`
}

type KinesisAnalyticsV2ApplicationSearchResponse struct {
	PitID string                            `json:"pit_id"`
	Hits  KinesisAnalyticsV2ApplicationHits `json:"hits"`
}

type KinesisAnalyticsV2ApplicationPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewKinesisAnalyticsV2ApplicationPaginator(filters []BoolFilter, limit *int64) (KinesisAnalyticsV2ApplicationPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_kinesisanalyticsv2_application", filters, limit)
	if err != nil {
		return KinesisAnalyticsV2ApplicationPaginator{}, err
	}

	p := KinesisAnalyticsV2ApplicationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p KinesisAnalyticsV2ApplicationPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p KinesisAnalyticsV2ApplicationPaginator) NextPage(ctx context.Context) ([]KinesisAnalyticsV2Application, error) {
	var response KinesisAnalyticsV2ApplicationSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []KinesisAnalyticsV2Application
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listKinesisAnalyticsV2ApplicationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListKinesisAnalyticsV2Application(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListKinesisAnalyticsV2Application")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewKinesisAnalyticsV2ApplicationPaginator(buildFilter(d.KeyColumnQuals, listKinesisAnalyticsV2ApplicationFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getKinesisAnalyticsV2ApplicationFilters = map[string]string{
	"application_name": "description.Application.ApplicationName",
	"keibi_account_id": "metadata.SourceID",
}

func GetKinesisAnalyticsV2Application(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetKinesisAnalyticsV2Application")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewKinesisAnalyticsV2ApplicationPaginator(buildFilter(d.KeyColumnQuals, getKinesisAnalyticsV2ApplicationFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: KinesisAnalyticsV2Application =============================

// ==========================  START: GlacierVault =============================

type GlacierVault struct {
	Description   aws.GlacierVaultDescription `json:"description"`
	Metadata      aws.Metadata                `json:"metadata"`
	ResourceJobID int                         `json:"resource_job_id"`
	SourceJobID   int                         `json:"source_job_id"`
	ResourceType  string                      `json:"resource_type"`
	SourceType    string                      `json:"source_type"`
	ID            string                      `json:"id"`
	ARN           string                      `json:"arn"`
	SourceID      string                      `json:"source_id"`
}

type GlacierVaultHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  GlacierVault  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type GlacierVaultHits struct {
	Total SearchTotal       `json:"total"`
	Hits  []GlacierVaultHit `json:"hits"`
}

type GlacierVaultSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  GlacierVaultHits `json:"hits"`
}

type GlacierVaultPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewGlacierVaultPaginator(filters []BoolFilter, limit *int64) (GlacierVaultPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_glacier_vault", filters, limit)
	if err != nil {
		return GlacierVaultPaginator{}, err
	}

	p := GlacierVaultPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p GlacierVaultPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p GlacierVaultPaginator) NextPage(ctx context.Context) ([]GlacierVault, error) {
	var response GlacierVaultSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []GlacierVault
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listGlacierVaultFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListGlacierVault(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListGlacierVault")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewGlacierVaultPaginator(buildFilter(d.KeyColumnQuals, listGlacierVaultFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getGlacierVaultFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"vault_name":       "description.Vault.VaultName",
}

func GetGlacierVault(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetGlacierVault")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewGlacierVaultPaginator(buildFilter(d.KeyColumnQuals, getGlacierVaultFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: GlacierVault =============================

// ==========================  START: WorkspacesWorkspace =============================

type WorkspacesWorkspace struct {
	Description   aws.WorkspacesWorkspaceDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type WorkspacesWorkspaceHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  WorkspacesWorkspace `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type WorkspacesWorkspaceHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []WorkspacesWorkspaceHit `json:"hits"`
}

type WorkspacesWorkspaceSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  WorkspacesWorkspaceHits `json:"hits"`
}

type WorkspacesWorkspacePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewWorkspacesWorkspacePaginator(filters []BoolFilter, limit *int64) (WorkspacesWorkspacePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_workspaces_workspace", filters, limit)
	if err != nil {
		return WorkspacesWorkspacePaginator{}, err
	}

	p := WorkspacesWorkspacePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p WorkspacesWorkspacePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p WorkspacesWorkspacePaginator) NextPage(ctx context.Context) ([]WorkspacesWorkspace, error) {
	var response WorkspacesWorkspaceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []WorkspacesWorkspace
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listWorkspacesWorkspaceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListWorkspacesWorkspace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListWorkspacesWorkspace")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewWorkspacesWorkspacePaginator(buildFilter(d.KeyColumnQuals, listWorkspacesWorkspaceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getWorkspacesWorkspaceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"workspace_id":     "description.Workspace.WorkspaceId",
}

func GetWorkspacesWorkspace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetWorkspacesWorkspace")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewWorkspacesWorkspacePaginator(buildFilter(d.KeyColumnQuals, getWorkspacesWorkspaceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: WorkspacesWorkspace =============================

// ==========================  START: WorkspacesBundle =============================

type WorkspacesBundle struct {
	Description   aws.WorkspacesBundleDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type WorkspacesBundleHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  WorkspacesBundle `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type WorkspacesBundleHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []WorkspacesBundleHit `json:"hits"`
}

type WorkspacesBundleSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  WorkspacesBundleHits `json:"hits"`
}

type WorkspacesBundlePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewWorkspacesBundlePaginator(filters []BoolFilter, limit *int64) (WorkspacesBundlePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_workspaces_bundle", filters, limit)
	if err != nil {
		return WorkspacesBundlePaginator{}, err
	}

	p := WorkspacesBundlePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p WorkspacesBundlePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p WorkspacesBundlePaginator) NextPage(ctx context.Context) ([]WorkspacesBundle, error) {
	var response WorkspacesBundleSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []WorkspacesBundle
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listWorkspacesBundleFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListWorkspacesBundle(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListWorkspacesBundle")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewWorkspacesBundlePaginator(buildFilter(d.KeyColumnQuals, listWorkspacesBundleFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getWorkspacesBundleFilters = map[string]string{
	"bundle_id":        "description.Bundle.BundleId",
	"keibi_account_id": "metadata.SourceID",
}

func GetWorkspacesBundle(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetWorkspacesBundle")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewWorkspacesBundlePaginator(buildFilter(d.KeyColumnQuals, getWorkspacesBundleFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: WorkspacesBundle =============================

// ==========================  START: KeyspacesKeyspace =============================

type KeyspacesKeyspace struct {
	Description   aws.KeyspacesKeyspaceDescription `json:"description"`
	Metadata      aws.Metadata                     `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

type KeyspacesKeyspaceHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  KeyspacesKeyspace `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type KeyspacesKeyspaceHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []KeyspacesKeyspaceHit `json:"hits"`
}

type KeyspacesKeyspaceSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  KeyspacesKeyspaceHits `json:"hits"`
}

type KeyspacesKeyspacePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewKeyspacesKeyspacePaginator(filters []BoolFilter, limit *int64) (KeyspacesKeyspacePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_keyspaces_keyspace", filters, limit)
	if err != nil {
		return KeyspacesKeyspacePaginator{}, err
	}

	p := KeyspacesKeyspacePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p KeyspacesKeyspacePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p KeyspacesKeyspacePaginator) NextPage(ctx context.Context) ([]KeyspacesKeyspace, error) {
	var response KeyspacesKeyspaceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []KeyspacesKeyspace
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listKeyspacesKeyspaceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListKeyspacesKeyspace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListKeyspacesKeyspace")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewKeyspacesKeyspacePaginator(buildFilter(d.KeyColumnQuals, listKeyspacesKeyspaceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getKeyspacesKeyspaceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"keyspace_name":    "description.Keyspace.KeyspaceName",
}

func GetKeyspacesKeyspace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetKeyspacesKeyspace")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewKeyspacesKeyspacePaginator(buildFilter(d.KeyColumnQuals, getKeyspacesKeyspaceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: KeyspacesKeyspace =============================

// ==========================  START: KeyspacesTable =============================

type KeyspacesTable struct {
	Description   aws.KeyspacesTableDescription `json:"description"`
	Metadata      aws.Metadata                  `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

type KeyspacesTableHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  KeyspacesTable `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type KeyspacesTableHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []KeyspacesTableHit `json:"hits"`
}

type KeyspacesTableSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  KeyspacesTableHits `json:"hits"`
}

type KeyspacesTablePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewKeyspacesTablePaginator(filters []BoolFilter, limit *int64) (KeyspacesTablePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_keyspaces_table", filters, limit)
	if err != nil {
		return KeyspacesTablePaginator{}, err
	}

	p := KeyspacesTablePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p KeyspacesTablePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p KeyspacesTablePaginator) NextPage(ctx context.Context) ([]KeyspacesTable, error) {
	var response KeyspacesTableSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []KeyspacesTable
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listKeyspacesTableFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListKeyspacesTable(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListKeyspacesTable")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewKeyspacesTablePaginator(buildFilter(d.KeyColumnQuals, listKeyspacesTableFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getKeyspacesTableFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"table_name":       "description.Table.TableName",
}

func GetKeyspacesTable(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetKeyspacesTable")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewKeyspacesTablePaginator(buildFilter(d.KeyColumnQuals, getKeyspacesTableFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: KeyspacesTable =============================

// ==========================  START: GrafanaWorkspace =============================

type GrafanaWorkspace struct {
	Description   aws.GrafanaWorkspaceDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type GrafanaWorkspaceHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  GrafanaWorkspace `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type GrafanaWorkspaceHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []GrafanaWorkspaceHit `json:"hits"`
}

type GrafanaWorkspaceSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  GrafanaWorkspaceHits `json:"hits"`
}

type GrafanaWorkspacePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewGrafanaWorkspacePaginator(filters []BoolFilter, limit *int64) (GrafanaWorkspacePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_grafana_workspace", filters, limit)
	if err != nil {
		return GrafanaWorkspacePaginator{}, err
	}

	p := GrafanaWorkspacePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p GrafanaWorkspacePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p GrafanaWorkspacePaginator) NextPage(ctx context.Context) ([]GrafanaWorkspace, error) {
	var response GrafanaWorkspaceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []GrafanaWorkspace
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listGrafanaWorkspaceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListGrafanaWorkspace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListGrafanaWorkspace")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewGrafanaWorkspacePaginator(buildFilter(d.KeyColumnQuals, listGrafanaWorkspaceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getGrafanaWorkspaceFilters = map[string]string{
	"id":               "description.Workspace.Id",
	"keibi_account_id": "metadata.SourceID",
}

func GetGrafanaWorkspace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetGrafanaWorkspace")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewGrafanaWorkspacePaginator(buildFilter(d.KeyColumnQuals, getGrafanaWorkspaceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: GrafanaWorkspace =============================

// ==========================  START: AMPWorkspace =============================

type AMPWorkspace struct {
	Description   aws.AMPWorkspaceDescription `json:"description"`
	Metadata      aws.Metadata                `json:"metadata"`
	ResourceJobID int                         `json:"resource_job_id"`
	SourceJobID   int                         `json:"source_job_id"`
	ResourceType  string                      `json:"resource_type"`
	SourceType    string                      `json:"source_type"`
	ID            string                      `json:"id"`
	ARN           string                      `json:"arn"`
	SourceID      string                      `json:"source_id"`
}

type AMPWorkspaceHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  AMPWorkspace  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type AMPWorkspaceHits struct {
	Total SearchTotal       `json:"total"`
	Hits  []AMPWorkspaceHit `json:"hits"`
}

type AMPWorkspaceSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  AMPWorkspaceHits `json:"hits"`
}

type AMPWorkspacePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAMPWorkspacePaginator(filters []BoolFilter, limit *int64) (AMPWorkspacePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_amp_workspace", filters, limit)
	if err != nil {
		return AMPWorkspacePaginator{}, err
	}

	p := AMPWorkspacePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AMPWorkspacePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AMPWorkspacePaginator) NextPage(ctx context.Context) ([]AMPWorkspace, error) {
	var response AMPWorkspaceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AMPWorkspace
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAMPWorkspaceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListAMPWorkspace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAMPWorkspace")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAMPWorkspacePaginator(buildFilter(d.KeyColumnQuals, listAMPWorkspaceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAMPWorkspaceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"workspace_id":     "description.Workspace.WorkspaceId",
}

func GetAMPWorkspace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAMPWorkspace")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAMPWorkspacePaginator(buildFilter(d.KeyColumnQuals, getAMPWorkspaceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AMPWorkspace =============================

// ==========================  START: KafkaCluster =============================

type KafkaCluster struct {
	Description   aws.KafkaClusterDescription `json:"description"`
	Metadata      aws.Metadata                `json:"metadata"`
	ResourceJobID int                         `json:"resource_job_id"`
	SourceJobID   int                         `json:"source_job_id"`
	ResourceType  string                      `json:"resource_type"`
	SourceType    string                      `json:"source_type"`
	ID            string                      `json:"id"`
	ARN           string                      `json:"arn"`
	SourceID      string                      `json:"source_id"`
}

type KafkaClusterHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  KafkaCluster  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type KafkaClusterHits struct {
	Total SearchTotal       `json:"total"`
	Hits  []KafkaClusterHit `json:"hits"`
}

type KafkaClusterSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  KafkaClusterHits `json:"hits"`
}

type KafkaClusterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewKafkaClusterPaginator(filters []BoolFilter, limit *int64) (KafkaClusterPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_kafka_cluster", filters, limit)
	if err != nil {
		return KafkaClusterPaginator{}, err
	}

	p := KafkaClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p KafkaClusterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p KafkaClusterPaginator) NextPage(ctx context.Context) ([]KafkaCluster, error) {
	var response KafkaClusterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []KafkaCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listKafkaClusterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListKafkaCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListKafkaCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewKafkaClusterPaginator(buildFilter(d.KeyColumnQuals, listKafkaClusterFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getKafkaClusterFilters = map[string]string{
	"cluster_name":     "description.Cluster.ClusterName",
	"keibi_account_id": "metadata.SourceID",
}

func GetKafkaCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetKafkaCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewKafkaClusterPaginator(buildFilter(d.KeyColumnQuals, getKafkaClusterFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: KafkaCluster =============================

// ==========================  START: MWAAEnvironment =============================

type MWAAEnvironment struct {
	Description   aws.MWAAEnvironmentDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type MWAAEnvironmentHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  MWAAEnvironment `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type MWAAEnvironmentHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []MWAAEnvironmentHit `json:"hits"`
}

type MWAAEnvironmentSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  MWAAEnvironmentHits `json:"hits"`
}

type MWAAEnvironmentPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewMWAAEnvironmentPaginator(filters []BoolFilter, limit *int64) (MWAAEnvironmentPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_mwaa_environment", filters, limit)
	if err != nil {
		return MWAAEnvironmentPaginator{}, err
	}

	p := MWAAEnvironmentPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p MWAAEnvironmentPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p MWAAEnvironmentPaginator) NextPage(ctx context.Context) ([]MWAAEnvironment, error) {
	var response MWAAEnvironmentSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []MWAAEnvironment
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listMWAAEnvironmentFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListMWAAEnvironment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListMWAAEnvironment")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewMWAAEnvironmentPaginator(buildFilter(d.KeyColumnQuals, listMWAAEnvironmentFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getMWAAEnvironmentFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Environment.Name",
}

func GetMWAAEnvironment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetMWAAEnvironment")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewMWAAEnvironmentPaginator(buildFilter(d.KeyColumnQuals, getMWAAEnvironmentFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: MWAAEnvironment =============================

// ==========================  START: MemoryDbCluster =============================

type MemoryDbCluster struct {
	Description   aws.MemoryDbClusterDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type MemoryDbClusterHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  MemoryDbCluster `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type MemoryDbClusterHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []MemoryDbClusterHit `json:"hits"`
}

type MemoryDbClusterSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  MemoryDbClusterHits `json:"hits"`
}

type MemoryDbClusterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewMemoryDbClusterPaginator(filters []BoolFilter, limit *int64) (MemoryDbClusterPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_memorydb_cluster", filters, limit)
	if err != nil {
		return MemoryDbClusterPaginator{}, err
	}

	p := MemoryDbClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p MemoryDbClusterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p MemoryDbClusterPaginator) NextPage(ctx context.Context) ([]MemoryDbCluster, error) {
	var response MemoryDbClusterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []MemoryDbCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listMemoryDbClusterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListMemoryDbCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListMemoryDbCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewMemoryDbClusterPaginator(buildFilter(d.KeyColumnQuals, listMemoryDbClusterFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getMemoryDbClusterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Cluster.Name",
}

func GetMemoryDbCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetMemoryDbCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewMemoryDbClusterPaginator(buildFilter(d.KeyColumnQuals, getMemoryDbClusterFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: MemoryDbCluster =============================

// ==========================  START: MQBroker =============================

type MQBroker struct {
	Description   aws.MQBrokerDescription `json:"description"`
	Metadata      aws.Metadata            `json:"metadata"`
	ResourceJobID int                     `json:"resource_job_id"`
	SourceJobID   int                     `json:"source_job_id"`
	ResourceType  string                  `json:"resource_type"`
	SourceType    string                  `json:"source_type"`
	ID            string                  `json:"id"`
	ARN           string                  `json:"arn"`
	SourceID      string                  `json:"source_id"`
}

type MQBrokerHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  MQBroker      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type MQBrokerHits struct {
	Total SearchTotal   `json:"total"`
	Hits  []MQBrokerHit `json:"hits"`
}

type MQBrokerSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  MQBrokerHits `json:"hits"`
}

type MQBrokerPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewMQBrokerPaginator(filters []BoolFilter, limit *int64) (MQBrokerPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_mq_broker", filters, limit)
	if err != nil {
		return MQBrokerPaginator{}, err
	}

	p := MQBrokerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p MQBrokerPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p MQBrokerPaginator) NextPage(ctx context.Context) ([]MQBroker, error) {
	var response MQBrokerSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []MQBroker
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listMQBrokerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListMQBroker(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListMQBroker")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewMQBrokerPaginator(buildFilter(d.KeyColumnQuals, listMQBrokerFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getMQBrokerFilters = map[string]string{
	"broker_name":      "description.Broker.BrokerName",
	"keibi_account_id": "metadata.SourceID",
}

func GetMQBroker(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetMQBroker")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewMQBrokerPaginator(buildFilter(d.KeyColumnQuals, getMQBrokerFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: MQBroker =============================

// ==========================  START: NeptuneDatabase =============================

type NeptuneDatabase struct {
	Description   aws.NeptuneDatabaseDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type NeptuneDatabaseHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  NeptuneDatabase `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type NeptuneDatabaseHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []NeptuneDatabaseHit `json:"hits"`
}

type NeptuneDatabaseSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  NeptuneDatabaseHits `json:"hits"`
}

type NeptuneDatabasePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewNeptuneDatabasePaginator(filters []BoolFilter, limit *int64) (NeptuneDatabasePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_neptune_database", filters, limit)
	if err != nil {
		return NeptuneDatabasePaginator{}, err
	}

	p := NeptuneDatabasePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p NeptuneDatabasePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p NeptuneDatabasePaginator) NextPage(ctx context.Context) ([]NeptuneDatabase, error) {
	var response NeptuneDatabaseSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []NeptuneDatabase
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listNeptuneDatabaseFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListNeptuneDatabase(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListNeptuneDatabase")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewNeptuneDatabasePaginator(buildFilter(d.KeyColumnQuals, listNeptuneDatabaseFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getNeptuneDatabaseFilters = map[string]string{
	"db_instance_identifier": "description.Database.DBInstanceIdentifier",
	"keibi_account_id":       "metadata.SourceID",
}

func GetNeptuneDatabase(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetNeptuneDatabase")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewNeptuneDatabasePaginator(buildFilter(d.KeyColumnQuals, getNeptuneDatabaseFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: NeptuneDatabase =============================

// ==========================  START: OpenSearchDomain =============================

type OpenSearchDomain struct {
	Description   aws.OpenSearchDomainDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type OpenSearchDomainHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  OpenSearchDomain `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type OpenSearchDomainHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []OpenSearchDomainHit `json:"hits"`
}

type OpenSearchDomainSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  OpenSearchDomainHits `json:"hits"`
}

type OpenSearchDomainPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewOpenSearchDomainPaginator(filters []BoolFilter, limit *int64) (OpenSearchDomainPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_opensearch_domain", filters, limit)
	if err != nil {
		return OpenSearchDomainPaginator{}, err
	}

	p := OpenSearchDomainPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p OpenSearchDomainPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p OpenSearchDomainPaginator) NextPage(ctx context.Context) ([]OpenSearchDomain, error) {
	var response OpenSearchDomainSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []OpenSearchDomain
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listOpenSearchDomainFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListOpenSearchDomain(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListOpenSearchDomain")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewOpenSearchDomainPaginator(buildFilter(d.KeyColumnQuals, listOpenSearchDomainFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getOpenSearchDomainFilters = map[string]string{
	"domain_name":      "description.Domain.DomainName",
	"keibi_account_id": "metadata.SourceID",
}

func GetOpenSearchDomain(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetOpenSearchDomain")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewOpenSearchDomainPaginator(buildFilter(d.KeyColumnQuals, getOpenSearchDomainFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: OpenSearchDomain =============================

// ==========================  START: SESConfigurationSet =============================

type SESConfigurationSet struct {
	Description   aws.SESConfigurationSetDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type SESConfigurationSetHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  SESConfigurationSet `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type SESConfigurationSetHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []SESConfigurationSetHit `json:"hits"`
}

type SESConfigurationSetSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  SESConfigurationSetHits `json:"hits"`
}

type SESConfigurationSetPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSESConfigurationSetPaginator(filters []BoolFilter, limit *int64) (SESConfigurationSetPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ses_configurtionset", filters, limit)
	if err != nil {
		return SESConfigurationSetPaginator{}, err
	}

	p := SESConfigurationSetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SESConfigurationSetPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SESConfigurationSetPaginator) NextPage(ctx context.Context) ([]SESConfigurationSet, error) {
	var response SESConfigurationSetSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SESConfigurationSet
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSESConfigurationSetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSESConfigurationSet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSESConfigurationSet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSESConfigurationSetPaginator(buildFilter(d.KeyColumnQuals, listSESConfigurationSetFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSESConfigurationSetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.ConfigurationSet.Name",
}

func GetSESConfigurationSet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSESConfigurationSet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSESConfigurationSetPaginator(buildFilter(d.KeyColumnQuals, getSESConfigurationSetFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SESConfigurationSet =============================

// ==========================  START: SESIdentity =============================

type SESIdentity struct {
	Description   aws.SESIdentityDescription `json:"description"`
	Metadata      aws.Metadata               `json:"metadata"`
	ResourceJobID int                        `json:"resource_job_id"`
	SourceJobID   int                        `json:"source_job_id"`
	ResourceType  string                     `json:"resource_type"`
	SourceType    string                     `json:"source_type"`
	ID            string                     `json:"id"`
	ARN           string                     `json:"arn"`
	SourceID      string                     `json:"source_id"`
}

type SESIdentityHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  SESIdentity   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type SESIdentityHits struct {
	Total SearchTotal      `json:"total"`
	Hits  []SESIdentityHit `json:"hits"`
}

type SESIdentitySearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  SESIdentityHits `json:"hits"`
}

type SESIdentityPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSESIdentityPaginator(filters []BoolFilter, limit *int64) (SESIdentityPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ses_identity", filters, limit)
	if err != nil {
		return SESIdentityPaginator{}, err
	}

	p := SESIdentityPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SESIdentityPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SESIdentityPaginator) NextPage(ctx context.Context) ([]SESIdentity, error) {
	var response SESIdentitySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SESIdentity
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSESIdentityFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSESIdentity(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSESIdentity")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSESIdentityPaginator(buildFilter(d.KeyColumnQuals, listSESIdentityFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSESIdentityFilters = map[string]string{
	"identity_name":    "description.Identity.IdentityName",
	"keibi_account_id": "metadata.SourceID",
}

func GetSESIdentity(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSESIdentity")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSESIdentityPaginator(buildFilter(d.KeyColumnQuals, getSESIdentityFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SESIdentity =============================

// ==========================  START: CloudFormationStack =============================

type CloudFormationStack struct {
	Description   aws.CloudFormationStackDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type CloudFormationStackHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  CloudFormationStack `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type CloudFormationStackHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []CloudFormationStackHit `json:"hits"`
}

type CloudFormationStackSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  CloudFormationStackHits `json:"hits"`
}

type CloudFormationStackPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudFormationStackPaginator(filters []BoolFilter, limit *int64) (CloudFormationStackPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudformation_stack", filters, limit)
	if err != nil {
		return CloudFormationStackPaginator{}, err
	}

	p := CloudFormationStackPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudFormationStackPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudFormationStackPaginator) NextPage(ctx context.Context) ([]CloudFormationStack, error) {
	var response CloudFormationStackSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudFormationStack
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudFormationStackFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Stack.StackName",
}

func ListCloudFormationStack(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudFormationStack")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudFormationStackPaginator(buildFilter(d.KeyColumnQuals, listCloudFormationStackFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudFormationStackFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Stack.StackName",
}

func GetCloudFormationStack(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudFormationStack")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudFormationStackPaginator(buildFilter(d.KeyColumnQuals, getCloudFormationStackFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudFormationStack =============================

// ==========================  START: CloudFormationStackSet =============================

type CloudFormationStackSet struct {
	Description   aws.CloudFormationStackSetDescription `json:"description"`
	Metadata      aws.Metadata                          `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

type CloudFormationStackSetHit struct {
	ID      string                 `json:"_id"`
	Score   float64                `json:"_score"`
	Index   string                 `json:"_index"`
	Type    string                 `json:"_type"`
	Version int64                  `json:"_version,omitempty"`
	Source  CloudFormationStackSet `json:"_source"`
	Sort    []interface{}          `json:"sort"`
}

type CloudFormationStackSetHits struct {
	Total SearchTotal                 `json:"total"`
	Hits  []CloudFormationStackSetHit `json:"hits"`
}

type CloudFormationStackSetSearchResponse struct {
	PitID string                     `json:"pit_id"`
	Hits  CloudFormationStackSetHits `json:"hits"`
}

type CloudFormationStackSetPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudFormationStackSetPaginator(filters []BoolFilter, limit *int64) (CloudFormationStackSetPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudformation_stackset", filters, limit)
	if err != nil {
		return CloudFormationStackSetPaginator{}, err
	}

	p := CloudFormationStackSetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudFormationStackSetPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudFormationStackSetPaginator) NextPage(ctx context.Context) ([]CloudFormationStackSet, error) {
	var response CloudFormationStackSetSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudFormationStackSet
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudFormationStackSetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCloudFormationStackSet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudFormationStackSet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudFormationStackSetPaginator(buildFilter(d.KeyColumnQuals, listCloudFormationStackSetFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudFormationStackSetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"stack_set_name":   "description.StackSet.StackSetName",
}

func GetCloudFormationStackSet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudFormationStackSet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudFormationStackSetPaginator(buildFilter(d.KeyColumnQuals, getCloudFormationStackSetFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudFormationStackSet =============================

// ==========================  START: CodeCommitRepository =============================

type CodeCommitRepository struct {
	Description   aws.CodeCommitRepositoryDescription `json:"description"`
	Metadata      aws.Metadata                        `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type CodeCommitRepositoryHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  CodeCommitRepository `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type CodeCommitRepositoryHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []CodeCommitRepositoryHit `json:"hits"`
}

type CodeCommitRepositorySearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  CodeCommitRepositoryHits `json:"hits"`
}

type CodeCommitRepositoryPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCodeCommitRepositoryPaginator(filters []BoolFilter, limit *int64) (CodeCommitRepositoryPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_codecommit_repository", filters, limit)
	if err != nil {
		return CodeCommitRepositoryPaginator{}, err
	}

	p := CodeCommitRepositoryPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CodeCommitRepositoryPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CodeCommitRepositoryPaginator) NextPage(ctx context.Context) ([]CodeCommitRepository, error) {
	var response CodeCommitRepositorySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CodeCommitRepository
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCodeCommitRepositoryFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCodeCommitRepository(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCodeCommitRepository")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCodeCommitRepositoryPaginator(buildFilter(d.KeyColumnQuals, listCodeCommitRepositoryFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCodeCommitRepositoryFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetCodeCommitRepository(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCodeCommitRepository")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCodeCommitRepositoryPaginator(buildFilter(d.KeyColumnQuals, getCodeCommitRepositoryFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CodeCommitRepository =============================

// ==========================  START: CodePipelinePipeline =============================

type CodePipelinePipeline struct {
	Description   aws.CodePipelinePipelineDescription `json:"description"`
	Metadata      aws.Metadata                        `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type CodePipelinePipelineHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  CodePipelinePipeline `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type CodePipelinePipelineHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []CodePipelinePipelineHit `json:"hits"`
}

type CodePipelinePipelineSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  CodePipelinePipelineHits `json:"hits"`
}

type CodePipelinePipelinePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCodePipelinePipelinePaginator(filters []BoolFilter, limit *int64) (CodePipelinePipelinePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_codepipeline_pipeline", filters, limit)
	if err != nil {
		return CodePipelinePipelinePaginator{}, err
	}

	p := CodePipelinePipelinePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CodePipelinePipelinePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CodePipelinePipelinePaginator) NextPage(ctx context.Context) ([]CodePipelinePipeline, error) {
	var response CodePipelinePipelineSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CodePipelinePipeline
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCodePipelinePipelineFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCodePipelinePipeline(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCodePipelinePipeline")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCodePipelinePipelinePaginator(buildFilter(d.KeyColumnQuals, listCodePipelinePipelineFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCodePipelinePipelineFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Pipeline.Name",
}

func GetCodePipelinePipeline(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCodePipelinePipeline")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCodePipelinePipelinePaginator(buildFilter(d.KeyColumnQuals, getCodePipelinePipelineFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CodePipelinePipeline =============================

// ==========================  START: DirectoryServiceDirectory =============================

type DirectoryServiceDirectory struct {
	Description   aws.DirectoryServiceDirectoryDescription `json:"description"`
	Metadata      aws.Metadata                             `json:"metadata"`
	ResourceJobID int                                      `json:"resource_job_id"`
	SourceJobID   int                                      `json:"source_job_id"`
	ResourceType  string                                   `json:"resource_type"`
	SourceType    string                                   `json:"source_type"`
	ID            string                                   `json:"id"`
	ARN           string                                   `json:"arn"`
	SourceID      string                                   `json:"source_id"`
}

type DirectoryServiceDirectoryHit struct {
	ID      string                    `json:"_id"`
	Score   float64                   `json:"_score"`
	Index   string                    `json:"_index"`
	Type    string                    `json:"_type"`
	Version int64                     `json:"_version,omitempty"`
	Source  DirectoryServiceDirectory `json:"_source"`
	Sort    []interface{}             `json:"sort"`
}

type DirectoryServiceDirectoryHits struct {
	Total SearchTotal                    `json:"total"`
	Hits  []DirectoryServiceDirectoryHit `json:"hits"`
}

type DirectoryServiceDirectorySearchResponse struct {
	PitID string                        `json:"pit_id"`
	Hits  DirectoryServiceDirectoryHits `json:"hits"`
}

type DirectoryServiceDirectoryPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDirectoryServiceDirectoryPaginator(filters []BoolFilter, limit *int64) (DirectoryServiceDirectoryPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_directoryservice_directory", filters, limit)
	if err != nil {
		return DirectoryServiceDirectoryPaginator{}, err
	}

	p := DirectoryServiceDirectoryPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DirectoryServiceDirectoryPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DirectoryServiceDirectoryPaginator) NextPage(ctx context.Context) ([]DirectoryServiceDirectory, error) {
	var response DirectoryServiceDirectorySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DirectoryServiceDirectory
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDirectoryServiceDirectoryFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListDirectoryServiceDirectory(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDirectoryServiceDirectory")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDirectoryServiceDirectoryPaginator(buildFilter(d.KeyColumnQuals, listDirectoryServiceDirectoryFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDirectoryServiceDirectoryFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Directory.DirectoryId",
}

func GetDirectoryServiceDirectory(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDirectoryServiceDirectory")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDirectoryServiceDirectoryPaginator(buildFilter(d.KeyColumnQuals, getDirectoryServiceDirectoryFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DirectoryServiceDirectory =============================

// ==========================  START: SSOAdminInstance =============================

type SSOAdminInstance struct {
	Description   aws.SSOAdminInstanceDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type SSOAdminInstanceHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  SSOAdminInstance `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type SSOAdminInstanceHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []SSOAdminInstanceHit `json:"hits"`
}

type SSOAdminInstanceSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  SSOAdminInstanceHits `json:"hits"`
}

type SSOAdminInstancePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSSOAdminInstancePaginator(filters []BoolFilter, limit *int64) (SSOAdminInstancePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ssoadmin_instance", filters, limit)
	if err != nil {
		return SSOAdminInstancePaginator{}, err
	}

	p := SSOAdminInstancePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SSOAdminInstancePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SSOAdminInstancePaginator) NextPage(ctx context.Context) ([]SSOAdminInstance, error) {
	var response SSOAdminInstanceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SSOAdminInstance
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSSOAdminInstanceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSSOAdminInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSSOAdminInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSSOAdminInstancePaginator(buildFilter(d.KeyColumnQuals, listSSOAdminInstanceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSSOAdminInstanceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetSSOAdminInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSSOAdminInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSSOAdminInstancePaginator(buildFilter(d.KeyColumnQuals, getSSOAdminInstanceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SSOAdminInstance =============================

// ==========================  START: WAFRule =============================

type WAFRule struct {
	Description   aws.WAFRuleDescription `json:"description"`
	Metadata      aws.Metadata           `json:"metadata"`
	ResourceJobID int                    `json:"resource_job_id"`
	SourceJobID   int                    `json:"source_job_id"`
	ResourceType  string                 `json:"resource_type"`
	SourceType    string                 `json:"source_type"`
	ID            string                 `json:"id"`
	ARN           string                 `json:"arn"`
	SourceID      string                 `json:"source_id"`
}

type WAFRuleHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  WAFRule       `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type WAFRuleHits struct {
	Total SearchTotal  `json:"total"`
	Hits  []WAFRuleHit `json:"hits"`
}

type WAFRuleSearchResponse struct {
	PitID string      `json:"pit_id"`
	Hits  WAFRuleHits `json:"hits"`
}

type WAFRulePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewWAFRulePaginator(filters []BoolFilter, limit *int64) (WAFRulePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_waf_rule", filters, limit)
	if err != nil {
		return WAFRulePaginator{}, err
	}

	p := WAFRulePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p WAFRulePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p WAFRulePaginator) NextPage(ctx context.Context) ([]WAFRule, error) {
	var response WAFRuleSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []WAFRule
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listWAFRuleFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListWAFRule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListWAFRule")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewWAFRulePaginator(buildFilter(d.KeyColumnQuals, listWAFRuleFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getWAFRuleFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"rule_id":          "description.Rule.RuleId",
}

func GetWAFRule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetWAFRule")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewWAFRulePaginator(buildFilter(d.KeyColumnQuals, getWAFRuleFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: WAFRule =============================

// ==========================  START: WAFRegionalRule =============================

type WAFRegionalRule struct {
	Description   aws.WAFRegionalRuleDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type WAFRegionalRuleHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  WAFRegionalRule `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type WAFRegionalRuleHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []WAFRegionalRuleHit `json:"hits"`
}

type WAFRegionalRuleSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  WAFRegionalRuleHits `json:"hits"`
}

type WAFRegionalRulePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewWAFRegionalRulePaginator(filters []BoolFilter, limit *int64) (WAFRegionalRulePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_wafregional_rule", filters, limit)
	if err != nil {
		return WAFRegionalRulePaginator{}, err
	}

	p := WAFRegionalRulePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p WAFRegionalRulePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p WAFRegionalRulePaginator) NextPage(ctx context.Context) ([]WAFRegionalRule, error) {
	var response WAFRegionalRuleSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []WAFRegionalRule
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listWAFRegionalRuleFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListWAFRegionalRule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListWAFRegionalRule")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewWAFRegionalRulePaginator(buildFilter(d.KeyColumnQuals, listWAFRegionalRuleFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getWAFRegionalRuleFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"rule_id":          "description.Rule.RuleId",
}

func GetWAFRegionalRule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetWAFRegionalRule")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewWAFRegionalRulePaginator(buildFilter(d.KeyColumnQuals, getWAFRegionalRuleFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: WAFRegionalRule =============================

// ==========================  START: Route53HostedZone =============================

type Route53HostedZone struct {
	Description   aws.Route53HostedZoneDescription `json:"description"`
	Metadata      aws.Metadata                     `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

type Route53HostedZoneHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  Route53HostedZone `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type Route53HostedZoneHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []Route53HostedZoneHit `json:"hits"`
}

type Route53HostedZoneSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  Route53HostedZoneHits `json:"hits"`
}

type Route53HostedZonePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRoute53HostedZonePaginator(filters []BoolFilter, limit *int64) (Route53HostedZonePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_route53_hostedzone", filters, limit)
	if err != nil {
		return Route53HostedZonePaginator{}, err
	}

	p := Route53HostedZonePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p Route53HostedZonePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p Route53HostedZonePaginator) NextPage(ctx context.Context) ([]Route53HostedZone, error) {
	var response Route53HostedZoneSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []Route53HostedZone
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRoute53HostedZoneFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListRoute53HostedZone(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRoute53HostedZone")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRoute53HostedZonePaginator(buildFilter(d.KeyColumnQuals, listRoute53HostedZoneFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRoute53HostedZoneFilters = map[string]string{
	"id":               "description.ID",
	"keibi_account_id": "metadata.SourceID",
}

func GetRoute53HostedZone(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRoute53HostedZone")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRoute53HostedZonePaginator(buildFilter(d.KeyColumnQuals, getRoute53HostedZoneFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: Route53HostedZone =============================

// ==========================  START: BatchComputeEnvironment =============================

type BatchComputeEnvironment struct {
	Description   aws.BatchComputeEnvironmentDescription `json:"description"`
	Metadata      aws.Metadata                           `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

type BatchComputeEnvironmentHit struct {
	ID      string                  `json:"_id"`
	Score   float64                 `json:"_score"`
	Index   string                  `json:"_index"`
	Type    string                  `json:"_type"`
	Version int64                   `json:"_version,omitempty"`
	Source  BatchComputeEnvironment `json:"_source"`
	Sort    []interface{}           `json:"sort"`
}

type BatchComputeEnvironmentHits struct {
	Total SearchTotal                  `json:"total"`
	Hits  []BatchComputeEnvironmentHit `json:"hits"`
}

type BatchComputeEnvironmentSearchResponse struct {
	PitID string                      `json:"pit_id"`
	Hits  BatchComputeEnvironmentHits `json:"hits"`
}

type BatchComputeEnvironmentPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewBatchComputeEnvironmentPaginator(filters []BoolFilter, limit *int64) (BatchComputeEnvironmentPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_batch_computeenvironment", filters, limit)
	if err != nil {
		return BatchComputeEnvironmentPaginator{}, err
	}

	p := BatchComputeEnvironmentPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p BatchComputeEnvironmentPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p BatchComputeEnvironmentPaginator) NextPage(ctx context.Context) ([]BatchComputeEnvironment, error) {
	var response BatchComputeEnvironmentSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []BatchComputeEnvironment
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listBatchComputeEnvironmentFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListBatchComputeEnvironment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListBatchComputeEnvironment")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewBatchComputeEnvironmentPaginator(buildFilter(d.KeyColumnQuals, listBatchComputeEnvironmentFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getBatchComputeEnvironmentFilters = map[string]string{
	"compute_environment_name": "description.ComputeEnvironment.ComputeEnvironmentName",
	"keibi_account_id":         "metadata.SourceID",
}

func GetBatchComputeEnvironment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetBatchComputeEnvironment")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewBatchComputeEnvironmentPaginator(buildFilter(d.KeyColumnQuals, getBatchComputeEnvironmentFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: BatchComputeEnvironment =============================

// ==========================  START: BatchJob =============================

type BatchJob struct {
	Description   aws.BatchJobDescription `json:"description"`
	Metadata      aws.Metadata            `json:"metadata"`
	ResourceJobID int                     `json:"resource_job_id"`
	SourceJobID   int                     `json:"source_job_id"`
	ResourceType  string                  `json:"resource_type"`
	SourceType    string                  `json:"source_type"`
	ID            string                  `json:"id"`
	ARN           string                  `json:"arn"`
	SourceID      string                  `json:"source_id"`
}

type BatchJobHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  BatchJob      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type BatchJobHits struct {
	Total SearchTotal   `json:"total"`
	Hits  []BatchJobHit `json:"hits"`
}

type BatchJobSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  BatchJobHits `json:"hits"`
}

type BatchJobPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewBatchJobPaginator(filters []BoolFilter, limit *int64) (BatchJobPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_batch_job", filters, limit)
	if err != nil {
		return BatchJobPaginator{}, err
	}

	p := BatchJobPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p BatchJobPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p BatchJobPaginator) NextPage(ctx context.Context) ([]BatchJob, error) {
	var response BatchJobSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []BatchJob
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listBatchJobFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListBatchJob(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListBatchJob")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewBatchJobPaginator(buildFilter(d.KeyColumnQuals, listBatchJobFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getBatchJobFilters = map[string]string{
	"job_name":         "description.Job.JobName",
	"keibi_account_id": "metadata.SourceID",
}

func GetBatchJob(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetBatchJob")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewBatchJobPaginator(buildFilter(d.KeyColumnQuals, getBatchJobFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: BatchJob =============================

// ==========================  START: CodeArtifactRepository =============================

type CodeArtifactRepository struct {
	Description   aws.CodeArtifactRepositoryDescription `json:"description"`
	Metadata      aws.Metadata                          `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

type CodeArtifactRepositoryHit struct {
	ID      string                 `json:"_id"`
	Score   float64                `json:"_score"`
	Index   string                 `json:"_index"`
	Type    string                 `json:"_type"`
	Version int64                  `json:"_version,omitempty"`
	Source  CodeArtifactRepository `json:"_source"`
	Sort    []interface{}          `json:"sort"`
}

type CodeArtifactRepositoryHits struct {
	Total SearchTotal                 `json:"total"`
	Hits  []CodeArtifactRepositoryHit `json:"hits"`
}

type CodeArtifactRepositorySearchResponse struct {
	PitID string                     `json:"pit_id"`
	Hits  CodeArtifactRepositoryHits `json:"hits"`
}

type CodeArtifactRepositoryPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCodeArtifactRepositoryPaginator(filters []BoolFilter, limit *int64) (CodeArtifactRepositoryPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_codeartifact_repository", filters, limit)
	if err != nil {
		return CodeArtifactRepositoryPaginator{}, err
	}

	p := CodeArtifactRepositoryPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CodeArtifactRepositoryPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CodeArtifactRepositoryPaginator) NextPage(ctx context.Context) ([]CodeArtifactRepository, error) {
	var response CodeArtifactRepositorySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CodeArtifactRepository
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCodeArtifactRepositoryFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCodeArtifactRepository(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCodeArtifactRepository")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCodeArtifactRepositoryPaginator(buildFilter(d.KeyColumnQuals, listCodeArtifactRepositoryFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCodeArtifactRepositoryFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Repository.Name",
}

func GetCodeArtifactRepository(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCodeArtifactRepository")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCodeArtifactRepositoryPaginator(buildFilter(d.KeyColumnQuals, getCodeArtifactRepositoryFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CodeArtifactRepository =============================

// ==========================  START: CodeArtifactDomain =============================

type CodeArtifactDomain struct {
	Description   aws.CodeArtifactDomainDescription `json:"description"`
	Metadata      aws.Metadata                      `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

type CodeArtifactDomainHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  CodeArtifactDomain `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type CodeArtifactDomainHits struct {
	Total SearchTotal             `json:"total"`
	Hits  []CodeArtifactDomainHit `json:"hits"`
}

type CodeArtifactDomainSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  CodeArtifactDomainHits `json:"hits"`
}

type CodeArtifactDomainPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCodeArtifactDomainPaginator(filters []BoolFilter, limit *int64) (CodeArtifactDomainPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_codeartifact_domain", filters, limit)
	if err != nil {
		return CodeArtifactDomainPaginator{}, err
	}

	p := CodeArtifactDomainPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CodeArtifactDomainPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CodeArtifactDomainPaginator) NextPage(ctx context.Context) ([]CodeArtifactDomain, error) {
	var response CodeArtifactDomainSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CodeArtifactDomain
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCodeArtifactDomainFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCodeArtifactDomain(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCodeArtifactDomain")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCodeArtifactDomainPaginator(buildFilter(d.KeyColumnQuals, listCodeArtifactDomainFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCodeArtifactDomainFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Domain.Owner",
}

func GetCodeArtifactDomain(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCodeArtifactDomain")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCodeArtifactDomainPaginator(buildFilter(d.KeyColumnQuals, getCodeArtifactDomainFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CodeArtifactDomain =============================

// ==========================  START: CodeDeployDeploymentGroup =============================

type CodeDeployDeploymentGroup struct {
	Description   aws.CodeDeployDeploymentGroupDescription `json:"description"`
	Metadata      aws.Metadata                             `json:"metadata"`
	ResourceJobID int                                      `json:"resource_job_id"`
	SourceJobID   int                                      `json:"source_job_id"`
	ResourceType  string                                   `json:"resource_type"`
	SourceType    string                                   `json:"source_type"`
	ID            string                                   `json:"id"`
	ARN           string                                   `json:"arn"`
	SourceID      string                                   `json:"source_id"`
}

type CodeDeployDeploymentGroupHit struct {
	ID      string                    `json:"_id"`
	Score   float64                   `json:"_score"`
	Index   string                    `json:"_index"`
	Type    string                    `json:"_type"`
	Version int64                     `json:"_version,omitempty"`
	Source  CodeDeployDeploymentGroup `json:"_source"`
	Sort    []interface{}             `json:"sort"`
}

type CodeDeployDeploymentGroupHits struct {
	Total SearchTotal                    `json:"total"`
	Hits  []CodeDeployDeploymentGroupHit `json:"hits"`
}

type CodeDeployDeploymentGroupSearchResponse struct {
	PitID string                        `json:"pit_id"`
	Hits  CodeDeployDeploymentGroupHits `json:"hits"`
}

type CodeDeployDeploymentGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCodeDeployDeploymentGroupPaginator(filters []BoolFilter, limit *int64) (CodeDeployDeploymentGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_codedeploy_deploymentgroup", filters, limit)
	if err != nil {
		return CodeDeployDeploymentGroupPaginator{}, err
	}

	p := CodeDeployDeploymentGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CodeDeployDeploymentGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CodeDeployDeploymentGroupPaginator) NextPage(ctx context.Context) ([]CodeDeployDeploymentGroup, error) {
	var response CodeDeployDeploymentGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CodeDeployDeploymentGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCodeDeployDeploymentGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCodeDeployDeploymentGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCodeDeployDeploymentGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCodeDeployDeploymentGroupPaginator(buildFilter(d.KeyColumnQuals, listCodeDeployDeploymentGroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCodeDeployDeploymentGroupFilters = map[string]string{
	"deployment_group_name": "description.DeploymentGroup.DeploymentGroupName",
	"keibi_account_id":      "metadata.SourceID",
}

func GetCodeDeployDeploymentGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCodeDeployDeploymentGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCodeDeployDeploymentGroupPaginator(buildFilter(d.KeyColumnQuals, getCodeDeployDeploymentGroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CodeDeployDeploymentGroup =============================

// ==========================  START: CodeDeployApplication =============================

type CodeDeployApplication struct {
	Description   aws.CodeDeployApplicationDescription `json:"description"`
	Metadata      aws.Metadata                         `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

type CodeDeployApplicationHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  CodeDeployApplication `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type CodeDeployApplicationHits struct {
	Total SearchTotal                `json:"total"`
	Hits  []CodeDeployApplicationHit `json:"hits"`
}

type CodeDeployApplicationSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  CodeDeployApplicationHits `json:"hits"`
}

type CodeDeployApplicationPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCodeDeployApplicationPaginator(filters []BoolFilter, limit *int64) (CodeDeployApplicationPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_codedeploy_application", filters, limit)
	if err != nil {
		return CodeDeployApplicationPaginator{}, err
	}

	p := CodeDeployApplicationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CodeDeployApplicationPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CodeDeployApplicationPaginator) NextPage(ctx context.Context) ([]CodeDeployApplication, error) {
	var response CodeDeployApplicationSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CodeDeployApplication
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCodeDeployApplicationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCodeDeployApplication(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCodeDeployApplication")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCodeDeployApplicationPaginator(buildFilter(d.KeyColumnQuals, listCodeDeployApplicationFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCodeDeployApplicationFilters = map[string]string{
	"application_name": "description.Application.ApplicationName",
	"keibi_account_id": "metadata.SourceID",
}

func GetCodeDeployApplication(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCodeDeployApplication")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCodeDeployApplicationPaginator(buildFilter(d.KeyColumnQuals, getCodeDeployApplicationFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CodeDeployApplication =============================

// ==========================  START: CodeStarProject =============================

type CodeStarProject struct {
	Description   aws.CodeStarProjectDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type CodeStarProjectHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  CodeStarProject `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type CodeStarProjectHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []CodeStarProjectHit `json:"hits"`
}

type CodeStarProjectSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  CodeStarProjectHits `json:"hits"`
}

type CodeStarProjectPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCodeStarProjectPaginator(filters []BoolFilter, limit *int64) (CodeStarProjectPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_codestar_project", filters, limit)
	if err != nil {
		return CodeStarProjectPaginator{}, err
	}

	p := CodeStarProjectPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CodeStarProjectPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CodeStarProjectPaginator) NextPage(ctx context.Context) ([]CodeStarProject, error) {
	var response CodeStarProjectSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CodeStarProject
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCodeStarProjectFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCodeStarProject(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCodeStarProject")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCodeStarProjectPaginator(buildFilter(d.KeyColumnQuals, listCodeStarProjectFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCodeStarProjectFilters = map[string]string{
	"id":               "description.Project.Id",
	"keibi_account_id": "metadata.SourceID",
}

func GetCodeStarProject(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCodeStarProject")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCodeStarProjectPaginator(buildFilter(d.KeyColumnQuals, getCodeStarProjectFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CodeStarProject =============================

// ==========================  START: DirectConnectConnection =============================

type DirectConnectConnection struct {
	Description   aws.DirectConnectConnectionDescription `json:"description"`
	Metadata      aws.Metadata                           `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

type DirectConnectConnectionHit struct {
	ID      string                  `json:"_id"`
	Score   float64                 `json:"_score"`
	Index   string                  `json:"_index"`
	Type    string                  `json:"_type"`
	Version int64                   `json:"_version,omitempty"`
	Source  DirectConnectConnection `json:"_source"`
	Sort    []interface{}           `json:"sort"`
}

type DirectConnectConnectionHits struct {
	Total SearchTotal                  `json:"total"`
	Hits  []DirectConnectConnectionHit `json:"hits"`
}

type DirectConnectConnectionSearchResponse struct {
	PitID string                      `json:"pit_id"`
	Hits  DirectConnectConnectionHits `json:"hits"`
}

type DirectConnectConnectionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDirectConnectConnectionPaginator(filters []BoolFilter, limit *int64) (DirectConnectConnectionPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_directconnect_connection", filters, limit)
	if err != nil {
		return DirectConnectConnectionPaginator{}, err
	}

	p := DirectConnectConnectionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DirectConnectConnectionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DirectConnectConnectionPaginator) NextPage(ctx context.Context) ([]DirectConnectConnection, error) {
	var response DirectConnectConnectionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DirectConnectConnection
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDirectConnectConnectionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListDirectConnectConnection(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDirectConnectConnection")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDirectConnectConnectionPaginator(buildFilter(d.KeyColumnQuals, listDirectConnectConnectionFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDirectConnectConnectionFilters = map[string]string{
	"connection_id":    "description.Connection.ConnectionId",
	"keibi_account_id": "metadata.SourceID",
}

func GetDirectConnectConnection(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDirectConnectConnection")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDirectConnectConnectionPaginator(buildFilter(d.KeyColumnQuals, getDirectConnectConnectionFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DirectConnectConnection =============================

// ==========================  START: DirectConnectGateway =============================

type DirectConnectGateway struct {
	Description   aws.DirectConnectGatewayDescription `json:"description"`
	Metadata      aws.Metadata                        `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type DirectConnectGatewayHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  DirectConnectGateway `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type DirectConnectGatewayHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []DirectConnectGatewayHit `json:"hits"`
}

type DirectConnectGatewaySearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  DirectConnectGatewayHits `json:"hits"`
}

type DirectConnectGatewayPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDirectConnectGatewayPaginator(filters []BoolFilter, limit *int64) (DirectConnectGatewayPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_directconnect_gateway", filters, limit)
	if err != nil {
		return DirectConnectGatewayPaginator{}, err
	}

	p := DirectConnectGatewayPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DirectConnectGatewayPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DirectConnectGatewayPaginator) NextPage(ctx context.Context) ([]DirectConnectGateway, error) {
	var response DirectConnectGatewaySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DirectConnectGateway
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDirectConnectGatewayFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListDirectConnectGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDirectConnectGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDirectConnectGatewayPaginator(buildFilter(d.KeyColumnQuals, listDirectConnectGatewayFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDirectConnectGatewayFilters = map[string]string{
	"direct_connect_gateway_id": "description.Gateway.DirectConnectGatewayId",
	"keibi_account_id":          "metadata.SourceID",
}

func GetDirectConnectGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDirectConnectGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDirectConnectGatewayPaginator(buildFilter(d.KeyColumnQuals, getDirectConnectGatewayFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DirectConnectGateway =============================

// ==========================  START: DRSSourceServer =============================

type DRSSourceServer struct {
	Description   aws.DRSSourceServerDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type DRSSourceServerHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  DRSSourceServer `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type DRSSourceServerHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []DRSSourceServerHit `json:"hits"`
}

type DRSSourceServerSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  DRSSourceServerHits `json:"hits"`
}

type DRSSourceServerPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDRSSourceServerPaginator(filters []BoolFilter, limit *int64) (DRSSourceServerPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_drs_sourceserver", filters, limit)
	if err != nil {
		return DRSSourceServerPaginator{}, err
	}

	p := DRSSourceServerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DRSSourceServerPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DRSSourceServerPaginator) NextPage(ctx context.Context) ([]DRSSourceServer, error) {
	var response DRSSourceServerSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DRSSourceServer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDRSSourceServerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListDRSSourceServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDRSSourceServer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDRSSourceServerPaginator(buildFilter(d.KeyColumnQuals, listDRSSourceServerFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDRSSourceServerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"source_server_id": "description.SourceServer.SourceServerID",
}

func GetDRSSourceServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDRSSourceServer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDRSSourceServerPaginator(buildFilter(d.KeyColumnQuals, getDRSSourceServerFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DRSSourceServer =============================

// ==========================  START: DRSRecoveryInstance =============================

type DRSRecoveryInstance struct {
	Description   aws.DRSRecoveryInstanceDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type DRSRecoveryInstanceHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  DRSRecoveryInstance `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type DRSRecoveryInstanceHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []DRSRecoveryInstanceHit `json:"hits"`
}

type DRSRecoveryInstanceSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  DRSRecoveryInstanceHits `json:"hits"`
}

type DRSRecoveryInstancePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDRSRecoveryInstancePaginator(filters []BoolFilter, limit *int64) (DRSRecoveryInstancePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_drs_recoveryinstance", filters, limit)
	if err != nil {
		return DRSRecoveryInstancePaginator{}, err
	}

	p := DRSRecoveryInstancePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DRSRecoveryInstancePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DRSRecoveryInstancePaginator) NextPage(ctx context.Context) ([]DRSRecoveryInstance, error) {
	var response DRSRecoveryInstanceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DRSRecoveryInstance
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDRSRecoveryInstanceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListDRSRecoveryInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDRSRecoveryInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDRSRecoveryInstancePaginator(buildFilter(d.KeyColumnQuals, listDRSRecoveryInstanceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDRSRecoveryInstanceFilters = map[string]string{
	"keibi_account_id":     "metadata.SourceID",
	"recovery_instance_id": "description.RecoveryInstance.RecoveryInstanceID",
}

func GetDRSRecoveryInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDRSRecoveryInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDRSRecoveryInstancePaginator(buildFilter(d.KeyColumnQuals, getDRSRecoveryInstanceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DRSRecoveryInstance =============================

// ==========================  START: DRSJob =============================

type DRSJob struct {
	Description   aws.DRSJobDescription `json:"description"`
	Metadata      aws.Metadata          `json:"metadata"`
	ResourceJobID int                   `json:"resource_job_id"`
	SourceJobID   int                   `json:"source_job_id"`
	ResourceType  string                `json:"resource_type"`
	SourceType    string                `json:"source_type"`
	ID            string                `json:"id"`
	ARN           string                `json:"arn"`
	SourceID      string                `json:"source_id"`
}

type DRSJobHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  DRSJob        `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type DRSJobHits struct {
	Total SearchTotal `json:"total"`
	Hits  []DRSJobHit `json:"hits"`
}

type DRSJobSearchResponse struct {
	PitID string     `json:"pit_id"`
	Hits  DRSJobHits `json:"hits"`
}

type DRSJobPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDRSJobPaginator(filters []BoolFilter, limit *int64) (DRSJobPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_drs_job", filters, limit)
	if err != nil {
		return DRSJobPaginator{}, err
	}

	p := DRSJobPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DRSJobPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DRSJobPaginator) NextPage(ctx context.Context) ([]DRSJob, error) {
	var response DRSJobSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DRSJob
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDRSJobFilters = map[string]string{
	"creation_date_time": "description.Job.CreationDateTime",
	"end_date_time":      "description.Job.EndDateTime",
	"job_id":             "description.Job.JobID",
	"keibi_account_id":   "metadata.SourceID",
}

func ListDRSJob(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDRSJob")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDRSJobPaginator(buildFilter(d.KeyColumnQuals, listDRSJobFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDRSJobFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetDRSJob(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDRSJob")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDRSJobPaginator(buildFilter(d.KeyColumnQuals, getDRSJobFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DRSJob =============================

// ==========================  START: DRSRecoverySnapshot =============================

type DRSRecoverySnapshot struct {
	Description   aws.DRSRecoverySnapshotDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type DRSRecoverySnapshotHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  DRSRecoverySnapshot `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type DRSRecoverySnapshotHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []DRSRecoverySnapshotHit `json:"hits"`
}

type DRSRecoverySnapshotSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  DRSRecoverySnapshotHits `json:"hits"`
}

type DRSRecoverySnapshotPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDRSRecoverySnapshotPaginator(filters []BoolFilter, limit *int64) (DRSRecoverySnapshotPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_drs_recoverysnapshot", filters, limit)
	if err != nil {
		return DRSRecoverySnapshotPaginator{}, err
	}

	p := DRSRecoverySnapshotPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DRSRecoverySnapshotPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DRSRecoverySnapshotPaginator) NextPage(ctx context.Context) ([]DRSRecoverySnapshot, error) {
	var response DRSRecoverySnapshotSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DRSRecoverySnapshot
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDRSRecoverySnapshotFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"source_server_id": "description.RecoveryInstance.SourceServerID",
	"timestamp":        "description.RecoveryInstance.Timestamp",
}

func ListDRSRecoverySnapshot(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDRSRecoverySnapshot")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDRSRecoverySnapshotPaginator(buildFilter(d.KeyColumnQuals, listDRSRecoverySnapshotFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDRSRecoverySnapshotFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetDRSRecoverySnapshot(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDRSRecoverySnapshot")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDRSRecoverySnapshotPaginator(buildFilter(d.KeyColumnQuals, getDRSRecoverySnapshotFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DRSRecoverySnapshot =============================

// ==========================  START: FMSPolicy =============================

type FMSPolicy struct {
	Description   aws.FMSPolicyDescription `json:"description"`
	Metadata      aws.Metadata             `json:"metadata"`
	ResourceJobID int                      `json:"resource_job_id"`
	SourceJobID   int                      `json:"source_job_id"`
	ResourceType  string                   `json:"resource_type"`
	SourceType    string                   `json:"source_type"`
	ID            string                   `json:"id"`
	ARN           string                   `json:"arn"`
	SourceID      string                   `json:"source_id"`
}

type FMSPolicyHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  FMSPolicy     `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type FMSPolicyHits struct {
	Total SearchTotal    `json:"total"`
	Hits  []FMSPolicyHit `json:"hits"`
}

type FMSPolicySearchResponse struct {
	PitID string        `json:"pit_id"`
	Hits  FMSPolicyHits `json:"hits"`
}

type FMSPolicyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewFMSPolicyPaginator(filters []BoolFilter, limit *int64) (FMSPolicyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_fms_policy", filters, limit)
	if err != nil {
		return FMSPolicyPaginator{}, err
	}

	p := FMSPolicyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p FMSPolicyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p FMSPolicyPaginator) NextPage(ctx context.Context) ([]FMSPolicy, error) {
	var response FMSPolicySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []FMSPolicy
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listFMSPolicyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListFMSPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListFMSPolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewFMSPolicyPaginator(buildFilter(d.KeyColumnQuals, listFMSPolicyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getFMSPolicyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"policy_name":      "description.Policy.PolicyName",
}

func GetFMSPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetFMSPolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewFMSPolicyPaginator(buildFilter(d.KeyColumnQuals, getFMSPolicyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: FMSPolicy =============================

// ==========================  START: NetworkFirewallFirewall =============================

type NetworkFirewallFirewall struct {
	Description   aws.NetworkFirewallFirewallDescription `json:"description"`
	Metadata      aws.Metadata                           `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

type NetworkFirewallFirewallHit struct {
	ID      string                  `json:"_id"`
	Score   float64                 `json:"_score"`
	Index   string                  `json:"_index"`
	Type    string                  `json:"_type"`
	Version int64                   `json:"_version,omitempty"`
	Source  NetworkFirewallFirewall `json:"_source"`
	Sort    []interface{}           `json:"sort"`
}

type NetworkFirewallFirewallHits struct {
	Total SearchTotal                  `json:"total"`
	Hits  []NetworkFirewallFirewallHit `json:"hits"`
}

type NetworkFirewallFirewallSearchResponse struct {
	PitID string                      `json:"pit_id"`
	Hits  NetworkFirewallFirewallHits `json:"hits"`
}

type NetworkFirewallFirewallPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewNetworkFirewallFirewallPaginator(filters []BoolFilter, limit *int64) (NetworkFirewallFirewallPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_networkfirewall_firewall", filters, limit)
	if err != nil {
		return NetworkFirewallFirewallPaginator{}, err
	}

	p := NetworkFirewallFirewallPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p NetworkFirewallFirewallPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p NetworkFirewallFirewallPaginator) NextPage(ctx context.Context) ([]NetworkFirewallFirewall, error) {
	var response NetworkFirewallFirewallSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []NetworkFirewallFirewall
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listNetworkFirewallFirewallFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListNetworkFirewallFirewall(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListNetworkFirewallFirewall")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewNetworkFirewallFirewallPaginator(buildFilter(d.KeyColumnQuals, listNetworkFirewallFirewallFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getNetworkFirewallFirewallFilters = map[string]string{
	"firewall_name":    "description.Firewall.FirewallName",
	"keibi_account_id": "metadata.SourceID",
}

func GetNetworkFirewallFirewall(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetNetworkFirewallFirewall")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewNetworkFirewallFirewallPaginator(buildFilter(d.KeyColumnQuals, getNetworkFirewallFirewallFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: NetworkFirewallFirewall =============================

// ==========================  START: OpsWorksCMServer =============================

type OpsWorksCMServer struct {
	Description   aws.OpsWorksCMServerDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type OpsWorksCMServerHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  OpsWorksCMServer `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type OpsWorksCMServerHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []OpsWorksCMServerHit `json:"hits"`
}

type OpsWorksCMServerSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  OpsWorksCMServerHits `json:"hits"`
}

type OpsWorksCMServerPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewOpsWorksCMServerPaginator(filters []BoolFilter, limit *int64) (OpsWorksCMServerPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_opsworkscm_server", filters, limit)
	if err != nil {
		return OpsWorksCMServerPaginator{}, err
	}

	p := OpsWorksCMServerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p OpsWorksCMServerPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p OpsWorksCMServerPaginator) NextPage(ctx context.Context) ([]OpsWorksCMServer, error) {
	var response OpsWorksCMServerSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []OpsWorksCMServer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listOpsWorksCMServerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListOpsWorksCMServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListOpsWorksCMServer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewOpsWorksCMServerPaginator(buildFilter(d.KeyColumnQuals, listOpsWorksCMServerFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getOpsWorksCMServerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"server_name":      "description.Server.ServerName",
}

func GetOpsWorksCMServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetOpsWorksCMServer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewOpsWorksCMServerPaginator(buildFilter(d.KeyColumnQuals, getOpsWorksCMServerFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: OpsWorksCMServer =============================

// ==========================  START: OrganizationsOrganization =============================

type OrganizationsOrganization struct {
	Description   aws.OrganizationsOrganizationDescription `json:"description"`
	Metadata      aws.Metadata                             `json:"metadata"`
	ResourceJobID int                                      `json:"resource_job_id"`
	SourceJobID   int                                      `json:"source_job_id"`
	ResourceType  string                                   `json:"resource_type"`
	SourceType    string                                   `json:"source_type"`
	ID            string                                   `json:"id"`
	ARN           string                                   `json:"arn"`
	SourceID      string                                   `json:"source_id"`
}

type OrganizationsOrganizationHit struct {
	ID      string                    `json:"_id"`
	Score   float64                   `json:"_score"`
	Index   string                    `json:"_index"`
	Type    string                    `json:"_type"`
	Version int64                     `json:"_version,omitempty"`
	Source  OrganizationsOrganization `json:"_source"`
	Sort    []interface{}             `json:"sort"`
}

type OrganizationsOrganizationHits struct {
	Total SearchTotal                    `json:"total"`
	Hits  []OrganizationsOrganizationHit `json:"hits"`
}

type OrganizationsOrganizationSearchResponse struct {
	PitID string                        `json:"pit_id"`
	Hits  OrganizationsOrganizationHits `json:"hits"`
}

type OrganizationsOrganizationPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewOrganizationsOrganizationPaginator(filters []BoolFilter, limit *int64) (OrganizationsOrganizationPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_organizations_organization", filters, limit)
	if err != nil {
		return OrganizationsOrganizationPaginator{}, err
	}

	p := OrganizationsOrganizationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p OrganizationsOrganizationPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p OrganizationsOrganizationPaginator) NextPage(ctx context.Context) ([]OrganizationsOrganization, error) {
	var response OrganizationsOrganizationSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []OrganizationsOrganization
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listOrganizationsOrganizationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListOrganizationsOrganization(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListOrganizationsOrganization")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewOrganizationsOrganizationPaginator(buildFilter(d.KeyColumnQuals, listOrganizationsOrganizationFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getOrganizationsOrganizationFilters = map[string]string{
	"id":               "description.Organization.Id",
	"keibi_account_id": "metadata.SourceID",
}

func GetOrganizationsOrganization(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetOrganizationsOrganization")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewOrganizationsOrganizationPaginator(buildFilter(d.KeyColumnQuals, getOrganizationsOrganizationFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: OrganizationsOrganization =============================

// ==========================  START: ACMPCACertificateAuthority =============================

type ACMPCACertificateAuthority struct {
	Description   aws.ACMPCACertificateAuthorityDescription `json:"description"`
	Metadata      aws.Metadata                              `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

type ACMPCACertificateAuthorityHit struct {
	ID      string                     `json:"_id"`
	Score   float64                    `json:"_score"`
	Index   string                     `json:"_index"`
	Type    string                     `json:"_type"`
	Version int64                      `json:"_version,omitempty"`
	Source  ACMPCACertificateAuthority `json:"_source"`
	Sort    []interface{}              `json:"sort"`
}

type ACMPCACertificateAuthorityHits struct {
	Total SearchTotal                     `json:"total"`
	Hits  []ACMPCACertificateAuthorityHit `json:"hits"`
}

type ACMPCACertificateAuthoritySearchResponse struct {
	PitID string                         `json:"pit_id"`
	Hits  ACMPCACertificateAuthorityHits `json:"hits"`
}

type ACMPCACertificateAuthorityPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewACMPCACertificateAuthorityPaginator(filters []BoolFilter, limit *int64) (ACMPCACertificateAuthorityPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_acmpca_certificateauthority", filters, limit)
	if err != nil {
		return ACMPCACertificateAuthorityPaginator{}, err
	}

	p := ACMPCACertificateAuthorityPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ACMPCACertificateAuthorityPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ACMPCACertificateAuthorityPaginator) NextPage(ctx context.Context) ([]ACMPCACertificateAuthority, error) {
	var response ACMPCACertificateAuthoritySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ACMPCACertificateAuthority
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listACMPCACertificateAuthorityFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListACMPCACertificateAuthority(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListACMPCACertificateAuthority")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewACMPCACertificateAuthorityPaginator(buildFilter(d.KeyColumnQuals, listACMPCACertificateAuthorityFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getACMPCACertificateAuthorityFilters = map[string]string{
	"arn":              "description.CertificateAuthority.Arn",
	"keibi_account_id": "metadata.SourceID",
}

func GetACMPCACertificateAuthority(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetACMPCACertificateAuthority")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewACMPCACertificateAuthorityPaginator(buildFilter(d.KeyColumnQuals, getACMPCACertificateAuthorityFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ACMPCACertificateAuthority =============================

// ==========================  START: ShieldProtectionGroup =============================

type ShieldProtectionGroup struct {
	Description   aws.ShieldProtectionGroupDescription `json:"description"`
	Metadata      aws.Metadata                         `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

type ShieldProtectionGroupHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  ShieldProtectionGroup `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type ShieldProtectionGroupHits struct {
	Total SearchTotal                `json:"total"`
	Hits  []ShieldProtectionGroupHit `json:"hits"`
}

type ShieldProtectionGroupSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  ShieldProtectionGroupHits `json:"hits"`
}

type ShieldProtectionGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewShieldProtectionGroupPaginator(filters []BoolFilter, limit *int64) (ShieldProtectionGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_shield_protectiongroup", filters, limit)
	if err != nil {
		return ShieldProtectionGroupPaginator{}, err
	}

	p := ShieldProtectionGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ShieldProtectionGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ShieldProtectionGroupPaginator) NextPage(ctx context.Context) ([]ShieldProtectionGroup, error) {
	var response ShieldProtectionGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ShieldProtectionGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listShieldProtectionGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListShieldProtectionGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListShieldProtectionGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewShieldProtectionGroupPaginator(buildFilter(d.KeyColumnQuals, listShieldProtectionGroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getShieldProtectionGroupFilters = map[string]string{
	"keibi_account_id":    "metadata.SourceID",
	"protection_group_id": "description.ProtectionGroup.ProtectionGroupId",
}

func GetShieldProtectionGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetShieldProtectionGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewShieldProtectionGroupPaginator(buildFilter(d.KeyColumnQuals, getShieldProtectionGroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ShieldProtectionGroup =============================

// ==========================  START: StorageGatewayStorageGateway =============================

type StorageGatewayStorageGateway struct {
	Description   aws.StorageGatewayStorageGatewayDescription `json:"description"`
	Metadata      aws.Metadata                                `json:"metadata"`
	ResourceJobID int                                         `json:"resource_job_id"`
	SourceJobID   int                                         `json:"source_job_id"`
	ResourceType  string                                      `json:"resource_type"`
	SourceType    string                                      `json:"source_type"`
	ID            string                                      `json:"id"`
	ARN           string                                      `json:"arn"`
	SourceID      string                                      `json:"source_id"`
}

type StorageGatewayStorageGatewayHit struct {
	ID      string                       `json:"_id"`
	Score   float64                      `json:"_score"`
	Index   string                       `json:"_index"`
	Type    string                       `json:"_type"`
	Version int64                        `json:"_version,omitempty"`
	Source  StorageGatewayStorageGateway `json:"_source"`
	Sort    []interface{}                `json:"sort"`
}

type StorageGatewayStorageGatewayHits struct {
	Total SearchTotal                       `json:"total"`
	Hits  []StorageGatewayStorageGatewayHit `json:"hits"`
}

type StorageGatewayStorageGatewaySearchResponse struct {
	PitID string                           `json:"pit_id"`
	Hits  StorageGatewayStorageGatewayHits `json:"hits"`
}

type StorageGatewayStorageGatewayPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewStorageGatewayStorageGatewayPaginator(filters []BoolFilter, limit *int64) (StorageGatewayStorageGatewayPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_storagegateway_storagegateway", filters, limit)
	if err != nil {
		return StorageGatewayStorageGatewayPaginator{}, err
	}

	p := StorageGatewayStorageGatewayPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p StorageGatewayStorageGatewayPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p StorageGatewayStorageGatewayPaginator) NextPage(ctx context.Context) ([]StorageGatewayStorageGateway, error) {
	var response StorageGatewayStorageGatewaySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []StorageGatewayStorageGateway
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listStorageGatewayStorageGatewayFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListStorageGatewayStorageGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListStorageGatewayStorageGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewStorageGatewayStorageGatewayPaginator(buildFilter(d.KeyColumnQuals, listStorageGatewayStorageGatewayFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getStorageGatewayStorageGatewayFilters = map[string]string{
	"gateway_id":       "description.StorageGateway.GatewayId",
	"keibi_account_id": "metadata.SourceID",
}

func GetStorageGatewayStorageGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetStorageGatewayStorageGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewStorageGatewayStorageGatewayPaginator(buildFilter(d.KeyColumnQuals, getStorageGatewayStorageGatewayFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: StorageGatewayStorageGateway =============================

// ==========================  START: ImageBuilderImage =============================

type ImageBuilderImage struct {
	Description   aws.ImageBuilderImageDescription `json:"description"`
	Metadata      aws.Metadata                     `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

type ImageBuilderImageHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  ImageBuilderImage `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type ImageBuilderImageHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []ImageBuilderImageHit `json:"hits"`
}

type ImageBuilderImageSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  ImageBuilderImageHits `json:"hits"`
}

type ImageBuilderImagePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewImageBuilderImagePaginator(filters []BoolFilter, limit *int64) (ImageBuilderImagePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_imagebuilder_image", filters, limit)
	if err != nil {
		return ImageBuilderImagePaginator{}, err
	}

	p := ImageBuilderImagePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ImageBuilderImagePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ImageBuilderImagePaginator) NextPage(ctx context.Context) ([]ImageBuilderImage, error) {
	var response ImageBuilderImageSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ImageBuilderImage
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listImageBuilderImageFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListImageBuilderImage(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListImageBuilderImage")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewImageBuilderImagePaginator(buildFilter(d.KeyColumnQuals, listImageBuilderImageFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getImageBuilderImageFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Image.Name",
}

func GetImageBuilderImage(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetImageBuilderImage")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewImageBuilderImagePaginator(buildFilter(d.KeyColumnQuals, getImageBuilderImageFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ImageBuilderImage =============================

// ==========================  START: AccountAlternateContact =============================

type AccountAlternateContact struct {
	Description   aws.AccountAlternateContactDescription `json:"description"`
	Metadata      aws.Metadata                           `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

type AccountAlternateContactHit struct {
	ID      string                  `json:"_id"`
	Score   float64                 `json:"_score"`
	Index   string                  `json:"_index"`
	Type    string                  `json:"_type"`
	Version int64                   `json:"_version,omitempty"`
	Source  AccountAlternateContact `json:"_source"`
	Sort    []interface{}           `json:"sort"`
}

type AccountAlternateContactHits struct {
	Total SearchTotal                  `json:"total"`
	Hits  []AccountAlternateContactHit `json:"hits"`
}

type AccountAlternateContactSearchResponse struct {
	PitID string                      `json:"pit_id"`
	Hits  AccountAlternateContactHits `json:"hits"`
}

type AccountAlternateContactPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAccountAlternateContactPaginator(filters []BoolFilter, limit *int64) (AccountAlternateContactPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_account_alternatecontact", filters, limit)
	if err != nil {
		return AccountAlternateContactPaginator{}, err
	}

	p := AccountAlternateContactPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AccountAlternateContactPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AccountAlternateContactPaginator) NextPage(ctx context.Context) ([]AccountAlternateContact, error) {
	var response AccountAlternateContactSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AccountAlternateContact
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAccountAlternateContactFilters = map[string]string{
	"contact_type":      "description.AlternateContact.AlternateContactType",
	"keibi_account_id":  "metadata.SourceID",
	"linked_account_id": "description.LinkedAccountID",
}

func ListAccountAlternateContact(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAccountAlternateContact")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAccountAlternateContactPaginator(buildFilter(d.KeyColumnQuals, listAccountAlternateContactFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAccountAlternateContactFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetAccountAlternateContact(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAccountAlternateContact")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAccountAlternateContactPaginator(buildFilter(d.KeyColumnQuals, getAccountAlternateContactFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AccountAlternateContact =============================

// ==========================  START: AccountContact =============================

type AccountContact struct {
	Description   aws.AccountContactDescription `json:"description"`
	Metadata      aws.Metadata                  `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

type AccountContactHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  AccountContact `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type AccountContactHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []AccountContactHit `json:"hits"`
}

type AccountContactSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  AccountContactHits `json:"hits"`
}

type AccountContactPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAccountContactPaginator(filters []BoolFilter, limit *int64) (AccountContactPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_account_contact", filters, limit)
	if err != nil {
		return AccountContactPaginator{}, err
	}

	p := AccountContactPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AccountContactPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AccountContactPaginator) NextPage(ctx context.Context) ([]AccountContact, error) {
	var response AccountContactSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AccountContact
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAccountContactFilters = map[string]string{
	"keibi_account_id":  "metadata.SourceID",
	"linked_account_id": "description.LinkedAccountID",
}

func ListAccountContact(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAccountContact")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAccountContactPaginator(buildFilter(d.KeyColumnQuals, listAccountContactFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAccountContactFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetAccountContact(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAccountContact")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAccountContactPaginator(buildFilter(d.KeyColumnQuals, getAccountContactFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AccountContact =============================

// ==========================  START: AmplifyApp =============================

type AmplifyApp struct {
	Description   aws.AmplifyAppDescription `json:"description"`
	Metadata      aws.Metadata              `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	ARN           string                    `json:"arn"`
	SourceID      string                    `json:"source_id"`
}

type AmplifyAppHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  AmplifyApp    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type AmplifyAppHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []AmplifyAppHit `json:"hits"`
}

type AmplifyAppSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  AmplifyAppHits `json:"hits"`
}

type AmplifyAppPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAmplifyAppPaginator(filters []BoolFilter, limit *int64) (AmplifyAppPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_amplify_app", filters, limit)
	if err != nil {
		return AmplifyAppPaginator{}, err
	}

	p := AmplifyAppPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AmplifyAppPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AmplifyAppPaginator) NextPage(ctx context.Context) ([]AmplifyApp, error) {
	var response AmplifyAppSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AmplifyApp
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAmplifyAppFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListAmplifyApp(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAmplifyApp")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAmplifyAppPaginator(buildFilter(d.KeyColumnQuals, listAmplifyAppFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAmplifyAppFilters = map[string]string{
	"app_id":           "description.App.AppId",
	"keibi_account_id": "metadata.SourceID",
}

func GetAmplifyApp(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAmplifyApp")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAmplifyAppPaginator(buildFilter(d.KeyColumnQuals, getAmplifyAppFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AmplifyApp =============================

// ==========================  START: AppConfigApplication =============================

type AppConfigApplication struct {
	Description   aws.AppConfigApplicationDescription `json:"description"`
	Metadata      aws.Metadata                        `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type AppConfigApplicationHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  AppConfigApplication `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type AppConfigApplicationHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []AppConfigApplicationHit `json:"hits"`
}

type AppConfigApplicationSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  AppConfigApplicationHits `json:"hits"`
}

type AppConfigApplicationPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAppConfigApplicationPaginator(filters []BoolFilter, limit *int64) (AppConfigApplicationPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_appconfig_application", filters, limit)
	if err != nil {
		return AppConfigApplicationPaginator{}, err
	}

	p := AppConfigApplicationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AppConfigApplicationPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AppConfigApplicationPaginator) NextPage(ctx context.Context) ([]AppConfigApplication, error) {
	var response AppConfigApplicationSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AppConfigApplication
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAppConfigApplicationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListAppConfigApplication(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAppConfigApplication")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAppConfigApplicationPaginator(buildFilter(d.KeyColumnQuals, listAppConfigApplicationFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAppConfigApplicationFilters = map[string]string{
	"id":               "description.Application.Id",
	"keibi_account_id": "metadata.SourceID",
}

func GetAppConfigApplication(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAppConfigApplication")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAppConfigApplicationPaginator(buildFilter(d.KeyColumnQuals, getAppConfigApplicationFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AppConfigApplication =============================

// ==========================  START: AuditManagerAssessment =============================

type AuditManagerAssessment struct {
	Description   aws.AuditManagerAssessmentDescription `json:"description"`
	Metadata      aws.Metadata                          `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

type AuditManagerAssessmentHit struct {
	ID      string                 `json:"_id"`
	Score   float64                `json:"_score"`
	Index   string                 `json:"_index"`
	Type    string                 `json:"_type"`
	Version int64                  `json:"_version,omitempty"`
	Source  AuditManagerAssessment `json:"_source"`
	Sort    []interface{}          `json:"sort"`
}

type AuditManagerAssessmentHits struct {
	Total SearchTotal                 `json:"total"`
	Hits  []AuditManagerAssessmentHit `json:"hits"`
}

type AuditManagerAssessmentSearchResponse struct {
	PitID string                     `json:"pit_id"`
	Hits  AuditManagerAssessmentHits `json:"hits"`
}

type AuditManagerAssessmentPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAuditManagerAssessmentPaginator(filters []BoolFilter, limit *int64) (AuditManagerAssessmentPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_auditmanager_assessment", filters, limit)
	if err != nil {
		return AuditManagerAssessmentPaginator{}, err
	}

	p := AuditManagerAssessmentPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AuditManagerAssessmentPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AuditManagerAssessmentPaginator) NextPage(ctx context.Context) ([]AuditManagerAssessment, error) {
	var response AuditManagerAssessmentSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AuditManagerAssessment
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAuditManagerAssessmentFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListAuditManagerAssessment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAuditManagerAssessment")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAuditManagerAssessmentPaginator(buildFilter(d.KeyColumnQuals, listAuditManagerAssessmentFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAuditManagerAssessmentFilters = map[string]string{
	"assessment_id":    "description.Assessment.Metadata.Id",
	"keibi_account_id": "metadata.SourceID",
}

func GetAuditManagerAssessment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAuditManagerAssessment")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAuditManagerAssessmentPaginator(buildFilter(d.KeyColumnQuals, getAuditManagerAssessmentFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AuditManagerAssessment =============================

// ==========================  START: AuditManagerControl =============================

type AuditManagerControl struct {
	Description   aws.AuditManagerControlDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type AuditManagerControlHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  AuditManagerControl `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type AuditManagerControlHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []AuditManagerControlHit `json:"hits"`
}

type AuditManagerControlSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  AuditManagerControlHits `json:"hits"`
}

type AuditManagerControlPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAuditManagerControlPaginator(filters []BoolFilter, limit *int64) (AuditManagerControlPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_auditmanager_control", filters, limit)
	if err != nil {
		return AuditManagerControlPaginator{}, err
	}

	p := AuditManagerControlPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AuditManagerControlPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AuditManagerControlPaginator) NextPage(ctx context.Context) ([]AuditManagerControl, error) {
	var response AuditManagerControlSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AuditManagerControl
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAuditManagerControlFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListAuditManagerControl(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAuditManagerControl")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAuditManagerControlPaginator(buildFilter(d.KeyColumnQuals, listAuditManagerControlFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAuditManagerControlFilters = map[string]string{
	"control_id":       "description.Control.Id",
	"keibi_account_id": "metadata.SourceID",
}

func GetAuditManagerControl(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAuditManagerControl")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAuditManagerControlPaginator(buildFilter(d.KeyColumnQuals, getAuditManagerControlFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AuditManagerControl =============================

// ==========================  START: AuditManagerEvidence =============================

type AuditManagerEvidence struct {
	Description   aws.AuditManagerEvidenceDescription `json:"description"`
	Metadata      aws.Metadata                        `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type AuditManagerEvidenceHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  AuditManagerEvidence `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type AuditManagerEvidenceHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []AuditManagerEvidenceHit `json:"hits"`
}

type AuditManagerEvidenceSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  AuditManagerEvidenceHits `json:"hits"`
}

type AuditManagerEvidencePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAuditManagerEvidencePaginator(filters []BoolFilter, limit *int64) (AuditManagerEvidencePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_auditmanager_evidence", filters, limit)
	if err != nil {
		return AuditManagerEvidencePaginator{}, err
	}

	p := AuditManagerEvidencePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AuditManagerEvidencePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AuditManagerEvidencePaginator) NextPage(ctx context.Context) ([]AuditManagerEvidence, error) {
	var response AuditManagerEvidenceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AuditManagerEvidence
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAuditManagerEvidenceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListAuditManagerEvidence(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAuditManagerEvidence")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAuditManagerEvidencePaginator(buildFilter(d.KeyColumnQuals, listAuditManagerEvidenceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAuditManagerEvidenceFilters = map[string]string{
	"assessment_id":      "description.AssessmentID",
	"control_set_id":     "description.ControlSetID",
	"evidence_folder_id": "description.Evidence.EvidenceFolderId",
	"id":                 "description.Evidence.Id",
	"keibi_account_id":   "metadata.SourceID",
}

func GetAuditManagerEvidence(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAuditManagerEvidence")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAuditManagerEvidencePaginator(buildFilter(d.KeyColumnQuals, getAuditManagerEvidenceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AuditManagerEvidence =============================

// ==========================  START: AuditManagerEvidenceFolder =============================

type AuditManagerEvidenceFolder struct {
	Description   aws.AuditManagerEvidenceFolderDescription `json:"description"`
	Metadata      aws.Metadata                              `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

type AuditManagerEvidenceFolderHit struct {
	ID      string                     `json:"_id"`
	Score   float64                    `json:"_score"`
	Index   string                     `json:"_index"`
	Type    string                     `json:"_type"`
	Version int64                      `json:"_version,omitempty"`
	Source  AuditManagerEvidenceFolder `json:"_source"`
	Sort    []interface{}              `json:"sort"`
}

type AuditManagerEvidenceFolderHits struct {
	Total SearchTotal                     `json:"total"`
	Hits  []AuditManagerEvidenceFolderHit `json:"hits"`
}

type AuditManagerEvidenceFolderSearchResponse struct {
	PitID string                         `json:"pit_id"`
	Hits  AuditManagerEvidenceFolderHits `json:"hits"`
}

type AuditManagerEvidenceFolderPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAuditManagerEvidenceFolderPaginator(filters []BoolFilter, limit *int64) (AuditManagerEvidenceFolderPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_auditmanager_evidencefolder", filters, limit)
	if err != nil {
		return AuditManagerEvidenceFolderPaginator{}, err
	}

	p := AuditManagerEvidenceFolderPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AuditManagerEvidenceFolderPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AuditManagerEvidenceFolderPaginator) NextPage(ctx context.Context) ([]AuditManagerEvidenceFolder, error) {
	var response AuditManagerEvidenceFolderSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AuditManagerEvidenceFolder
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAuditManagerEvidenceFolderFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListAuditManagerEvidenceFolder(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAuditManagerEvidenceFolder")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAuditManagerEvidenceFolderPaginator(buildFilter(d.KeyColumnQuals, listAuditManagerEvidenceFolderFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAuditManagerEvidenceFolderFilters = map[string]string{
	"assessment_id":    "description.AssessmentID",
	"control_set_id":   "description.ControlSetID",
	"id":               "description.EvidenceFolder.Id",
	"keibi_account_id": "metadata.SourceID",
}

func GetAuditManagerEvidenceFolder(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAuditManagerEvidenceFolder")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAuditManagerEvidenceFolderPaginator(buildFilter(d.KeyColumnQuals, getAuditManagerEvidenceFolderFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AuditManagerEvidenceFolder =============================

// ==========================  START: AuditManagerFramework =============================

type AuditManagerFramework struct {
	Description   aws.AuditManagerFrameworkDescription `json:"description"`
	Metadata      aws.Metadata                         `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

type AuditManagerFrameworkHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  AuditManagerFramework `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type AuditManagerFrameworkHits struct {
	Total SearchTotal                `json:"total"`
	Hits  []AuditManagerFrameworkHit `json:"hits"`
}

type AuditManagerFrameworkSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  AuditManagerFrameworkHits `json:"hits"`
}

type AuditManagerFrameworkPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAuditManagerFrameworkPaginator(filters []BoolFilter, limit *int64) (AuditManagerFrameworkPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_auditmanager_framework", filters, limit)
	if err != nil {
		return AuditManagerFrameworkPaginator{}, err
	}

	p := AuditManagerFrameworkPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AuditManagerFrameworkPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AuditManagerFrameworkPaginator) NextPage(ctx context.Context) ([]AuditManagerFramework, error) {
	var response AuditManagerFrameworkSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AuditManagerFramework
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAuditManagerFrameworkFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListAuditManagerFramework(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAuditManagerFramework")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAuditManagerFrameworkPaginator(buildFilter(d.KeyColumnQuals, listAuditManagerFrameworkFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAuditManagerFrameworkFilters = map[string]string{
	"id":               "description.Framework.Id",
	"keibi_account_id": "metadata.SourceID",
	"region":           "metadata.Region",
}

func GetAuditManagerFramework(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAuditManagerFramework")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAuditManagerFrameworkPaginator(buildFilter(d.KeyColumnQuals, getAuditManagerFrameworkFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AuditManagerFramework =============================

// ==========================  START: CloudControlResource =============================

type CloudControlResource struct {
	Description   aws.CloudControlResourceDescription `json:"description"`
	Metadata      aws.Metadata                        `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type CloudControlResourceHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  CloudControlResource `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type CloudControlResourceHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []CloudControlResourceHit `json:"hits"`
}

type CloudControlResourceSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  CloudControlResourceHits `json:"hits"`
}

type CloudControlResourcePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudControlResourcePaginator(filters []BoolFilter, limit *int64) (CloudControlResourcePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudcontrol_resource", filters, limit)
	if err != nil {
		return CloudControlResourcePaginator{}, err
	}

	p := CloudControlResourcePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudControlResourcePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudControlResourcePaginator) NextPage(ctx context.Context) ([]CloudControlResource, error) {
	var response CloudControlResourceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudControlResource
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudControlResourceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCloudControlResource(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudControlResource")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudControlResourcePaginator(buildFilter(d.KeyColumnQuals, listCloudControlResourceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudControlResourceFilters = map[string]string{
	"identifier":       "description.Resource.Identifier",
	"keibi_account_id": "metadata.SourceID",
}

func GetCloudControlResource(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudControlResource")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudControlResourcePaginator(buildFilter(d.KeyColumnQuals, getCloudControlResourceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudControlResource =============================

// ==========================  START: CloudSearchDomain =============================

type CloudSearchDomain struct {
	Description   aws.CloudSearchDomainDescription `json:"description"`
	Metadata      aws.Metadata                     `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

type CloudSearchDomainHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  CloudSearchDomain `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type CloudSearchDomainHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []CloudSearchDomainHit `json:"hits"`
}

type CloudSearchDomainSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  CloudSearchDomainHits `json:"hits"`
}

type CloudSearchDomainPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudSearchDomainPaginator(filters []BoolFilter, limit *int64) (CloudSearchDomainPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudsearch_domain", filters, limit)
	if err != nil {
		return CloudSearchDomainPaginator{}, err
	}

	p := CloudSearchDomainPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudSearchDomainPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudSearchDomainPaginator) NextPage(ctx context.Context) ([]CloudSearchDomain, error) {
	var response CloudSearchDomainSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudSearchDomain
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudSearchDomainFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCloudSearchDomain(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudSearchDomain")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudSearchDomainPaginator(buildFilter(d.KeyColumnQuals, listCloudSearchDomainFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudSearchDomainFilters = map[string]string{
	"domain_name":      "description.DomainStatus.DomainName",
	"keibi_account_id": "metadata.SourceID",
}

func GetCloudSearchDomain(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudSearchDomain")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudSearchDomainPaginator(buildFilter(d.KeyColumnQuals, getCloudSearchDomainFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudSearchDomain =============================

// ==========================  START: DLMLifecyclePolicy =============================

type DLMLifecyclePolicy struct {
	Description   aws.DLMLifecyclePolicyDescription `json:"description"`
	Metadata      aws.Metadata                      `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

type DLMLifecyclePolicyHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  DLMLifecyclePolicy `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type DLMLifecyclePolicyHits struct {
	Total SearchTotal             `json:"total"`
	Hits  []DLMLifecyclePolicyHit `json:"hits"`
}

type DLMLifecyclePolicySearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  DLMLifecyclePolicyHits `json:"hits"`
}

type DLMLifecyclePolicyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDLMLifecyclePolicyPaginator(filters []BoolFilter, limit *int64) (DLMLifecyclePolicyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_dlm_lifecyclepolicy", filters, limit)
	if err != nil {
		return DLMLifecyclePolicyPaginator{}, err
	}

	p := DLMLifecyclePolicyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DLMLifecyclePolicyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DLMLifecyclePolicyPaginator) NextPage(ctx context.Context) ([]DLMLifecyclePolicy, error) {
	var response DLMLifecyclePolicySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DLMLifecyclePolicy
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDLMLifecyclePolicyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListDLMLifecyclePolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDLMLifecyclePolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDLMLifecyclePolicyPaginator(buildFilter(d.KeyColumnQuals, listDLMLifecyclePolicyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDLMLifecyclePolicyFilters = map[string]string{
	"id":               "description.LifecyclePolicy.PolicyId",
	"keibi_account_id": "metadata.SourceID",
}

func GetDLMLifecyclePolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDLMLifecyclePolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDLMLifecyclePolicyPaginator(buildFilter(d.KeyColumnQuals, getDLMLifecyclePolicyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DLMLifecyclePolicy =============================

// ==========================  START: DocDBCluster =============================

type DocDBCluster struct {
	Description   aws.DocDBClusterDescription `json:"description"`
	Metadata      aws.Metadata                `json:"metadata"`
	ResourceJobID int                         `json:"resource_job_id"`
	SourceJobID   int                         `json:"source_job_id"`
	ResourceType  string                      `json:"resource_type"`
	SourceType    string                      `json:"source_type"`
	ID            string                      `json:"id"`
	ARN           string                      `json:"arn"`
	SourceID      string                      `json:"source_id"`
}

type DocDBClusterHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  DocDBCluster  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type DocDBClusterHits struct {
	Total SearchTotal       `json:"total"`
	Hits  []DocDBClusterHit `json:"hits"`
}

type DocDBClusterSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  DocDBClusterHits `json:"hits"`
}

type DocDBClusterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDocDBClusterPaginator(filters []BoolFilter, limit *int64) (DocDBClusterPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_docdb_cluster", filters, limit)
	if err != nil {
		return DocDBClusterPaginator{}, err
	}

	p := DocDBClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DocDBClusterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DocDBClusterPaginator) NextPage(ctx context.Context) ([]DocDBCluster, error) {
	var response DocDBClusterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DocDBCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDocDBClusterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListDocDBCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDocDBCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDocDBClusterPaginator(buildFilter(d.KeyColumnQuals, listDocDBClusterFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDocDBClusterFilters = map[string]string{
	"db_cluster_identifier": "description.DBCluster.DBClusterIdentifier",
	"keibi_account_id":      "metadata.SourceID",
}

func GetDocDBCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDocDBCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDocDBClusterPaginator(buildFilter(d.KeyColumnQuals, getDocDBClusterFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DocDBCluster =============================

// ==========================  START: GlobalAcceleratorAccelerator =============================

type GlobalAcceleratorAccelerator struct {
	Description   aws.GlobalAcceleratorAcceleratorDescription `json:"description"`
	Metadata      aws.Metadata                                `json:"metadata"`
	ResourceJobID int                                         `json:"resource_job_id"`
	SourceJobID   int                                         `json:"source_job_id"`
	ResourceType  string                                      `json:"resource_type"`
	SourceType    string                                      `json:"source_type"`
	ID            string                                      `json:"id"`
	ARN           string                                      `json:"arn"`
	SourceID      string                                      `json:"source_id"`
}

type GlobalAcceleratorAcceleratorHit struct {
	ID      string                       `json:"_id"`
	Score   float64                      `json:"_score"`
	Index   string                       `json:"_index"`
	Type    string                       `json:"_type"`
	Version int64                        `json:"_version,omitempty"`
	Source  GlobalAcceleratorAccelerator `json:"_source"`
	Sort    []interface{}                `json:"sort"`
}

type GlobalAcceleratorAcceleratorHits struct {
	Total SearchTotal                       `json:"total"`
	Hits  []GlobalAcceleratorAcceleratorHit `json:"hits"`
}

type GlobalAcceleratorAcceleratorSearchResponse struct {
	PitID string                           `json:"pit_id"`
	Hits  GlobalAcceleratorAcceleratorHits `json:"hits"`
}

type GlobalAcceleratorAcceleratorPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewGlobalAcceleratorAcceleratorPaginator(filters []BoolFilter, limit *int64) (GlobalAcceleratorAcceleratorPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_globalaccelerator_accelerator", filters, limit)
	if err != nil {
		return GlobalAcceleratorAcceleratorPaginator{}, err
	}

	p := GlobalAcceleratorAcceleratorPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p GlobalAcceleratorAcceleratorPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p GlobalAcceleratorAcceleratorPaginator) NextPage(ctx context.Context) ([]GlobalAcceleratorAccelerator, error) {
	var response GlobalAcceleratorAcceleratorSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []GlobalAcceleratorAccelerator
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listGlobalAcceleratorAcceleratorFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListGlobalAcceleratorAccelerator(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListGlobalAcceleratorAccelerator")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewGlobalAcceleratorAcceleratorPaginator(buildFilter(d.KeyColumnQuals, listGlobalAcceleratorAcceleratorFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getGlobalAcceleratorAcceleratorFilters = map[string]string{
	"arn":              "description.Accelerator.AcceleratorArn",
	"keibi_account_id": "metadata.SourceID",
}

func GetGlobalAcceleratorAccelerator(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetGlobalAcceleratorAccelerator")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewGlobalAcceleratorAcceleratorPaginator(buildFilter(d.KeyColumnQuals, getGlobalAcceleratorAcceleratorFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: GlobalAcceleratorAccelerator =============================

// ==========================  START: GlobalAcceleratorEndpointGroup =============================

type GlobalAcceleratorEndpointGroup struct {
	Description   aws.GlobalAcceleratorEndpointGroupDescription `json:"description"`
	Metadata      aws.Metadata                                  `json:"metadata"`
	ResourceJobID int                                           `json:"resource_job_id"`
	SourceJobID   int                                           `json:"source_job_id"`
	ResourceType  string                                        `json:"resource_type"`
	SourceType    string                                        `json:"source_type"`
	ID            string                                        `json:"id"`
	ARN           string                                        `json:"arn"`
	SourceID      string                                        `json:"source_id"`
}

type GlobalAcceleratorEndpointGroupHit struct {
	ID      string                         `json:"_id"`
	Score   float64                        `json:"_score"`
	Index   string                         `json:"_index"`
	Type    string                         `json:"_type"`
	Version int64                          `json:"_version,omitempty"`
	Source  GlobalAcceleratorEndpointGroup `json:"_source"`
	Sort    []interface{}                  `json:"sort"`
}

type GlobalAcceleratorEndpointGroupHits struct {
	Total SearchTotal                         `json:"total"`
	Hits  []GlobalAcceleratorEndpointGroupHit `json:"hits"`
}

type GlobalAcceleratorEndpointGroupSearchResponse struct {
	PitID string                             `json:"pit_id"`
	Hits  GlobalAcceleratorEndpointGroupHits `json:"hits"`
}

type GlobalAcceleratorEndpointGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewGlobalAcceleratorEndpointGroupPaginator(filters []BoolFilter, limit *int64) (GlobalAcceleratorEndpointGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_globalaccelerator_endpointgroup", filters, limit)
	if err != nil {
		return GlobalAcceleratorEndpointGroupPaginator{}, err
	}

	p := GlobalAcceleratorEndpointGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p GlobalAcceleratorEndpointGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p GlobalAcceleratorEndpointGroupPaginator) NextPage(ctx context.Context) ([]GlobalAcceleratorEndpointGroup, error) {
	var response GlobalAcceleratorEndpointGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []GlobalAcceleratorEndpointGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listGlobalAcceleratorEndpointGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"listener_arn":     "description.ListenerArn",
}

func ListGlobalAcceleratorEndpointGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListGlobalAcceleratorEndpointGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewGlobalAcceleratorEndpointGroupPaginator(buildFilter(d.KeyColumnQuals, listGlobalAcceleratorEndpointGroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getGlobalAcceleratorEndpointGroupFilters = map[string]string{
	"arn":              "description.EndpointGroup.EndpointGroupArn",
	"keibi_account_id": "metadata.SourceID",
}

func GetGlobalAcceleratorEndpointGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetGlobalAcceleratorEndpointGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewGlobalAcceleratorEndpointGroupPaginator(buildFilter(d.KeyColumnQuals, getGlobalAcceleratorEndpointGroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: GlobalAcceleratorEndpointGroup =============================

// ==========================  START: GlobalAcceleratorListener =============================

type GlobalAcceleratorListener struct {
	Description   aws.GlobalAcceleratorListenerDescription `json:"description"`
	Metadata      aws.Metadata                             `json:"metadata"`
	ResourceJobID int                                      `json:"resource_job_id"`
	SourceJobID   int                                      `json:"source_job_id"`
	ResourceType  string                                   `json:"resource_type"`
	SourceType    string                                   `json:"source_type"`
	ID            string                                   `json:"id"`
	ARN           string                                   `json:"arn"`
	SourceID      string                                   `json:"source_id"`
}

type GlobalAcceleratorListenerHit struct {
	ID      string                    `json:"_id"`
	Score   float64                   `json:"_score"`
	Index   string                    `json:"_index"`
	Type    string                    `json:"_type"`
	Version int64                     `json:"_version,omitempty"`
	Source  GlobalAcceleratorListener `json:"_source"`
	Sort    []interface{}             `json:"sort"`
}

type GlobalAcceleratorListenerHits struct {
	Total SearchTotal                    `json:"total"`
	Hits  []GlobalAcceleratorListenerHit `json:"hits"`
}

type GlobalAcceleratorListenerSearchResponse struct {
	PitID string                        `json:"pit_id"`
	Hits  GlobalAcceleratorListenerHits `json:"hits"`
}

type GlobalAcceleratorListenerPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewGlobalAcceleratorListenerPaginator(filters []BoolFilter, limit *int64) (GlobalAcceleratorListenerPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_globalaccelerator_listener", filters, limit)
	if err != nil {
		return GlobalAcceleratorListenerPaginator{}, err
	}

	p := GlobalAcceleratorListenerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p GlobalAcceleratorListenerPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p GlobalAcceleratorListenerPaginator) NextPage(ctx context.Context) ([]GlobalAcceleratorListener, error) {
	var response GlobalAcceleratorListenerSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []GlobalAcceleratorListener
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listGlobalAcceleratorListenerFilters = map[string]string{
	"accelerator_arn":  "description.AcceleratorArn",
	"keibi_account_id": "metadata.SourceID",
}

func ListGlobalAcceleratorListener(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListGlobalAcceleratorListener")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewGlobalAcceleratorListenerPaginator(buildFilter(d.KeyColumnQuals, listGlobalAcceleratorListenerFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getGlobalAcceleratorListenerFilters = map[string]string{
	"arn":              "description.Listener.ListenerArn",
	"keibi_account_id": "metadata.SourceID",
}

func GetGlobalAcceleratorListener(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetGlobalAcceleratorListener")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewGlobalAcceleratorListenerPaginator(buildFilter(d.KeyColumnQuals, getGlobalAcceleratorListenerFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: GlobalAcceleratorListener =============================

// ==========================  START: GlueCatalogDatabase =============================

type GlueCatalogDatabase struct {
	Description   aws.GlueCatalogDatabaseDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type GlueCatalogDatabaseHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  GlueCatalogDatabase `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type GlueCatalogDatabaseHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []GlueCatalogDatabaseHit `json:"hits"`
}

type GlueCatalogDatabaseSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  GlueCatalogDatabaseHits `json:"hits"`
}

type GlueCatalogDatabasePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewGlueCatalogDatabasePaginator(filters []BoolFilter, limit *int64) (GlueCatalogDatabasePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_glue_catalogdatabase", filters, limit)
	if err != nil {
		return GlueCatalogDatabasePaginator{}, err
	}

	p := GlueCatalogDatabasePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p GlueCatalogDatabasePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p GlueCatalogDatabasePaginator) NextPage(ctx context.Context) ([]GlueCatalogDatabase, error) {
	var response GlueCatalogDatabaseSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []GlueCatalogDatabase
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listGlueCatalogDatabaseFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListGlueCatalogDatabase(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListGlueCatalogDatabase")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewGlueCatalogDatabasePaginator(buildFilter(d.KeyColumnQuals, listGlueCatalogDatabaseFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getGlueCatalogDatabaseFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Database.Name",
}

func GetGlueCatalogDatabase(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetGlueCatalogDatabase")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewGlueCatalogDatabasePaginator(buildFilter(d.KeyColumnQuals, getGlueCatalogDatabaseFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: GlueCatalogDatabase =============================

// ==========================  START: GlueCatalogTable =============================

type GlueCatalogTable struct {
	Description   aws.GlueCatalogTableDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type GlueCatalogTableHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  GlueCatalogTable `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type GlueCatalogTableHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []GlueCatalogTableHit `json:"hits"`
}

type GlueCatalogTableSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  GlueCatalogTableHits `json:"hits"`
}

type GlueCatalogTablePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewGlueCatalogTablePaginator(filters []BoolFilter, limit *int64) (GlueCatalogTablePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_glue_catalogtable", filters, limit)
	if err != nil {
		return GlueCatalogTablePaginator{}, err
	}

	p := GlueCatalogTablePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p GlueCatalogTablePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p GlueCatalogTablePaginator) NextPage(ctx context.Context) ([]GlueCatalogTable, error) {
	var response GlueCatalogTableSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []GlueCatalogTable
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listGlueCatalogTableFilters = map[string]string{
	"catalog_id":       "description.Table.CatalogId",
	"database_name":    "description.Table.DatabaseName",
	"keibi_account_id": "metadata.SourceID",
}

func ListGlueCatalogTable(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListGlueCatalogTable")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewGlueCatalogTablePaginator(buildFilter(d.KeyColumnQuals, listGlueCatalogTableFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getGlueCatalogTableFilters = map[string]string{
	"database_name":    "description.DatabaseName",
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Table.Name",
}

func GetGlueCatalogTable(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetGlueCatalogTable")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewGlueCatalogTablePaginator(buildFilter(d.KeyColumnQuals, getGlueCatalogTableFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: GlueCatalogTable =============================

// ==========================  START: GlueConnection =============================

type GlueConnection struct {
	Description   aws.GlueConnectionDescription `json:"description"`
	Metadata      aws.Metadata                  `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

type GlueConnectionHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  GlueConnection `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type GlueConnectionHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []GlueConnectionHit `json:"hits"`
}

type GlueConnectionSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  GlueConnectionHits `json:"hits"`
}

type GlueConnectionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewGlueConnectionPaginator(filters []BoolFilter, limit *int64) (GlueConnectionPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_glue_connection", filters, limit)
	if err != nil {
		return GlueConnectionPaginator{}, err
	}

	p := GlueConnectionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p GlueConnectionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p GlueConnectionPaginator) NextPage(ctx context.Context) ([]GlueConnection, error) {
	var response GlueConnectionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []GlueConnection
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listGlueConnectionFilters = map[string]string{
	"connection_type":  "description.Connection.ConnectionType",
	"keibi_account_id": "metadata.SourceID",
}

func ListGlueConnection(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListGlueConnection")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewGlueConnectionPaginator(buildFilter(d.KeyColumnQuals, listGlueConnectionFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getGlueConnectionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Connection.Name",
}

func GetGlueConnection(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetGlueConnection")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewGlueConnectionPaginator(buildFilter(d.KeyColumnQuals, getGlueConnectionFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: GlueConnection =============================

// ==========================  START: GlueCrawler =============================

type GlueCrawler struct {
	Description   aws.GlueCrawlerDescription `json:"description"`
	Metadata      aws.Metadata               `json:"metadata"`
	ResourceJobID int                        `json:"resource_job_id"`
	SourceJobID   int                        `json:"source_job_id"`
	ResourceType  string                     `json:"resource_type"`
	SourceType    string                     `json:"source_type"`
	ID            string                     `json:"id"`
	ARN           string                     `json:"arn"`
	SourceID      string                     `json:"source_id"`
}

type GlueCrawlerHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  GlueCrawler   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type GlueCrawlerHits struct {
	Total SearchTotal      `json:"total"`
	Hits  []GlueCrawlerHit `json:"hits"`
}

type GlueCrawlerSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  GlueCrawlerHits `json:"hits"`
}

type GlueCrawlerPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewGlueCrawlerPaginator(filters []BoolFilter, limit *int64) (GlueCrawlerPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_glue_crawler", filters, limit)
	if err != nil {
		return GlueCrawlerPaginator{}, err
	}

	p := GlueCrawlerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p GlueCrawlerPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p GlueCrawlerPaginator) NextPage(ctx context.Context) ([]GlueCrawler, error) {
	var response GlueCrawlerSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []GlueCrawler
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listGlueCrawlerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListGlueCrawler(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListGlueCrawler")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewGlueCrawlerPaginator(buildFilter(d.KeyColumnQuals, listGlueCrawlerFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getGlueCrawlerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Crawler.Name",
}

func GetGlueCrawler(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetGlueCrawler")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewGlueCrawlerPaginator(buildFilter(d.KeyColumnQuals, getGlueCrawlerFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: GlueCrawler =============================

// ==========================  START: GlueDataCatalogEncryptionSettings =============================

type GlueDataCatalogEncryptionSettings struct {
	Description   aws.GlueDataCatalogEncryptionSettingsDescription `json:"description"`
	Metadata      aws.Metadata                                     `json:"metadata"`
	ResourceJobID int                                              `json:"resource_job_id"`
	SourceJobID   int                                              `json:"source_job_id"`
	ResourceType  string                                           `json:"resource_type"`
	SourceType    string                                           `json:"source_type"`
	ID            string                                           `json:"id"`
	ARN           string                                           `json:"arn"`
	SourceID      string                                           `json:"source_id"`
}

type GlueDataCatalogEncryptionSettingsHit struct {
	ID      string                            `json:"_id"`
	Score   float64                           `json:"_score"`
	Index   string                            `json:"_index"`
	Type    string                            `json:"_type"`
	Version int64                             `json:"_version,omitempty"`
	Source  GlueDataCatalogEncryptionSettings `json:"_source"`
	Sort    []interface{}                     `json:"sort"`
}

type GlueDataCatalogEncryptionSettingsHits struct {
	Total SearchTotal                            `json:"total"`
	Hits  []GlueDataCatalogEncryptionSettingsHit `json:"hits"`
}

type GlueDataCatalogEncryptionSettingsSearchResponse struct {
	PitID string                                `json:"pit_id"`
	Hits  GlueDataCatalogEncryptionSettingsHits `json:"hits"`
}

type GlueDataCatalogEncryptionSettingsPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewGlueDataCatalogEncryptionSettingsPaginator(filters []BoolFilter, limit *int64) (GlueDataCatalogEncryptionSettingsPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_glue_datacatalogencryptionsettings", filters, limit)
	if err != nil {
		return GlueDataCatalogEncryptionSettingsPaginator{}, err
	}

	p := GlueDataCatalogEncryptionSettingsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p GlueDataCatalogEncryptionSettingsPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p GlueDataCatalogEncryptionSettingsPaginator) NextPage(ctx context.Context) ([]GlueDataCatalogEncryptionSettings, error) {
	var response GlueDataCatalogEncryptionSettingsSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []GlueDataCatalogEncryptionSettings
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listGlueDataCatalogEncryptionSettingsFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListGlueDataCatalogEncryptionSettings(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListGlueDataCatalogEncryptionSettings")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewGlueDataCatalogEncryptionSettingsPaginator(buildFilter(d.KeyColumnQuals, listGlueDataCatalogEncryptionSettingsFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getGlueDataCatalogEncryptionSettingsFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetGlueDataCatalogEncryptionSettings(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetGlueDataCatalogEncryptionSettings")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewGlueDataCatalogEncryptionSettingsPaginator(buildFilter(d.KeyColumnQuals, getGlueDataCatalogEncryptionSettingsFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: GlueDataCatalogEncryptionSettings =============================

// ==========================  START: GlueDataQualityRuleset =============================

type GlueDataQualityRuleset struct {
	Description   aws.GlueDataQualityRulesetDescription `json:"description"`
	Metadata      aws.Metadata                          `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

type GlueDataQualityRulesetHit struct {
	ID      string                 `json:"_id"`
	Score   float64                `json:"_score"`
	Index   string                 `json:"_index"`
	Type    string                 `json:"_type"`
	Version int64                  `json:"_version,omitempty"`
	Source  GlueDataQualityRuleset `json:"_source"`
	Sort    []interface{}          `json:"sort"`
}

type GlueDataQualityRulesetHits struct {
	Total SearchTotal                 `json:"total"`
	Hits  []GlueDataQualityRulesetHit `json:"hits"`
}

type GlueDataQualityRulesetSearchResponse struct {
	PitID string                     `json:"pit_id"`
	Hits  GlueDataQualityRulesetHits `json:"hits"`
}

type GlueDataQualityRulesetPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewGlueDataQualityRulesetPaginator(filters []BoolFilter, limit *int64) (GlueDataQualityRulesetPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_glue_dataqualityruleset", filters, limit)
	if err != nil {
		return GlueDataQualityRulesetPaginator{}, err
	}

	p := GlueDataQualityRulesetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p GlueDataQualityRulesetPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p GlueDataQualityRulesetPaginator) NextPage(ctx context.Context) ([]GlueDataQualityRuleset, error) {
	var response GlueDataQualityRulesetSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []GlueDataQualityRuleset
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listGlueDataQualityRulesetFilters = map[string]string{
	"created_on":       "description.DataQualityRuleset.CreatedOn",
	"keibi_account_id": "metadata.SourceID",
	"last_modified_on": "description.DataQualityRuleset.LastModifiedOn",
}

func ListGlueDataQualityRuleset(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListGlueDataQualityRuleset")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewGlueDataQualityRulesetPaginator(buildFilter(d.KeyColumnQuals, listGlueDataQualityRulesetFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getGlueDataQualityRulesetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.DataQualityRuleset.Name",
}

func GetGlueDataQualityRuleset(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetGlueDataQualityRuleset")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewGlueDataQualityRulesetPaginator(buildFilter(d.KeyColumnQuals, getGlueDataQualityRulesetFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: GlueDataQualityRuleset =============================

// ==========================  START: GlueDevEndpoint =============================

type GlueDevEndpoint struct {
	Description   aws.GlueDevEndpointDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type GlueDevEndpointHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  GlueDevEndpoint `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type GlueDevEndpointHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []GlueDevEndpointHit `json:"hits"`
}

type GlueDevEndpointSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  GlueDevEndpointHits `json:"hits"`
}

type GlueDevEndpointPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewGlueDevEndpointPaginator(filters []BoolFilter, limit *int64) (GlueDevEndpointPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_glue_devendpoint", filters, limit)
	if err != nil {
		return GlueDevEndpointPaginator{}, err
	}

	p := GlueDevEndpointPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p GlueDevEndpointPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p GlueDevEndpointPaginator) NextPage(ctx context.Context) ([]GlueDevEndpoint, error) {
	var response GlueDevEndpointSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []GlueDevEndpoint
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listGlueDevEndpointFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListGlueDevEndpoint(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListGlueDevEndpoint")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewGlueDevEndpointPaginator(buildFilter(d.KeyColumnQuals, listGlueDevEndpointFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getGlueDevEndpointFilters = map[string]string{
	"endpoint_name":    "description.DevEndpoint.EndpointName",
	"keibi_account_id": "metadata.SourceID",
}

func GetGlueDevEndpoint(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetGlueDevEndpoint")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewGlueDevEndpointPaginator(buildFilter(d.KeyColumnQuals, getGlueDevEndpointFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: GlueDevEndpoint =============================

// ==========================  START: GlueJob =============================

type GlueJob struct {
	Description   aws.GlueJobDescription `json:"description"`
	Metadata      aws.Metadata           `json:"metadata"`
	ResourceJobID int                    `json:"resource_job_id"`
	SourceJobID   int                    `json:"source_job_id"`
	ResourceType  string                 `json:"resource_type"`
	SourceType    string                 `json:"source_type"`
	ID            string                 `json:"id"`
	ARN           string                 `json:"arn"`
	SourceID      string                 `json:"source_id"`
}

type GlueJobHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  GlueJob       `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type GlueJobHits struct {
	Total SearchTotal  `json:"total"`
	Hits  []GlueJobHit `json:"hits"`
}

type GlueJobSearchResponse struct {
	PitID string      `json:"pit_id"`
	Hits  GlueJobHits `json:"hits"`
}

type GlueJobPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewGlueJobPaginator(filters []BoolFilter, limit *int64) (GlueJobPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_glue_job", filters, limit)
	if err != nil {
		return GlueJobPaginator{}, err
	}

	p := GlueJobPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p GlueJobPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p GlueJobPaginator) NextPage(ctx context.Context) ([]GlueJob, error) {
	var response GlueJobSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []GlueJob
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listGlueJobFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListGlueJob(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListGlueJob")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewGlueJobPaginator(buildFilter(d.KeyColumnQuals, listGlueJobFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getGlueJobFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Job.Name",
}

func GetGlueJob(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetGlueJob")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewGlueJobPaginator(buildFilter(d.KeyColumnQuals, getGlueJobFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: GlueJob =============================

// ==========================  START: GlueSecurityConfiguration =============================

type GlueSecurityConfiguration struct {
	Description   aws.GlueSecurityConfigurationDescription `json:"description"`
	Metadata      aws.Metadata                             `json:"metadata"`
	ResourceJobID int                                      `json:"resource_job_id"`
	SourceJobID   int                                      `json:"source_job_id"`
	ResourceType  string                                   `json:"resource_type"`
	SourceType    string                                   `json:"source_type"`
	ID            string                                   `json:"id"`
	ARN           string                                   `json:"arn"`
	SourceID      string                                   `json:"source_id"`
}

type GlueSecurityConfigurationHit struct {
	ID      string                    `json:"_id"`
	Score   float64                   `json:"_score"`
	Index   string                    `json:"_index"`
	Type    string                    `json:"_type"`
	Version int64                     `json:"_version,omitempty"`
	Source  GlueSecurityConfiguration `json:"_source"`
	Sort    []interface{}             `json:"sort"`
}

type GlueSecurityConfigurationHits struct {
	Total SearchTotal                    `json:"total"`
	Hits  []GlueSecurityConfigurationHit `json:"hits"`
}

type GlueSecurityConfigurationSearchResponse struct {
	PitID string                        `json:"pit_id"`
	Hits  GlueSecurityConfigurationHits `json:"hits"`
}

type GlueSecurityConfigurationPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewGlueSecurityConfigurationPaginator(filters []BoolFilter, limit *int64) (GlueSecurityConfigurationPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_glue_securityconfiguration", filters, limit)
	if err != nil {
		return GlueSecurityConfigurationPaginator{}, err
	}

	p := GlueSecurityConfigurationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p GlueSecurityConfigurationPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p GlueSecurityConfigurationPaginator) NextPage(ctx context.Context) ([]GlueSecurityConfiguration, error) {
	var response GlueSecurityConfigurationSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []GlueSecurityConfiguration
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listGlueSecurityConfigurationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListGlueSecurityConfiguration(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListGlueSecurityConfiguration")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewGlueSecurityConfigurationPaginator(buildFilter(d.KeyColumnQuals, listGlueSecurityConfigurationFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getGlueSecurityConfigurationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.SecurityConfiguration.Name",
}

func GetGlueSecurityConfiguration(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetGlueSecurityConfiguration")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewGlueSecurityConfigurationPaginator(buildFilter(d.KeyColumnQuals, getGlueSecurityConfigurationFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: GlueSecurityConfiguration =============================

// ==========================  START: HealthEvent =============================

type HealthEvent struct {
	Description   aws.HealthEventDescription `json:"description"`
	Metadata      aws.Metadata               `json:"metadata"`
	ResourceJobID int                        `json:"resource_job_id"`
	SourceJobID   int                        `json:"source_job_id"`
	ResourceType  string                     `json:"resource_type"`
	SourceType    string                     `json:"source_type"`
	ID            string                     `json:"id"`
	ARN           string                     `json:"arn"`
	SourceID      string                     `json:"source_id"`
}

type HealthEventHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  HealthEvent   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type HealthEventHits struct {
	Total SearchTotal      `json:"total"`
	Hits  []HealthEventHit `json:"hits"`
}

type HealthEventSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  HealthEventHits `json:"hits"`
}

type HealthEventPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewHealthEventPaginator(filters []BoolFilter, limit *int64) (HealthEventPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_health_event", filters, limit)
	if err != nil {
		return HealthEventPaginator{}, err
	}

	p := HealthEventPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p HealthEventPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p HealthEventPaginator) NextPage(ctx context.Context) ([]HealthEvent, error) {
	var response HealthEventSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []HealthEvent
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listHealthEventFilters = map[string]string{
	"arn":                 "description.Event.Arn",
	"availability_zone":   "description.Event.AvailabilityZone",
	"end_time":            "description.Event.EndTime",
	"event_type_category": "description.Event.EventTypeCategory",
	"event_type_code":     "description.Event.EventTypeCode",
	"keibi_account_id":    "metadata.SourceID",
	"last_updated_time":   "description.Event.LastUpdatedTime",
	"service":             "description.Event.Service",
	"start_time":          "description.Event.StartTime",
	"status_code":         "description.Event.StatusCode",
}

func ListHealthEvent(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListHealthEvent")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewHealthEventPaginator(buildFilter(d.KeyColumnQuals, listHealthEventFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getHealthEventFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetHealthEvent(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetHealthEvent")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewHealthEventPaginator(buildFilter(d.KeyColumnQuals, getHealthEventFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: HealthEvent =============================

// ==========================  START: IdentityStoreGroup =============================

type IdentityStoreGroup struct {
	Description   aws.IdentityStoreGroupDescription `json:"description"`
	Metadata      aws.Metadata                      `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

type IdentityStoreGroupHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  IdentityStoreGroup `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type IdentityStoreGroupHits struct {
	Total SearchTotal             `json:"total"`
	Hits  []IdentityStoreGroupHit `json:"hits"`
}

type IdentityStoreGroupSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  IdentityStoreGroupHits `json:"hits"`
}

type IdentityStoreGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIdentityStoreGroupPaginator(filters []BoolFilter, limit *int64) (IdentityStoreGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_identitystore_group", filters, limit)
	if err != nil {
		return IdentityStoreGroupPaginator{}, err
	}

	p := IdentityStoreGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IdentityStoreGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IdentityStoreGroupPaginator) NextPage(ctx context.Context) ([]IdentityStoreGroup, error) {
	var response IdentityStoreGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IdentityStoreGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIdentityStoreGroupFilters = map[string]string{
	"identity_store_id": "description.Group.IdentityStoreId",
	"keibi_account_id":  "metadata.SourceID",
}

func ListIdentityStoreGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIdentityStoreGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIdentityStoreGroupPaginator(buildFilter(d.KeyColumnQuals, listIdentityStoreGroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIdentityStoreGroupFilters = map[string]string{
	"id":                "description.Group.GroupId",
	"identity_store_id": "description.Group.IdentityStoreId",
	"keibi_account_id":  "metadata.SourceID",
}

func GetIdentityStoreGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIdentityStoreGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIdentityStoreGroupPaginator(buildFilter(d.KeyColumnQuals, getIdentityStoreGroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IdentityStoreGroup =============================

// ==========================  START: IdentityStoreUser =============================

type IdentityStoreUser struct {
	Description   aws.IdentityStoreUserDescription `json:"description"`
	Metadata      aws.Metadata                     `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

type IdentityStoreUserHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  IdentityStoreUser `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type IdentityStoreUserHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []IdentityStoreUserHit `json:"hits"`
}

type IdentityStoreUserSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  IdentityStoreUserHits `json:"hits"`
}

type IdentityStoreUserPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIdentityStoreUserPaginator(filters []BoolFilter, limit *int64) (IdentityStoreUserPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_identitystore_user", filters, limit)
	if err != nil {
		return IdentityStoreUserPaginator{}, err
	}

	p := IdentityStoreUserPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IdentityStoreUserPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IdentityStoreUserPaginator) NextPage(ctx context.Context) ([]IdentityStoreUser, error) {
	var response IdentityStoreUserSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IdentityStoreUser
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIdentityStoreUserFilters = map[string]string{
	"identity_store_id": "description.User.IdentityStoreId",
	"keibi_account_id":  "metadata.SourceID",
}

func ListIdentityStoreUser(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIdentityStoreUser")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIdentityStoreUserPaginator(buildFilter(d.KeyColumnQuals, listIdentityStoreUserFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIdentityStoreUserFilters = map[string]string{
	"id":                "description.User.UserId",
	"identity_store_id": "description.User.IdentityStoreId",
	"keibi_account_id":  "metadata.SourceID",
}

func GetIdentityStoreUser(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIdentityStoreUser")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIdentityStoreUserPaginator(buildFilter(d.KeyColumnQuals, getIdentityStoreUserFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IdentityStoreUser =============================

// ==========================  START: InspectorAssessmentRun =============================

type InspectorAssessmentRun struct {
	Description   aws.InspectorAssessmentRunDescription `json:"description"`
	Metadata      aws.Metadata                          `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

type InspectorAssessmentRunHit struct {
	ID      string                 `json:"_id"`
	Score   float64                `json:"_score"`
	Index   string                 `json:"_index"`
	Type    string                 `json:"_type"`
	Version int64                  `json:"_version,omitempty"`
	Source  InspectorAssessmentRun `json:"_source"`
	Sort    []interface{}          `json:"sort"`
}

type InspectorAssessmentRunHits struct {
	Total SearchTotal                 `json:"total"`
	Hits  []InspectorAssessmentRunHit `json:"hits"`
}

type InspectorAssessmentRunSearchResponse struct {
	PitID string                     `json:"pit_id"`
	Hits  InspectorAssessmentRunHits `json:"hits"`
}

type InspectorAssessmentRunPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewInspectorAssessmentRunPaginator(filters []BoolFilter, limit *int64) (InspectorAssessmentRunPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_inspector_assessmentrun", filters, limit)
	if err != nil {
		return InspectorAssessmentRunPaginator{}, err
	}

	p := InspectorAssessmentRunPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p InspectorAssessmentRunPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p InspectorAssessmentRunPaginator) NextPage(ctx context.Context) ([]InspectorAssessmentRun, error) {
	var response InspectorAssessmentRunSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []InspectorAssessmentRun
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listInspectorAssessmentRunFilters = map[string]string{
	"assessment_template_arn": "description.AssessmentRun.AssessmentTemplateArn",
	"keibi_account_id":        "metadata.SourceID",
	"name":                    "description.AssessmentRun.Name",
	"state":                   "description.AssessmentRun.State",
}

func ListInspectorAssessmentRun(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListInspectorAssessmentRun")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewInspectorAssessmentRunPaginator(buildFilter(d.KeyColumnQuals, listInspectorAssessmentRunFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getInspectorAssessmentRunFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetInspectorAssessmentRun(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetInspectorAssessmentRun")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewInspectorAssessmentRunPaginator(buildFilter(d.KeyColumnQuals, getInspectorAssessmentRunFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: InspectorAssessmentRun =============================

// ==========================  START: InspectorAssessmentTarget =============================

type InspectorAssessmentTarget struct {
	Description   aws.InspectorAssessmentTargetDescription `json:"description"`
	Metadata      aws.Metadata                             `json:"metadata"`
	ResourceJobID int                                      `json:"resource_job_id"`
	SourceJobID   int                                      `json:"source_job_id"`
	ResourceType  string                                   `json:"resource_type"`
	SourceType    string                                   `json:"source_type"`
	ID            string                                   `json:"id"`
	ARN           string                                   `json:"arn"`
	SourceID      string                                   `json:"source_id"`
}

type InspectorAssessmentTargetHit struct {
	ID      string                    `json:"_id"`
	Score   float64                   `json:"_score"`
	Index   string                    `json:"_index"`
	Type    string                    `json:"_type"`
	Version int64                     `json:"_version,omitempty"`
	Source  InspectorAssessmentTarget `json:"_source"`
	Sort    []interface{}             `json:"sort"`
}

type InspectorAssessmentTargetHits struct {
	Total SearchTotal                    `json:"total"`
	Hits  []InspectorAssessmentTargetHit `json:"hits"`
}

type InspectorAssessmentTargetSearchResponse struct {
	PitID string                        `json:"pit_id"`
	Hits  InspectorAssessmentTargetHits `json:"hits"`
}

type InspectorAssessmentTargetPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewInspectorAssessmentTargetPaginator(filters []BoolFilter, limit *int64) (InspectorAssessmentTargetPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_inspector_assessmenttarget", filters, limit)
	if err != nil {
		return InspectorAssessmentTargetPaginator{}, err
	}

	p := InspectorAssessmentTargetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p InspectorAssessmentTargetPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p InspectorAssessmentTargetPaginator) NextPage(ctx context.Context) ([]InspectorAssessmentTarget, error) {
	var response InspectorAssessmentTargetSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []InspectorAssessmentTarget
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listInspectorAssessmentTargetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListInspectorAssessmentTarget(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListInspectorAssessmentTarget")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewInspectorAssessmentTargetPaginator(buildFilter(d.KeyColumnQuals, listInspectorAssessmentTargetFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getInspectorAssessmentTargetFilters = map[string]string{
	"arn":              "description.AssessmentTarget.Arn",
	"keibi_account_id": "metadata.SourceID",
}

func GetInspectorAssessmentTarget(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetInspectorAssessmentTarget")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewInspectorAssessmentTargetPaginator(buildFilter(d.KeyColumnQuals, getInspectorAssessmentTargetFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: InspectorAssessmentTarget =============================

// ==========================  START: InspectorAssessmentTemplate =============================

type InspectorAssessmentTemplate struct {
	Description   aws.InspectorAssessmentTemplateDescription `json:"description"`
	Metadata      aws.Metadata                               `json:"metadata"`
	ResourceJobID int                                        `json:"resource_job_id"`
	SourceJobID   int                                        `json:"source_job_id"`
	ResourceType  string                                     `json:"resource_type"`
	SourceType    string                                     `json:"source_type"`
	ID            string                                     `json:"id"`
	ARN           string                                     `json:"arn"`
	SourceID      string                                     `json:"source_id"`
}

type InspectorAssessmentTemplateHit struct {
	ID      string                      `json:"_id"`
	Score   float64                     `json:"_score"`
	Index   string                      `json:"_index"`
	Type    string                      `json:"_type"`
	Version int64                       `json:"_version,omitempty"`
	Source  InspectorAssessmentTemplate `json:"_source"`
	Sort    []interface{}               `json:"sort"`
}

type InspectorAssessmentTemplateHits struct {
	Total SearchTotal                      `json:"total"`
	Hits  []InspectorAssessmentTemplateHit `json:"hits"`
}

type InspectorAssessmentTemplateSearchResponse struct {
	PitID string                          `json:"pit_id"`
	Hits  InspectorAssessmentTemplateHits `json:"hits"`
}

type InspectorAssessmentTemplatePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewInspectorAssessmentTemplatePaginator(filters []BoolFilter, limit *int64) (InspectorAssessmentTemplatePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_inspector_assessmenttemplate", filters, limit)
	if err != nil {
		return InspectorAssessmentTemplatePaginator{}, err
	}

	p := InspectorAssessmentTemplatePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p InspectorAssessmentTemplatePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p InspectorAssessmentTemplatePaginator) NextPage(ctx context.Context) ([]InspectorAssessmentTemplate, error) {
	var response InspectorAssessmentTemplateSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []InspectorAssessmentTemplate
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listInspectorAssessmentTemplateFilters = map[string]string{
	"assessment_target_arn": "description.AssessmentTemplate.AssessmentTargetArn",
	"keibi_account_id":      "metadata.SourceID",
	"name":                  "description.AssessmentTemplate.Name",
}

func ListInspectorAssessmentTemplate(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListInspectorAssessmentTemplate")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewInspectorAssessmentTemplatePaginator(buildFilter(d.KeyColumnQuals, listInspectorAssessmentTemplateFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getInspectorAssessmentTemplateFilters = map[string]string{
	"arn":              "description.AssessmentTemplate.Arn",
	"keibi_account_id": "metadata.SourceID",
}

func GetInspectorAssessmentTemplate(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetInspectorAssessmentTemplate")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewInspectorAssessmentTemplatePaginator(buildFilter(d.KeyColumnQuals, getInspectorAssessmentTemplateFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: InspectorAssessmentTemplate =============================

// ==========================  START: InspectorExclusion =============================

type InspectorExclusion struct {
	Description   aws.InspectorExclusionDescription `json:"description"`
	Metadata      aws.Metadata                      `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

type InspectorExclusionHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  InspectorExclusion `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type InspectorExclusionHits struct {
	Total SearchTotal             `json:"total"`
	Hits  []InspectorExclusionHit `json:"hits"`
}

type InspectorExclusionSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  InspectorExclusionHits `json:"hits"`
}

type InspectorExclusionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewInspectorExclusionPaginator(filters []BoolFilter, limit *int64) (InspectorExclusionPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_inspector_exclusion", filters, limit)
	if err != nil {
		return InspectorExclusionPaginator{}, err
	}

	p := InspectorExclusionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p InspectorExclusionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p InspectorExclusionPaginator) NextPage(ctx context.Context) ([]InspectorExclusion, error) {
	var response InspectorExclusionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []InspectorExclusion
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listInspectorExclusionFilters = map[string]string{
	"assessment_run_arn": "description.Exclusion.Arn",
	"keibi_account_id":   "metadata.SourceID",
}

func ListInspectorExclusion(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListInspectorExclusion")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewInspectorExclusionPaginator(buildFilter(d.KeyColumnQuals, listInspectorExclusionFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getInspectorExclusionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetInspectorExclusion(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetInspectorExclusion")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewInspectorExclusionPaginator(buildFilter(d.KeyColumnQuals, getInspectorExclusionFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: InspectorExclusion =============================

// ==========================  START: InspectorFinding =============================

type InspectorFinding struct {
	Description   aws.InspectorFindingDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type InspectorFindingHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  InspectorFinding `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type InspectorFindingHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []InspectorFindingHit `json:"hits"`
}

type InspectorFindingSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  InspectorFindingHits `json:"hits"`
}

type InspectorFindingPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewInspectorFindingPaginator(filters []BoolFilter, limit *int64) (InspectorFindingPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_inspector_finding", filters, limit)
	if err != nil {
		return InspectorFindingPaginator{}, err
	}

	p := InspectorFindingPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p InspectorFindingPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p InspectorFindingPaginator) NextPage(ctx context.Context) ([]InspectorFinding, error) {
	var response InspectorFindingSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []InspectorFinding
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listInspectorFindingFilters = map[string]string{
	"agent_id":           "description.Finding.AssetAttributes.AgentId",
	"auto_scaling_group": "description.Finding.AssetAttributes.AutoScalingGroup",
	"keibi_account_id":   "metadata.SourceID",
	"severity":           "description.Finding.Severity",
}

func ListInspectorFinding(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListInspectorFinding")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewInspectorFindingPaginator(buildFilter(d.KeyColumnQuals, listInspectorFindingFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getInspectorFindingFilters = map[string]string{
	"arn":              "description.Finding.Arn",
	"keibi_account_id": "metadata.SourceID",
}

func GetInspectorFinding(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetInspectorFinding")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewInspectorFindingPaginator(buildFilter(d.KeyColumnQuals, getInspectorFindingFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: InspectorFinding =============================
